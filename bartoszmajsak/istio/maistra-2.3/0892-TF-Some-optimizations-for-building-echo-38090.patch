From 85aa65802ed654261ed2ec248a3bb87d5285ee3e Mon Sep 17 00:00:00 2001
From: Nathan Mittler <nmittler@gmail.com>
Date: Wed, 23 Mar 2022 11:03:38 -0700
Subject: [TF] Some optimizations for building echo (#38090)

Adding some concurrency and additional cleanup.
---
 .../components/echo/deployment/builder.go     | 31 ++++----
 .../framework/components/echo/kube/builder.go | 72 +++----------------
 .../components/echo/kube/instance.go          | 10 +--
 pkg/test/framework/config.go                  | 22 +++---
 pkg/test/framework/resource/context.go        |  3 +
 5 files changed, 46 insertions(+), 92 deletions(-)

diff --git a/pkg/test/framework/components/echo/deployment/builder.go b/pkg/test/framework/components/echo/deployment/builder.go
index 3560374c83..3f9635f736 100644
--- a/pkg/test/framework/components/echo/deployment/builder.go
+++ b/pkg/test/framework/components/echo/deployment/builder.go
@@ -19,6 +19,7 @@
 	"fmt"
 	"strings"
 	"sync"
+	"time"
 
 	"github.com/google/go-cmp/cmp"
 	"github.com/hashicorp/go-multierror"
@@ -150,7 +151,7 @@ func (b builder) With(i *echo.Instance, cfg echo.Config) Builder {
 	for idx, c := range targetClusters {
 		ec, ok := c.(echo.Cluster)
 		if !ok {
-			b.errs = multierror.Append(b.errs, fmt.Errorf("attembed to deploy to %s but it does not implement echo.Cluster", c.Name()))
+			b.errs = multierror.Append(b.errs, fmt.Errorf("attempted to deploy to %s but it does not implement echo.Cluster", c.Name()))
 			continue
 		}
 		perClusterConfig, ok := ec.CanDeploy(cfg)
@@ -252,11 +253,14 @@ func (b builder) injectionTemplates() (map[string]sets.Set, error) {
 
 // build inner allows assigning to b (assignment to receiver would be ineffective)
 func build(b builder) (out echo.Instances, err error) {
+	start := time.Now()
 	scopes.Framework.Info("=== BEGIN: Deploy echo instances ===")
 	defer func() {
 		if err != nil {
 			scopes.Framework.Error("=== FAILED: Deploy echo instances ===")
 			scopes.Framework.Error(err)
+		} else {
+			scopes.Framework.Infof("=== SUCCEEDED: Deploy echo instances in %f ===", time.Since(start).Seconds())
 		}
 	}()
 
@@ -279,8 +283,6 @@ func build(b builder) (out echo.Instances, err error) {
 	if out, err = b.deployInstances(); err != nil {
 		return
 	}
-
-	scopes.Framework.Info("=== DONE: Deploy echo instances ===")
 	return
 }
 
@@ -299,8 +301,8 @@ func (b builder) getOrCreateNamespace(prefix string) (builder, namespace.Instanc
 
 // deployServices deploys the kubernetes Service to all clusters. Multicluster meshes should have "sameness"
 // per cluster. This avoids concurrent writes later.
-func (b builder) deployServices() error {
-	services := map[string]string{}
+func (b builder) deployServices() (err error) {
+	services := make(map[string]string)
 	for _, cfgs := range b.configs {
 		for _, cfg := range cfgs {
 			svc, err := kube.GenerateService(cfg)
@@ -317,26 +319,25 @@ func (b builder) deployServices() error {
 		}
 	}
 
-	errG := multierror.Group{}
+	// Deploy the services to all clusters.
+	cfg := b.ctx.ConfigKube().New()
 	for svcNs, svcYaml := range services {
-		svcYaml := svcYaml
 		ns := strings.Split(svcNs, ".")[1]
-		errG.Go(func() error {
-			return b.ctx.ConfigKube().YAML(ns, svcYaml).Apply(resource.NoCleanup)
-		})
+		cfg.YAML(ns, svcYaml)
 	}
-	return errG.Wait().ErrorOrNil()
+
+	return cfg.Apply(resource.NoCleanup)
 }
 
-func (b builder) deployInstances() (echo.Instances, error) {
+func (b builder) deployInstances() (instances echo.Instances, err error) {
 	m := sync.Mutex{}
 	out := echo.Instances{}
-	errGroup := multierror.Group{}
+	g := multierror.Group{}
 	// run the builder func for each kind of config in parallel
 	for kind, configs := range b.configs {
 		kind := kind
 		configs := configs
-		errGroup.Go(func() error {
+		g.Go(func() error {
 			buildFunc, err := echo.GetBuilder(kind)
 			if err != nil {
 				return err
@@ -358,7 +359,7 @@ func (b builder) deployInstances() (echo.Instances, error) {
 			return nil
 		})
 	}
-	if err := errGroup.Wait().ErrorOrNil(); err != nil {
+	if err := g.Wait().ErrorOrNil(); err != nil {
 		return nil, err
 	}
 	return out, nil
diff --git a/pkg/test/framework/components/echo/kube/builder.go b/pkg/test/framework/components/echo/kube/builder.go
index 3b30b6b4d4..5af92f9a12 100644
--- a/pkg/test/framework/components/echo/kube/builder.go
+++ b/pkg/test/framework/components/echo/kube/builder.go
@@ -15,16 +15,11 @@
 package kube
 
 import (
-	"fmt"
-	"sync"
-	"time"
-
 	"github.com/hashicorp/go-multierror"
 
 	"istio.io/istio/pkg/test/framework/components/cluster"
 	"istio.io/istio/pkg/test/framework/components/echo"
 	"istio.io/istio/pkg/test/framework/resource"
-	"istio.io/istio/pkg/test/scopes"
 )
 
 func init() {
@@ -32,62 +27,17 @@ func init() {
 }
 
 func build(ctx resource.Context, configs []echo.Config) (echo.Instances, error) {
-	t0 := time.Now()
-	instances, err := newInstances(ctx, configs)
-	if err != nil {
-		return nil, fmt.Errorf("build instance: %v", err)
-	}
-	scopes.Framework.Debugf("created echo deployments in %v", time.Since(t0))
-
-	if err := startAll(instances); err != nil {
-		return nil, fmt.Errorf("failed starting kube echo instances: %v", err)
-	}
-	scopes.Framework.Debugf("successfully started kube echo instances in %v", time.Since(t0))
-
-	return instances, nil
-}
-
-func newInstances(ctx resource.Context, configs []echo.Config) (echo.Instances, error) {
-	// TODO consider making this parallel. This was attempted but had issues with concurrent writes
-	// it should be possible though.
-	instances := make([]echo.Instance, 0, len(configs))
-	for _, cfg := range configs {
-		inst, err := newInstance(ctx, cfg)
-		if err != nil {
-			return nil, err
-		}
-		instances = append(instances, inst)
-	}
-	return instances, nil
-}
-
-func startAll(instances echo.Instances) error {
-	// Wait to receive the k8s Endpoints for each Echo Instance.
-	wg := sync.WaitGroup{}
-	aggregateErrMux := &sync.Mutex{}
-	var aggregateErr error
-	for _, i := range instances {
-		inst := i.(*instance)
-		wg.Add(1)
-
-		// Run the waits in parallel.
-		go func() {
-			defer wg.Done()
-
-			if err := inst.Start(); err != nil {
-				aggregateErrMux.Lock()
-				aggregateErr = multierror.Append(aggregateErr, fmt.Errorf("start %v/%v/%v: %v",
-					inst.ID(), inst.Config().Service, inst.Address(), err))
-				aggregateErrMux.Unlock()
-			}
-		}()
-	}
-
-	wg.Wait()
-
-	if aggregateErr != nil {
-		return aggregateErr
+	instances := make([]echo.Instance, len(configs))
+
+	g := multierror.Group{}
+	for i, cfg := range configs {
+		i, cfg := i, cfg
+		g.Go(func() (err error) {
+			instances[i], err = newInstance(ctx, cfg)
+			return
+		})
 	}
 
-	return nil
+	err := g.Wait().ErrorOrNil()
+	return instances, err
 }
diff --git a/pkg/test/framework/components/echo/kube/instance.go b/pkg/test/framework/components/echo/kube/instance.go
index 93664d7632..29e86f567b 100644
--- a/pkg/test/framework/components/echo/kube/instance.go
+++ b/pkg/test/framework/components/echo/kube/instance.go
@@ -104,6 +104,11 @@ func newInstance(ctx resource.Context, originalCfg echo.Config) (out *instance,
 		c.clusterIP = ""
 	}
 
+	// Start the workload manager.
+	if err := c.workloadMgr.Start(); err != nil {
+		return nil, err
+	}
+
 	return c, nil
 }
 
@@ -156,11 +161,6 @@ func (c *instance) firstClient() (*echoClient.Client, error) {
 	return workloads[0].(*workload).Client()
 }
 
-// Start this echo instance
-func (c *instance) Start() error {
-	return c.workloadMgr.Start()
-}
-
 func (c *instance) Close() (err error) {
 	return c.workloadMgr.Close()
 }
diff --git a/pkg/test/framework/config.go b/pkg/test/framework/config.go
index b34f807a43..0d814b3634 100644
--- a/pkg/test/framework/config.go
+++ b/pkg/test/framework/config.go
@@ -54,20 +54,27 @@ func newConfigManager(ctx resource.Context, clusters cluster.Clusters) resource.
 // Note: go tests are distinct binaries per test suite, so this is the suite level number of calls
 var GlobalYAMLWrites = atomic.NewUint64(0)
 
+func (c *configManager) New() resource.Config {
+	return &configImpl{
+		configManager: c,
+		yamlText:      make(map[string][]string),
+	}
+}
+
 func (c *configManager) YAML(ns string, yamlText ...string) resource.Config {
-	return newConfig(c).YAML(ns, yamlText...)
+	return c.New().YAML(ns, yamlText...)
 }
 
 func (c *configManager) Eval(ns string, args interface{}, yamlTemplates ...string) resource.Config {
-	return newConfig(c).Eval(ns, args, yamlTemplates...)
+	return c.New().Eval(ns, args, yamlTemplates...)
 }
 
 func (c *configManager) File(ns string, filePaths ...string) resource.Config {
-	return newConfig(c).File(ns, filePaths...)
+	return c.New().File(ns, filePaths...)
 }
 
 func (c *configManager) EvalFile(ns string, args interface{}, filePaths ...string) resource.Config {
-	return newConfig(c).EvalFile(ns, args, filePaths...)
+	return c.New().EvalFile(ns, args, filePaths...)
 }
 
 func (c *configManager) applyYAML(cleanup bool, ns string, yamlText ...string) error {
@@ -172,13 +179,6 @@ func (c *configManager) WithFilePrefix(prefix string) resource.ConfigManager {
 
 var _ resource.Config = &configImpl{}
 
-func newConfig(m *configManager) *configImpl {
-	return &configImpl{
-		configManager: m,
-		yamlText:      make(map[string][]string),
-	}
-}
-
 type configImpl struct {
 	*configManager
 	yamlText map[string][]string
diff --git a/pkg/test/framework/resource/context.go b/pkg/test/framework/resource/context.go
index 6d4c274519..ca7772e2e1 100644
--- a/pkg/test/framework/resource/context.go
+++ b/pkg/test/framework/resource/context.go
@@ -71,6 +71,9 @@ type Config interface {
 type ConfigManager interface {
 	ConfigFactory
 
+	// New empty Config.
+	New() Config
+
 	// WithFilePrefix sets the prefix used for intermediate files.
 	WithFilePrefix(prefix string) ConfigManager
 }
-- 
2.35.3

