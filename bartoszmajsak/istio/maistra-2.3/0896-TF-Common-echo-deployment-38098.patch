From 3f767bbcf14f4d080d029ecec33d4e9d5164e394 Mon Sep 17 00:00:00 2001
From: Nathan Mittler <nmittler@gmail.com>
Date: Wed, 23 Mar 2022 15:21:35 -0700
Subject: [TF] Common echo deployment (#38098)

This moves the common echo deployment out of the pilot tests, to a shared area. A number of improvements to support future integration with the security tests.

Refactored all pilot tests to use the new deployment.
---
 .../framework/components/echo/common/call.go  |  39 +-
 .../components/echo/common/deployment/apps.go | 497 ++++++++++++++++++
 .../components/echo/common/ports/ports.go     |  11 +
 .../components/echo/deployment/builder.go     |   2 +-
 .../components/echo/echotest/filters.go       |   4 +-
 .../framework/components/echo/instances.go    |  12 +-
 .../components/echo/match/matchers.go         |   4 +-
 .../framework/components/echo/services.go     |  14 +
 .../pilot/cni/cniversionskew_test.go          |   7 +-
 tests/integration/pilot/common/apps.go        | 339 ------------
 tests/integration/pilot/common/routing.go     | 141 ++---
 tests/integration/pilot/common/traffic.go     |   9 +-
 .../integration/pilot/cross_revision_test.go  |   4 +-
 .../pilot/endpointslice/endpointslice_test.go |   7 +-
 tests/integration/pilot/gw_topology_test.go   |   4 +-
 tests/integration/pilot/ingress_test.go       |  40 +-
 tests/integration/pilot/istioctl_test.go      |  54 +-
 tests/integration/pilot/locality_test.go      |  12 +-
 tests/integration/pilot/main_test.go          |   6 +-
 tests/integration/pilot/mirror_test.go        |  20 +-
 .../pilot/multi_version_revision_test.go      |   2 +-
 tests/integration/pilot/multicluster_test.go  |   6 +-
 .../pilot/original_src_addr_test.go           |   4 +-
 tests/integration/pilot/piggyback_test.go     |   4 +-
 .../pilot/revisioned_upgrade_test.go          |   4 +-
 tests/integration/pilot/routing_test.go       |   2 +-
 tests/integration/pilot/vm_test.go            |  10 +-
 27 files changed, 724 insertions(+), 534 deletions(-)
 create mode 100644 pkg/test/framework/components/echo/common/deployment/apps.go
 delete mode 100644 tests/integration/pilot/common/apps.go

diff --git a/pkg/test/framework/components/echo/common/call.go b/pkg/test/framework/components/echo/common/call.go
index d6afd72c9a..2461e71ba8 100644
--- a/pkg/test/framework/components/echo/common/call.go
+++ b/pkg/test/framework/components/echo/common/call.go
@@ -19,7 +19,6 @@
 	"fmt"
 	"net"
 	"strconv"
-	"strings"
 	"time"
 
 	echoclient "istio.io/istio/pkg/test/echo"
@@ -39,20 +38,7 @@ func callInternal(srcName string, opts *echo.CallOptions, send sendFunc) (echocl
 		return nil, err
 	}
 
-	var targetURL string
-	port := opts.Port.ServicePort
-	addressAndPort := net.JoinHostPort(opts.Address, strconv.Itoa(port))
-	// Forward a request from 'this' service to the destination service.
-	switch opts.Scheme {
-	case scheme.DNS:
-		targetURL = fmt.Sprintf("%s://%s", string(opts.Scheme), opts.Address)
-	case scheme.TCP:
-		targetURL = fmt.Sprintf("%s://%s", string(opts.Scheme), addressAndPort)
-	case scheme.XDS:
-		targetURL = fmt.Sprintf("%s:///%s", string(opts.Scheme), addressAndPort)
-	default:
-		targetURL = fmt.Sprintf("%s://%s%s", string(opts.Scheme), addressAndPort, opts.HTTP.Path)
-	}
+	targetURL := getTargetURL(opts)
 
 	// Copy all the headers.
 	protoHeaders := common.HTTPToProtoHeaders(opts.HTTP.Headers)
@@ -158,13 +144,26 @@ func ForwardEcho(srcName string, clientProvider EchoClientProvider, opts *echo.C
 		return c.ForwardEcho(context.Background(), req)
 	})
 	if err != nil {
-		return nil, fmt.Errorf("failed calling %s->'%s://%s:%d/%s': %v",
+		return nil, fmt.Errorf("failed calling %s->'%s': %v",
 			srcName,
-			strings.ToLower(string(opts.Port.Protocol)),
-			opts.Address,
-			opts.Port.ServicePort,
-			opts.HTTP.Path,
+			getTargetURL(opts),
 			err)
 	}
 	return res, nil
 }
+
+func getTargetURL(opts *echo.CallOptions) string {
+	port := opts.Port.ServicePort
+	addressAndPort := net.JoinHostPort(opts.Address, strconv.Itoa(port))
+	// Forward a request from 'this' service to the destination service.
+	switch opts.Scheme {
+	case scheme.DNS:
+		return fmt.Sprintf("%s://%s", string(opts.Scheme), opts.Address)
+	case scheme.TCP, scheme.GRPC:
+		return fmt.Sprintf("%s://%s", string(opts.Scheme), addressAndPort)
+	case scheme.XDS:
+		return fmt.Sprintf("%s:///%s", string(opts.Scheme), addressAndPort)
+	default:
+		return fmt.Sprintf("%s://%s%s", string(opts.Scheme), addressAndPort, opts.HTTP.Path)
+	}
+}
diff --git a/pkg/test/framework/components/echo/common/deployment/apps.go b/pkg/test/framework/components/echo/common/deployment/apps.go
new file mode 100644
index 0000000000..54d276fb66
--- /dev/null
+++ b/pkg/test/framework/components/echo/common/deployment/apps.go
@@ -0,0 +1,497 @@
+// Copyright Istio Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package deployment
+
+import (
+	"context"
+	"fmt"
+	"sort"
+	"strconv"
+	"strings"
+	"sync"
+
+	"github.com/hashicorp/go-multierror"
+	"golang.org/x/sync/errgroup"
+
+	"istio.io/istio/pilot/pkg/model"
+	"istio.io/istio/pkg/test/framework/components/echo"
+	"istio.io/istio/pkg/test/framework/components/echo/common/ports"
+	"istio.io/istio/pkg/test/framework/components/echo/deployment"
+	"istio.io/istio/pkg/test/framework/components/echo/match"
+	"istio.io/istio/pkg/test/framework/components/istio"
+	"istio.io/istio/pkg/test/framework/components/istio/ingress"
+	"istio.io/istio/pkg/test/framework/components/namespace"
+	"istio.io/istio/pkg/test/framework/resource"
+)
+
+const (
+	PodASvc          = "a"
+	PodBSvc          = "b"
+	PodCSvc          = "c"
+	PodTproxySvc     = "tproxy"
+	VMSvc            = "vm"
+	HeadlessSvc      = "headless"
+	StatefulSetSvc   = "statefulset"
+	ProxylessGRPCSvc = "proxyless-grpc"
+	NakedSvc         = "naked"
+	ExternalSvc      = "external"
+	DeltaSvc         = "delta"
+	externalHostname = "fake.external.com"
+)
+
+type Namespace struct {
+	// Namespace echo apps will be deployed
+	Namespace namespace.Instance
+
+	// Standard echo app to be used by tests
+	A echo.Instances
+	// Standard echo app to be used by tests
+	B echo.Instances
+	// Standard echo app to be used by tests
+	C echo.Instances
+	// Standard echo app with TPROXY interception mode to be used by tests
+	Tproxy echo.Instances
+	// Headless echo app to be used by tests
+	Headless echo.Instances
+	// StatefulSet echo app to be used by tests
+	StatefulSet echo.Instances
+	// ProxylessGRPC echo app to be used by tests
+	ProxylessGRPC echo.Instances
+	// Echo app to be used by tests, with no sidecar injected
+	Naked echo.Instances
+	// A virtual machine echo app (only deployed to one cluster)
+	VM echo.Instances
+	// DeltaXDS echo app uses the delta XDS protocol. This should be functionally equivalent to A.
+	DeltaXDS echo.Instances
+
+	// All echo apps in this namespace
+	All echo.Services
+}
+
+// ServiceNames returns the names of all services in this namespace.
+func (n Namespace) ServiceNames() []string {
+	out := make([]string, 0, len(n.All))
+	for _, n := range n.All.ServiceNames() {
+		out = append(out, n.Name)
+	}
+	sort.Strings(out)
+	return out
+}
+
+func (n *Namespace) loadValues(t resource.Context, echos echo.Instances, d *Echos) error {
+	ns := n.Namespace.Name()
+
+	all := func(is echo.Instances) echo.Instances {
+		if len(is) > 0 {
+			n.All = append(n.All, is)
+			return is
+		}
+		return nil
+	}
+
+	n.A = all(match.ServiceName(model.NamespacedName{Name: PodASvc, Namespace: ns}).GetMatches(echos))
+	n.B = all(match.ServiceName(model.NamespacedName{Name: PodBSvc, Namespace: ns}).GetMatches(echos))
+	n.C = all(match.ServiceName(model.NamespacedName{Name: PodCSvc, Namespace: ns}).GetMatches(echos))
+	n.Tproxy = all(match.ServiceName(model.NamespacedName{Name: PodTproxySvc, Namespace: ns}).GetMatches(echos))
+	n.Headless = all(match.ServiceName(model.NamespacedName{Name: HeadlessSvc, Namespace: ns}).GetMatches(echos))
+	n.StatefulSet = all(match.ServiceName(model.NamespacedName{Name: StatefulSetSvc, Namespace: ns}).GetMatches(echos))
+	n.Naked = all(match.ServiceName(model.NamespacedName{Name: NakedSvc, Namespace: ns}).GetMatches(echos))
+	n.ProxylessGRPC = all(match.ServiceName(model.NamespacedName{Name: ProxylessGRPCSvc, Namespace: ns}).GetMatches(echos))
+	if !t.Settings().Skip(echo.VM) {
+		n.VM = all(match.ServiceName(model.NamespacedName{Name: VMSvc, Namespace: ns}).GetMatches(echos))
+	}
+	if !skipDeltaXDS(t) {
+		n.DeltaXDS = all(match.ServiceName(model.NamespacedName{Name: DeltaSvc, Namespace: ns}).GetMatches(echos))
+	}
+
+	// Restrict egress from this namespace to only those endpoints in the same Echos.
+	if err := t.ConfigIstio().Eval(ns, map[string]interface{}{
+		"otherNS": d.namespaces(n.Namespace),
+	}, `
+apiVersion: networking.istio.io/v1alpha3
+kind: Sidecar
+metadata:
+  name: restrict-to-namespace
+spec:
+  egress:
+  - hosts:
+    - "./*"
+    - "istio-system/*"
+{{ range $ns := .otherNS }}
+    - "{{ $ns }}/*"
+{{ end }}
+`).Apply(resource.NoCleanup); err != nil {
+		return err
+	}
+
+	// Create a ServiceEntry to allow apps in this namespace to talk to the external service.
+	if err := t.ConfigIstio().Eval(ns, map[string]interface{}{
+		"Namespace": d.External.Namespace.Name(),
+		"Hostname":  externalHostname,
+		"Ports":     serviceEntryPorts(),
+	}, `apiVersion: networking.istio.io/v1alpha3
+kind: ServiceEntry
+metadata:
+  name: external-service
+spec:
+  hosts:
+  - {{.Hostname}}
+  location: MESH_EXTERNAL
+  resolution: DNS
+  endpoints:
+  - address: external.{{.Namespace}}.svc.cluster.local
+  ports:
+  - name: http-tls-origination
+    number: 8888
+    protocol: http
+    targetPort: 443
+  - name: http2-tls-origination
+    number: 8882
+    protocol: http2
+    targetPort: 443
+{{- range $i, $p := .Ports }}
+  - name: {{$p.Name}}
+    number: {{$p.ServicePort}}
+    protocol: "{{$p.Protocol}}"
+{{- end }}
+`).Apply(resource.NoCleanup); err != nil {
+		return err
+	}
+	return nil
+}
+
+type External struct {
+	// Namespace where external echo app will be deployed
+	Namespace namespace.Instance
+
+	// Echos app to be used by tests, with no sidecar injected
+	Echos echo.Instances
+}
+
+func (e *External) loadValues(echos echo.Instances) {
+	e.Echos = match.ServiceName(model.NamespacedName{Name: ExternalSvc, Namespace: e.Namespace.Name()}).GetMatches(echos)
+}
+
+// Echos is a common set of echo deployments to support integration testing.
+type Echos struct {
+	// Ingressgateway instance
+	Ingress   ingress.Instance
+	Ingresses ingress.Instances
+
+	// NS is the list of echo namespaces.
+	NS []Namespace
+
+	// External (out-of-mesh) deployments
+	External External
+
+	// All echo instances.
+	All echo.Services
+}
+
+// NS1 is shorthand for NS[0]
+func (d Echos) NS1() Namespace {
+	return d.NS[0]
+}
+
+// NS2 is shorthand for NS[1]. Will panic if there are not at least 2 apps namespaces.
+func (d Echos) NS2() Namespace {
+	return d.NS[1]
+}
+
+// NS1AndNS2 returns the combined set of services in NS1 and NS2.
+func (d Echos) NS1AndNS2() echo.Services {
+	return d.NS1().All.Append(d.NS2().All)
+}
+
+func (d *Echos) loadValues(t resource.Context, echos echo.Instances) error {
+	d.All = echos.Services()
+
+	for i := 0; i < len(d.NS); i++ {
+		if err := d.NS[i].loadValues(t, echos, d); err != nil {
+			return err
+		}
+	}
+
+	d.External.loadValues(echos)
+	return nil
+}
+
+func (d Echos) namespaces(excludes ...namespace.Instance) []string {
+	var out []string
+	for _, n := range d.NS {
+		include := true
+		for _, e := range excludes {
+			if n.Namespace.Name() == e.Name() {
+				include = false
+				break
+			}
+		}
+		if include {
+			out = append(out, n.Namespace.Name())
+		}
+	}
+
+	sort.Strings(out)
+	return out
+}
+
+func serviceEntryPorts() []echo.Port {
+	var res []echo.Port
+	for _, p := range ports.All().GetServicePorts() {
+		if strings.HasPrefix(p.Name, "auto") {
+			// The protocol needs to be set in common.EchoPorts to configure the echo deployment
+			// But for service entry, we want to ensure we set it to "" which will use sniffing
+			p.Protocol = ""
+		}
+		res = append(res, p)
+	}
+	return res
+}
+
+type Config struct {
+	NamespaceCount int
+}
+
+func (c *Config) fillDefaults() {
+	if c.NamespaceCount <= 1 {
+		c.NamespaceCount = 1
+	}
+}
+
+func Setup(t resource.Context, apps *Echos, cfg Config) error {
+	cfg.fillDefaults()
+
+	// Get the Istio component.
+	i, err := istio.Get(t)
+	if err != nil {
+		return err
+	}
+
+	// Create the namespaces concurrently.
+	g, _ := errgroup.WithContext(context.TODO())
+
+	// Create the echo namespaces.
+	apps.NS = make([]Namespace, cfg.NamespaceCount)
+	if cfg.NamespaceCount == 1 {
+		// If only using a single namespace, preserve the "echo" prefix.
+		g.Go(func() (err error) {
+			apps.NS[0].Namespace, err = namespace.New(t, namespace.Config{
+				Prefix: "echo",
+				Inject: true,
+			})
+			return
+		})
+	} else {
+		for i := 0; i < cfg.NamespaceCount; i++ {
+			i := i
+			g.Go(func() (err error) {
+				apps.NS[i].Namespace, err = namespace.New(t, namespace.Config{
+					Prefix: fmt.Sprintf("echo%d", i),
+					Inject: true,
+				})
+				return
+			})
+		}
+	}
+
+	// Create the external namespace.
+	g.Go(func() (err error) {
+		apps.External.Namespace, err = namespace.New(t, namespace.Config{
+			Prefix: "external",
+			Inject: false,
+		})
+		return
+	})
+
+	// Wait for the namespaces to be created.
+	if err := g.Wait(); err != nil {
+		return err
+	}
+
+	apps.Ingress = i.IngressFor(t.Clusters().Default())
+	apps.Ingresses = i.Ingresses()
+
+	builder := deployment.New(t).WithClusters(t.Clusters()...)
+	for _, n := range apps.NS {
+		builder = buildNamespace(t, builder, n.Namespace)
+	}
+	builder = buildExternal(builder, apps.External.Namespace)
+
+	echos, err := builder.Build()
+	if err != nil {
+		return err
+	}
+
+	// Load values from the deployed echo instances.
+	return apps.loadValues(t, echos)
+}
+
+// TODO: should t.Settings().Skip(echo.Delta) do all of this?
+func skipDeltaXDS(t resource.Context) bool {
+	return t.Settings().Skip(echo.Delta) || !t.Settings().Revisions.AtLeast("1.11")
+}
+
+func buildNamespace(t resource.Context, b deployment.Builder, ns namespace.Instance) deployment.Builder {
+	b = b.WithConfig(echo.Config{
+		Service:        PodASvc,
+		Namespace:      ns,
+		ServiceAccount: true,
+		Ports:          ports.All(),
+		Subsets:        []echo.SubsetConfig{{}},
+		Locality:       "region.zone.subzone",
+	}).
+		WithConfig(echo.Config{
+			Service:        PodBSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Ports:          ports.All(),
+			Subsets:        []echo.SubsetConfig{{}},
+		}).
+		WithConfig(echo.Config{
+			Service:        PodCSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Ports:          ports.All(),
+			Subsets:        []echo.SubsetConfig{{}},
+		}).
+		WithConfig(echo.Config{
+			Service:        HeadlessSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Headless:       true,
+			Ports:          ports.Headless(),
+			Subsets:        []echo.SubsetConfig{{}},
+		}).
+		WithConfig(echo.Config{
+			Service:        StatefulSetSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Headless:       true,
+			StatefulSet:    true,
+			Ports:          ports.Headless(),
+			Subsets:        []echo.SubsetConfig{{}},
+		}).
+		WithConfig(echo.Config{
+			Service:        NakedSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Ports:          ports.All(),
+			Subsets: []echo.SubsetConfig{
+				{
+					Annotations: map[echo.Annotation]*echo.AnnotationValue{
+						echo.SidecarInject: {
+							Value: strconv.FormatBool(false),
+						},
+					},
+				},
+			},
+		}).
+		WithConfig(echo.Config{
+			Service:        PodTproxySvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Ports:          ports.All(),
+			Subsets: []echo.SubsetConfig{{
+				Annotations: echo.NewAnnotations().Set(echo.SidecarInterceptionMode, "TPROXY"),
+			}},
+		}).
+		WithConfig(echo.Config{
+			Service:        VMSvc,
+			Namespace:      ns,
+			ServiceAccount: true,
+			Ports:          ports.All(),
+			DeployAsVM:     true,
+			AutoRegisterVM: true,
+			Subsets:        []echo.SubsetConfig{{}},
+		})
+
+	if !skipDeltaXDS(t) {
+		b = b.
+			WithConfig(echo.Config{
+				Service:        DeltaSvc,
+				Namespace:      ns,
+				ServiceAccount: true,
+				Ports:          ports.All(),
+				Subsets: []echo.SubsetConfig{{
+					Annotations: echo.NewAnnotations().Set(echo.SidecarProxyConfig, `proxyMetadata:
+  ISTIO_DELTA_XDS: "true"`),
+				}},
+			})
+	}
+
+	if !t.Clusters().IsMulticluster() {
+		b = b.
+			// TODO when agent handles secure control-plane connection for grpc-less, deploy to "remote" clusters
+			WithConfig(echo.Config{
+				Service:        ProxylessGRPCSvc,
+				Namespace:      ns,
+				ServiceAccount: true,
+				Ports:          ports.All(),
+				Subsets: []echo.SubsetConfig{
+					{
+						Annotations: map[echo.Annotation]*echo.AnnotationValue{
+							echo.SidecarInjectTemplates: {
+								Value: "grpc-agent",
+							},
+						},
+					},
+				},
+			})
+	}
+	return b
+}
+
+func buildExternal(b deployment.Builder, ns namespace.Instance) deployment.Builder {
+	return b.WithConfig(echo.Config{
+		Service:           ExternalSvc,
+		Namespace:         ns,
+		DefaultHostHeader: externalHostname,
+		Ports:             ports.All(),
+		Subsets: []echo.SubsetConfig{
+			{
+				Annotations: map[echo.Annotation]*echo.AnnotationValue{
+					echo.SidecarInject: {
+						Value: strconv.FormatBool(false),
+					},
+				},
+			},
+		},
+	})
+}
+
+// Restart restarts all echo deployments.
+func (d Echos) Restart() error {
+	wg := sync.WaitGroup{}
+	aggregateErrMux := &sync.Mutex{}
+	var aggregateErr error
+	for _, app := range d.All.Instances() {
+		app := app
+		wg.Add(1)
+		go func() {
+			defer wg.Done()
+
+			if err := app.Restart(); err != nil {
+				aggregateErrMux.Lock()
+				aggregateErr = multierror.Append(aggregateErr, err)
+				aggregateErrMux.Unlock()
+			}
+		}()
+	}
+	wg.Wait()
+	if aggregateErr != nil {
+		return aggregateErr
+	}
+	return nil
+}
diff --git a/pkg/test/framework/components/echo/common/ports/ports.go b/pkg/test/framework/components/echo/common/ports/ports.go
index fa0acbf501..6a2cc4574d 100644
--- a/pkg/test/framework/components/echo/common/ports/ports.go
+++ b/pkg/test/framework/components/echo/common/ports/ports.go
@@ -58,3 +58,14 @@ func All() echo.Ports {
 		{Name: HTTPWorkloadOnly, Protocol: protocol.HTTP, ServicePort: echo.NoServicePort, WorkloadPort: 18083},
 	}
 }
+
+// Headless returns a modified version of All for use with headless services.
+func Headless() echo.Ports {
+	all := All()
+	headlessPorts := make([]echo.Port, len(all))
+	for i, p := range all {
+		p.ServicePort = p.WorkloadPort
+		headlessPorts[i] = p
+	}
+	return headlessPorts
+}
diff --git a/pkg/test/framework/components/echo/deployment/builder.go b/pkg/test/framework/components/echo/deployment/builder.go
index 3f9635f736..d43b8c8766 100644
--- a/pkg/test/framework/components/echo/deployment/builder.go
+++ b/pkg/test/framework/components/echo/deployment/builder.go
@@ -260,7 +260,7 @@ func build(b builder) (out echo.Instances, err error) {
 			scopes.Framework.Error("=== FAILED: Deploy echo instances ===")
 			scopes.Framework.Error(err)
 		} else {
-			scopes.Framework.Infof("=== SUCCEEDED: Deploy echo instances in %f ===", time.Since(start).Seconds())
+			scopes.Framework.Infof("=== SUCCEEDED: Deploy echo instances in %v ===", time.Since(start))
 		}
 	}()
 
diff --git a/pkg/test/framework/components/echo/echotest/filters.go b/pkg/test/framework/components/echo/echotest/filters.go
index 00181ee377..5100fbbdd8 100644
--- a/pkg/test/framework/components/echo/echotest/filters.go
+++ b/pkg/test/framework/components/echo/echotest/filters.go
@@ -98,7 +98,7 @@ func (t *T) applyCombinationFilters(from echo.Instance, to echo.Instances) echo.
 // TODO this name is not good
 func SingleSimplePodServiceAndAllSpecial(exclude ...echo.Instance) Filter {
 	return func(instances echo.Instances) echo.Instances {
-		return oneRegularPodPerNamespace(exclude)(instances).Append(notRegularPods()(instances)...)
+		return oneRegularPodPerNamespace(exclude)(instances).Append(notRegularPods()(instances))
 	}
 }
 
@@ -107,7 +107,7 @@ func oneRegularPodPerNamespace(exclude echo.Instances) Filter {
 		// Apply the filters.
 		regularPods := match.And(
 			match.RegularPod,
-			match.Not(match.AnyServiceName(exclude))).GetMatches(instances)
+			match.Not(match.AnyServiceName(exclude...))).GetMatches(instances)
 
 		if len(regularPods) == 0 {
 			return regularPods
diff --git a/pkg/test/framework/components/echo/instances.go b/pkg/test/framework/components/echo/instances.go
index c3e16bcba8..4ac896f051 100644
--- a/pkg/test/framework/components/echo/instances.go
+++ b/pkg/test/framework/components/echo/instances.go
@@ -148,8 +148,12 @@ func (i Instances) Services() Services {
 	return out
 }
 
-// Append the given instances together at the end of this Instances and return a new Instances.
-// Does not modify this Instances.
-func (i Instances) Append(instances ...Instance) Instances {
-	return append(append(Instances{}, i...), instances...)
+// Copy this Instances array.
+func (i Instances) Copy() Instances {
+	return append(Instances{}, i...)
+}
+
+// Append returns a new Instances array with the given values appended.
+func (i Instances) Append(instances Instances) Instances {
+	return append(i.Copy(), instances...)
 }
diff --git a/pkg/test/framework/components/echo/match/matchers.go b/pkg/test/framework/components/echo/match/matchers.go
index a20d714384..97da70c516 100644
--- a/pkg/test/framework/components/echo/match/matchers.go
+++ b/pkg/test/framework/components/echo/match/matchers.go
@@ -65,8 +65,8 @@ func ServiceName(n model.NamespacedName) Matcher {
 }
 
 // AnyServiceName matches instances if they have the same Service and Namespace as any of the provided instances.
-func AnyServiceName(expected echo.Instances) Matcher {
-	expectedNames := expected.Services().ServiceNames()
+func AnyServiceName(expected ...echo.Instance) Matcher {
+	expectedNames := echo.Instances(expected).Services().ServiceNames()
 	return func(instance echo.Instance) bool {
 		serviceName := instance.NamespacedName()
 		for _, expectedName := range expectedNames {
diff --git a/pkg/test/framework/components/echo/services.go b/pkg/test/framework/components/echo/services.go
index 45c13d46f5..f228329e5b 100644
--- a/pkg/test/framework/components/echo/services.go
+++ b/pkg/test/framework/components/echo/services.go
@@ -126,3 +126,17 @@ func (d Services) Less(i, j int) bool {
 func (d Services) Swap(i, j int) {
 	d[i], d[j] = d[j], d[i]
 }
+
+// Copy this services array.
+func (d Services) Copy() Services {
+	return append(Services{}, d...)
+}
+
+// Append returns a new Services array with the given values appended.
+func (d Services) Append(others ...Services) Services {
+	out := d.Copy()
+	for _, o := range others {
+		out = append(out, o...)
+	}
+	return out
+}
diff --git a/tests/integration/pilot/cni/cniversionskew_test.go b/tests/integration/pilot/cni/cniversionskew_test.go
index 6762c912a7..844e64fbe5 100644
--- a/tests/integration/pilot/cni/cniversionskew_test.go
+++ b/tests/integration/pilot/cni/cniversionskew_test.go
@@ -25,6 +25,7 @@
 
 	"istio.io/istio/pkg/test/env"
 	"istio.io/istio/pkg/test/framework"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/istio"
 	"istio.io/istio/pkg/test/framework/label"
 	"istio.io/istio/pkg/test/framework/resource"
@@ -37,7 +38,7 @@
 var (
 	i istio.Instance
 
-	apps = &common.EchoDeployments{}
+	apps = deployment.Echos{}
 )
 
 const (
@@ -86,7 +87,7 @@ func TestCNIVersionSkew(t *testing.T) {
 				if err := apps.Restart(); err != nil {
 					t.Fatalf("Failed to restart apps %v", err)
 				}
-				common.RunAllTrafficTests(t, i, apps)
+				common.RunAllTrafficTests(t, i, &apps)
 			}
 		})
 }
@@ -100,7 +101,7 @@ func TestMain(m *testing.M) {
 		RequireMultiPrimary().
 		Setup(istio.Setup(&i, nil)).
 		Setup(func(t resource.Context) error {
-			return common.SetupApps(t, i, apps)
+			return deployment.Setup(t, &apps, deployment.Config{})
 		}).
 		Run()
 }
diff --git a/tests/integration/pilot/common/apps.go b/tests/integration/pilot/common/apps.go
deleted file mode 100644
index 7931ca08ec..0000000000
--- a/tests/integration/pilot/common/apps.go
+++ /dev/null
@@ -1,339 +0,0 @@
-//go:build integ
-// +build integ
-
-// Copyright Istio Authors
-//
-// Licensed under the Apache License, Version 2.0 (the "License");
-// you may not use this file except in compliance with the License.
-// You may obtain a copy of the License at
-//
-//     http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software
-// distributed under the License is distributed on an "AS IS" BASIS,
-// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-// See the License for the specific language governing permissions and
-// limitations under the License.
-
-package common
-
-import (
-	"strconv"
-	"strings"
-	"sync"
-
-	"github.com/hashicorp/go-multierror"
-
-	"istio.io/istio/pilot/pkg/model"
-	"istio.io/istio/pkg/test/framework/components/echo"
-	"istio.io/istio/pkg/test/framework/components/echo/common/ports"
-	"istio.io/istio/pkg/test/framework/components/echo/deployment"
-	"istio.io/istio/pkg/test/framework/components/echo/match"
-	"istio.io/istio/pkg/test/framework/components/istio"
-	"istio.io/istio/pkg/test/framework/components/istio/ingress"
-	"istio.io/istio/pkg/test/framework/components/namespace"
-	"istio.io/istio/pkg/test/framework/resource"
-	"istio.io/istio/pkg/test/util/tmpl"
-)
-
-type EchoDeployments struct {
-	// Namespace echo apps will be deployed
-	Namespace namespace.Instance
-	// Namespace where external echo app will be deployed
-	ExternalNamespace namespace.Instance
-
-	// Ingressgateway instance
-	Ingress   ingress.Instance
-	Ingresses ingress.Instances
-
-	// Standard echo app to be used by tests
-	PodA echo.Instances
-	// Standard echo app to be used by tests
-	PodB echo.Instances
-	// Standard echo app to be used by tests
-	PodC echo.Instances
-	// Standard echo app with TPROXY interception mode to be used by tests
-	PodTproxy echo.Instances
-	// Headless echo app to be used by tests
-	Headless echo.Instances
-	// StatefulSet echo app to be used by tests
-	StatefulSet echo.Instances
-	// ProxylessGRPC echo app to be used by tests
-	ProxylessGRPC echo.Instances
-	// Echo app to be used by tests, with no sidecar injected
-	Naked echo.Instances
-	// A virtual machine echo app (only deployed to one cluster)
-	VM echo.Instances
-	// DeltaXDS echo app uses the delta XDS protocol. This should be functionally equivalent to PodA.
-	DeltaXDS echo.Instances
-
-	// Echo app to be used by tests, with no sidecar injected
-	External echo.Instances
-
-	All echo.Instances
-}
-
-const (
-	PodASvc          = "a"
-	PodBSvc          = "b"
-	PodCSvc          = "c"
-	PodTproxySvc     = "tproxy"
-	VMSvc            = "vm"
-	HeadlessSvc      = "headless"
-	StatefulSetSvc   = "statefulset"
-	ProxylessGRPCSvc = "proxyless-grpc"
-	NakedSvc         = "naked"
-	ExternalSvc      = "external"
-	DeltaSvc         = "delta"
-
-	externalHostname = "fake.external.com"
-)
-
-func serviceEntryPorts() []echo.Port {
-	var res []echo.Port
-	for _, p := range ports.All().GetServicePorts() {
-		if strings.HasPrefix(p.Name, "auto") {
-			// The protocol needs to be set in common.EchoPorts to configure the echo deployment
-			// But for service entry, we want to ensure we set it to "" which will use sniffing
-			p.Protocol = ""
-		}
-		res = append(res, p)
-	}
-	return res
-}
-
-func SetupApps(t resource.Context, i istio.Instance, apps *EchoDeployments) error {
-	var err error
-	apps.Namespace, err = namespace.New(t, namespace.Config{
-		Prefix: "echo",
-		Inject: true,
-	})
-	if err != nil {
-		return err
-	}
-	apps.ExternalNamespace, err = namespace.New(t, namespace.Config{
-		Prefix: "external",
-		Inject: false,
-	})
-	if err != nil {
-		return err
-	}
-
-	apps.Ingress = i.IngressFor(t.Clusters().Default())
-	apps.Ingresses = i.Ingresses()
-
-	// Headless services don't work with targetPort, set to same port
-	headlessPorts := make([]echo.Port, len(ports.All()))
-	for i, p := range ports.All() {
-		p.ServicePort = p.WorkloadPort
-		headlessPorts[i] = p
-	}
-	builder := deployment.New(t).
-		WithClusters(t.Clusters()...).
-		WithConfig(echo.Config{
-			Service:   PodASvc,
-			Namespace: apps.Namespace,
-			Ports:     ports.All(),
-			Subsets:   []echo.SubsetConfig{{}},
-			Locality:  "region.zone.subzone",
-		}).
-		WithConfig(echo.Config{
-			Service:   PodBSvc,
-			Namespace: apps.Namespace,
-			Ports:     ports.All(),
-			Subsets:   []echo.SubsetConfig{{}},
-		}).
-		WithConfig(echo.Config{
-			Service:   PodCSvc,
-			Namespace: apps.Namespace,
-			Ports:     ports.All(),
-			Subsets:   []echo.SubsetConfig{{}},
-		}).
-		WithConfig(echo.Config{
-			Service:   HeadlessSvc,
-			Headless:  true,
-			Namespace: apps.Namespace,
-			Ports:     headlessPorts,
-			Subsets:   []echo.SubsetConfig{{}},
-		}).
-		WithConfig(echo.Config{
-			Service:     StatefulSetSvc,
-			Headless:    true,
-			StatefulSet: true,
-			Namespace:   apps.Namespace,
-			Ports:       headlessPorts,
-			Subsets:     []echo.SubsetConfig{{}},
-		}).
-		WithConfig(echo.Config{
-			Service:   NakedSvc,
-			Namespace: apps.Namespace,
-			Ports:     ports.All(),
-			Subsets: []echo.SubsetConfig{
-				{
-					Annotations: map[echo.Annotation]*echo.AnnotationValue{
-						echo.SidecarInject: {
-							Value: strconv.FormatBool(false),
-						},
-					},
-				},
-			},
-		}).
-		WithConfig(echo.Config{
-			Service:           ExternalSvc,
-			Namespace:         apps.ExternalNamespace,
-			DefaultHostHeader: externalHostname,
-			Ports:             ports.All(),
-			Subsets: []echo.SubsetConfig{
-				{
-					Annotations: map[echo.Annotation]*echo.AnnotationValue{
-						echo.SidecarInject: {
-							Value: strconv.FormatBool(false),
-						},
-					},
-				},
-			},
-		}).
-		WithConfig(echo.Config{
-			Service:   PodTproxySvc,
-			Namespace: apps.Namespace,
-			Ports:     ports.All(),
-			Subsets: []echo.SubsetConfig{{
-				Annotations: echo.NewAnnotations().Set(echo.SidecarInterceptionMode, "TPROXY"),
-			}},
-		}).
-		WithConfig(echo.Config{
-			Service:        VMSvc,
-			Namespace:      apps.Namespace,
-			Ports:          ports.All(),
-			DeployAsVM:     true,
-			AutoRegisterVM: true,
-			Subsets:        []echo.SubsetConfig{{}},
-		})
-
-	skipDelta := t.Settings().Skip(echo.Delta) || !t.Settings().Revisions.AtLeast("1.12")
-	if !skipDelta {
-		builder = builder.
-			WithConfig(echo.Config{
-				Service:   DeltaSvc,
-				Namespace: apps.Namespace,
-				Ports:     ports.All(),
-				Subsets: []echo.SubsetConfig{{
-					Annotations: echo.NewAnnotations().Set(echo.SidecarProxyConfig, `proxyMetadata:
-  ISTIO_DELTA_XDS: "true"`),
-				}},
-			})
-	}
-
-	if !t.Clusters().IsMulticluster() {
-		builder = builder.
-			// TODO when agent handles secure control-plane connection for grpc-less, deploy to "remote" clusters
-			WithConfig(echo.Config{
-				Service:   ProxylessGRPCSvc,
-				Namespace: apps.Namespace,
-				Ports:     ports.All(),
-				Subsets: []echo.SubsetConfig{
-					{
-						Annotations: map[echo.Annotation]*echo.AnnotationValue{
-							echo.SidecarInjectTemplates: {
-								Value: "grpc-agent",
-							},
-						},
-					},
-				},
-			})
-	}
-
-	echos, err := builder.Build()
-	if err != nil {
-		return err
-	}
-	apps.All = echos
-	apps.PodA = match.ServiceName(model.NamespacedName{Name: PodASvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.PodB = match.ServiceName(model.NamespacedName{Name: PodBSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.PodC = match.ServiceName(model.NamespacedName{Name: PodCSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.PodTproxy = match.ServiceName(model.NamespacedName{Name: PodTproxySvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.Headless = match.ServiceName(model.NamespacedName{Name: HeadlessSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.StatefulSet = match.ServiceName(model.NamespacedName{Name: StatefulSetSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.Naked = match.ServiceName(model.NamespacedName{Name: NakedSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	apps.External = match.ServiceName(model.NamespacedName{Name: ExternalSvc, Namespace: apps.ExternalNamespace.Name()}).GetMatches(echos)
-	apps.ProxylessGRPC = match.ServiceName(model.NamespacedName{Name: ProxylessGRPCSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	if !t.Settings().Skip(echo.VM) {
-		apps.VM = match.ServiceName(model.NamespacedName{Name: VMSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	}
-	if !skipDelta {
-		apps.DeltaXDS = match.ServiceName(model.NamespacedName{Name: DeltaSvc, Namespace: apps.Namespace.Name()}).GetMatches(echos)
-	}
-
-	if err := t.ConfigIstio().YAML(apps.Namespace.Name(), `
-apiVersion: networking.istio.io/v1alpha3
-kind: Sidecar
-metadata:
-  name: restrict-to-namespace
-spec:
-  egress:
-  - hosts:
-    - "./*"
-    - "istio-system/*"
-`).Apply(resource.NoCleanup); err != nil {
-		return err
-	}
-
-	se, err := tmpl.Evaluate(`apiVersion: networking.istio.io/v1alpha3
-kind: ServiceEntry
-metadata:
-  name: external-service
-spec:
-  hosts:
-  - {{.Hostname}}
-  location: MESH_EXTERNAL
-  resolution: DNS
-  endpoints:
-  - address: external.{{.Namespace}}.svc.cluster.local
-  ports:
-  - name: http-tls-origination
-    number: 8888
-    protocol: http
-    targetPort: 443
-  - name: http2-tls-origination
-    number: 8882
-    protocol: http2
-    targetPort: 443
-{{- range $i, $p := .Ports }}
-  - name: {{$p.Name}}
-    number: {{$p.ServicePort}}
-    protocol: "{{$p.Protocol}}"
-{{- end }}
-`, map[string]interface{}{"Namespace": apps.ExternalNamespace.Name(), "Hostname": externalHostname, "Ports": serviceEntryPorts()})
-	if err != nil {
-		return err
-	}
-	if err := t.ConfigIstio().YAML(apps.Namespace.Name(), se).Apply(resource.NoCleanup); err != nil {
-		return err
-	}
-	return nil
-}
-
-// Restart restarts all echo deployments.
-func (d EchoDeployments) Restart() error {
-	wg := sync.WaitGroup{}
-	aggregateErrMux := &sync.Mutex{}
-	var aggregateErr error
-	for _, app := range d.All {
-		app := app
-		wg.Add(1)
-		go func() {
-			defer wg.Done()
-
-			if err := app.Restart(); err != nil {
-				aggregateErrMux.Lock()
-				aggregateErr = multierror.Append(aggregateErr, err)
-				aggregateErrMux.Unlock()
-			}
-		}()
-	}
-	wg.Wait()
-	if aggregateErr != nil {
-		return aggregateErr
-	}
-	return nil
-}
diff --git a/tests/integration/pilot/common/routing.go b/tests/integration/pilot/common/routing.go
index 112d845ae1..2996208369 100644
--- a/tests/integration/pilot/common/routing.go
+++ b/tests/integration/pilot/common/routing.go
@@ -41,6 +41,7 @@
 	"istio.io/istio/pkg/test/echo/common/scheme"
 	epb "istio.io/istio/pkg/test/echo/proto"
 	"istio.io/istio/pkg/test/framework/components/echo"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/echo/common/ports"
 	"istio.io/istio/pkg/test/framework/components/echo/echotest"
 	"istio.io/istio/pkg/test/framework/components/echo/match"
@@ -762,7 +763,7 @@ func HostHeader(header string) http.Header {
 }
 
 // tlsOriginationCases contains tests TLS origination from DestinationRule
-func tlsOriginationCases(apps *EchoDeployments) []TrafficTestCase {
+func tlsOriginationCases(apps *deployment.Echos) []TrafficTestCase {
 	tc := TrafficTestCase{
 		name: "",
 		config: fmt.Sprintf(`
@@ -775,7 +776,7 @@ func tlsOriginationCases(apps *EchoDeployments) []TrafficTestCase {
   trafficPolicy:
     tls:
       mode: SIMPLE
-`, apps.External[0].Config().DefaultHostHeader),
+`, apps.External.Echos.Config().DefaultHostHeader),
 		children: []TrafficCall{},
 	}
 	expects := []struct {
@@ -785,7 +786,7 @@ func tlsOriginationCases(apps *EchoDeployments) []TrafficTestCase {
 		{8888, "http/1.1"},
 		{8882, "h2"},
 	}
-	for _, c := range apps.PodA {
+	for _, c := range apps.NS1().A {
 		for _, e := range expects {
 			c := c
 			e := e
@@ -795,9 +796,9 @@ func tlsOriginationCases(apps *EchoDeployments) []TrafficTestCase {
 				opts: echo.CallOptions{
 					Port:    echo.Port{ServicePort: e.port, Protocol: protocol.HTTP},
 					Count:   1,
-					Address: apps.External[0].Address(),
+					Address: apps.External.Echos[0].Address(),
 					HTTP: echo.HTTP{
-						Headers: HostHeader(apps.External[0].Config().DefaultHostHeader),
+						Headers: HostHeader(apps.External.Echos[0].Config().DefaultHostHeader),
 					},
 					Scheme: scheme.HTTP,
 					Check: check.And(
@@ -812,10 +813,10 @@ func tlsOriginationCases(apps *EchoDeployments) []TrafficTestCase {
 }
 
 // useClientProtocolCases contains tests use_client_protocol from DestinationRule
-func useClientProtocolCases(apps *EchoDeployments) []TrafficTestCase {
+func useClientProtocolCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
-	client := apps.PodA
-	to := apps.PodC
+	client := apps.NS1().A
+	to := apps.NS1().C
 	cases = append(cases,
 		TrafficTestCase{
 			name:   "use client protocol with h2",
@@ -861,10 +862,10 @@ func useClientProtocolCases(apps *EchoDeployments) []TrafficTestCase {
 }
 
 // destinationRuleCases contains tests some specific DestinationRule tests.
-func destinationRuleCases(apps *EchoDeployments) []TrafficTestCase {
+func destinationRuleCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
-	from := apps.PodA
-	to := apps.PodC
+	from := apps.NS1().A
+	to := apps.NS1().C
 	cases = append(cases,
 		// Validates the config is generated correctly when only idletimeout is specified in DR.
 		TrafficTestCase{
@@ -889,10 +890,10 @@ func destinationRuleCases(apps *EchoDeployments) []TrafficTestCase {
 }
 
 // trafficLoopCases contains tests to ensure traffic does not loop through the sidecar
-func trafficLoopCases(apps *EchoDeployments) []TrafficTestCase {
+func trafficLoopCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
-	for _, c := range apps.PodA {
-		for _, d := range apps.PodB {
+	for _, c := range apps.NS1().A {
+		for _, d := range apps.NS1().B {
 			for _, port := range []string{"15001", "15006"} {
 				c, d, port := c, d, port
 				cases = append(cases, TrafficTestCase{
@@ -919,14 +920,14 @@ func trafficLoopCases(apps *EchoDeployments) []TrafficTestCase {
 }
 
 // autoPassthroughCases tests that we cannot hit unexpected destinations when using AUTO_PASSTHROUGH
-func autoPassthroughCases(apps *EchoDeployments) []TrafficTestCase {
+func autoPassthroughCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
 	// We test the cross product of all Istio ALPNs (or no ALPN), all mTLS modes, and various backends
 	alpns := []string{"istio", "istio-peer-exchange", "istio-http/1.0", "istio-http/1.1", "istio-h2", ""}
 	modes := []string{"STRICT", "PERMISSIVE", "DISABLE"}
 
-	mtlsHost := host.Name(apps.PodA[0].Config().ClusterLocalFQDN())
-	nakedHost := host.Name(apps.Naked[0].Config().ClusterLocalFQDN())
+	mtlsHost := host.Name(apps.NS1().A.Config().ClusterLocalFQDN())
+	nakedHost := host.Name(apps.NS1().Naked.Config().ClusterLocalFQDN())
 	httpsPort := ports.All().MustForName("https").ServicePort
 	httpsAutoPort := ports.All().MustForName("auto-https").ServicePort
 	snis := []string{
@@ -1485,11 +1486,11 @@ func gatewayCases() []TrafficTestCase {
 	return cases
 }
 
-func XFFGatewayCase(apps *EchoDeployments, gateway string) []TrafficTestCase {
+func XFFGatewayCase(apps *deployment.Echos, gateway string) []TrafficTestCase {
 	var cases []TrafficTestCase
 
 	destinationSets := []echo.Instances{
-		apps.PodA,
+		apps.NS1().A,
 	}
 
 	for _, d := range destinationSets {
@@ -1501,7 +1502,7 @@ func XFFGatewayCase(apps *EchoDeployments, gateway string) []TrafficTestCase {
 		cases = append(cases, TrafficTestCase{
 			name:   d[0].Config().Service,
 			config: httpGateway("*") + httpVirtualService("gateway", fqdn, d[0].PortForName("http").ServicePort),
-			call:   apps.Naked[0].CallOrFail,
+			call:   apps.NS1().Naked[0].CallOrFail,
 			opts: echo.CallOptions{
 				Count:   1,
 				Port:    echo.Port{ServicePort: 80},
@@ -1540,7 +1541,7 @@ func(r echoClient.Response) error {
 	return cases
 }
 
-func envoyFilterCases(apps *EchoDeployments) []TrafficTestCase {
+func envoyFilterCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
 	// Test adding envoyfilter to inbound and outbound route/cluster/listeners
 	cfg := `
@@ -1638,12 +1639,12 @@ function envoy_on_request(request_handle)
       value:
         http2_protocol_options: {}
 `
-	for _, c := range apps.PodA {
+	for _, c := range apps.NS1().A {
 		cases = append(cases, TrafficTestCase{
 			config: cfg,
 			call:   c.CallOrFail,
 			opts: echo.CallOptions{
-				To: apps.PodB,
+				To: apps.NS1().B,
 				Port: echo.Port{
 					Name: "http",
 				},
@@ -1664,12 +1665,12 @@ function envoy_on_request(request_handle)
 }
 
 // hostCases tests different forms of host header to use
-func hostCases(apps *EchoDeployments) ([]TrafficTestCase, error) {
+func hostCases(apps *deployment.Echos) ([]TrafficTestCase, error) {
 	var cases []TrafficTestCase
-	for _, c := range apps.PodA {
-		cfg := apps.Headless[0].Config()
+	for _, c := range apps.NS1().A {
+		cfg := apps.NS1().Headless.Config()
 		port := ports.All().MustForName("auto-http").WorkloadPort
-		wl, err := apps.Headless[0].Workloads()
+		wl, err := apps.NS1().Headless[0].Workloads()
 		if err != nil {
 			return nil, err
 		}
@@ -1698,7 +1699,7 @@ func hostCases(apps *EchoDeployments) ([]TrafficTestCase, error) {
 				name: name,
 				call: c.CallOrFail,
 				opts: echo.CallOptions{
-					To: apps.Headless,
+					To: apps.NS1().Headless,
 					Port: echo.Port{
 						Name: "auto-http",
 					},
@@ -1731,7 +1732,7 @@ func hostCases(apps *EchoDeployments) ([]TrafficTestCase, error) {
 				name: name,
 				call: c.CallOrFail,
 				opts: echo.CallOptions{
-					To: apps.Headless,
+					To: apps.NS1().Headless,
 					Port: echo.Port{
 						Name: "http",
 					},
@@ -1757,9 +1758,9 @@ func hostCases(apps *EchoDeployments) ([]TrafficTestCase, error) {
 // 3) Another service, B', with P' -> T. In this case, the listener is shared. This is fine, with the exception of different protocols
 //    The cluster is distinct.
 // 4) Another service, B', with P' -> T'. There is no conflicts here at all.
-func serviceCases(apps *EchoDeployments) []TrafficTestCase {
+func serviceCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
-	for _, c := range apps.PodA {
+	for _, c := range apps.NS1().A {
 		c := c
 
 		// Case 1
@@ -1881,9 +1882,9 @@ func serviceCases(apps *EchoDeployments) []TrafficTestCase {
 }
 
 // consistentHashCases tests destination rule's consistent hashing mechanism
-func consistentHashCases(apps *EchoDeployments) []TrafficTestCase {
+func consistentHashCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
-	for _, app := range []echo.Instances{apps.PodA, apps.PodB} {
+	for _, app := range []echo.Instances{apps.NS1().A, apps.NS1().B} {
 		app := app
 		for _, c := range app {
 			c := c
@@ -2110,7 +2111,7 @@ func selfCallsCases() []TrafficTestCase {
 }
 
 // TODO: merge with security TestReachability code
-func protocolSniffingCases(apps *EchoDeployments) []TrafficTestCase {
+func protocolSniffingCases(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
 
 	type protocolCase struct {
@@ -2176,9 +2177,9 @@ type protocolCase struct {
 	// To simulate these, we use TCP and hand-craft the requests.
 	cases = append(cases, TrafficTestCase{
 		name: "http10 to http",
-		call: apps.PodA[0].CallOrFail,
+		call: apps.NS1().A[0].CallOrFail,
 		opts: echo.CallOptions{
-			To:    apps.PodB,
+			To:    apps.NS1().B,
 			Count: 1,
 			Port: echo.Port{
 				Name: "http",
@@ -2195,9 +2196,9 @@ type protocolCase struct {
 	},
 		TrafficTestCase{
 			name: "http10 to auto",
-			call: apps.PodA[0].CallOrFail,
+			call: apps.NS1().A[0].CallOrFail,
 			opts: echo.CallOptions{
-				To:    apps.PodB,
+				To:    apps.NS1().B,
 				Count: 1,
 				Port: echo.Port{
 					Name: "auto-http",
@@ -2214,11 +2215,11 @@ type protocolCase struct {
 		},
 		TrafficTestCase{
 			name: "http10 to external",
-			call: apps.PodA[0].CallOrFail,
+			call: apps.NS1().A[0].CallOrFail,
 			opts: echo.CallOptions{
-				Address: apps.External[0].Address(),
+				Address: apps.External.Echos[0].Address(),
 				HTTP: echo.HTTP{
-					Headers: HostHeader(apps.External[0].Config().DefaultHostHeader),
+					Headers: HostHeader(apps.External.Echos.Config().DefaultHostHeader),
 				},
 				Port:   httpPort,
 				Count:  1,
@@ -2234,11 +2235,11 @@ type protocolCase struct {
 		},
 		TrafficTestCase{
 			name: "http10 to external auto",
-			call: apps.PodA[0].CallOrFail,
+			call: apps.NS1().A[0].CallOrFail,
 			opts: echo.CallOptions{
-				Address: apps.External[0].Address(),
+				Address: apps.External.Echos[0].Address(),
 				HTTP: echo.HTTP{
-					Headers: HostHeader(apps.External[0].Config().DefaultHostHeader),
+					Headers: HostHeader(apps.External.Echos.Config().DefaultHostHeader),
 				},
 				Port:   autoPort,
 				Count:  1,
@@ -2278,7 +2279,7 @@ type protocolCase struct {
 }
 
 // Todo merge with security TestReachability code
-func instanceIPTests(apps *EchoDeployments) []TrafficTestCase {
+func instanceIPTests(apps *deployment.Echos) []TrafficTestCase {
 	var cases []TrafficTestCase
 	ipCases := []struct {
 		name            string
@@ -2371,10 +2372,10 @@ func instanceIPTests(apps *EchoDeployments) []TrafficTestCase {
 		},
 	}
 	for _, ipCase := range ipCases {
-		for _, client := range apps.PodA {
+		for _, client := range apps.NS1().A {
 			ipCase := ipCase
 			client := client
-			to := apps.PodB
+			to := apps.NS1().B
 			var config string
 			if !ipCase.disableSidecar {
 				config = fmt.Sprintf(`
@@ -2432,7 +2433,7 @@ type vmCase struct {
 	host string
 }
 
-func DNSTestCases(apps *EchoDeployments, cniEnabled bool) []TrafficTestCase {
+func DNSTestCases(apps *deployment.Echos, cniEnabled bool) []TrafficTestCase {
 	makeSE := func(ips ...string) string {
 		return tmpl.MustEvaluate(`
 apiVersion: networking.istio.io/v1alpha3
@@ -2512,7 +2513,7 @@ func DNSTestCases(apps *EchoDeployments, cniEnabled bool) []TrafficTestCase {
 			server:   dummyLocalhostServer,
 		},
 	}
-	for _, client := range flatten(apps.VM, apps.PodA, apps.PodTproxy) {
+	for _, client := range flatten(apps.NS1().VM, apps.NS1().A, apps.NS1().Tproxy) {
 		for _, tt := range cases {
 			if tt.skipCNI && cniEnabled {
 				continue
@@ -2563,13 +2564,13 @@ func DNSTestCases(apps *EchoDeployments, cniEnabled bool) []TrafficTestCase {
 			protocol: "udp",
 		},
 	}
-	for _, client := range flatten(apps.VM, apps.PodA, apps.PodTproxy) {
+	for _, client := range flatten(apps.NS1().VM, apps.NS1().A, apps.NS1().Tproxy) {
 		for _, tt := range svcCases {
 			tt, client := tt, client
-			aInCluster := match.Cluster(client.Config().Cluster).GetMatches(apps.PodA)
+			aInCluster := match.Cluster(client.Config().Cluster).GetMatches(apps.NS1().A)
 			if len(aInCluster) == 0 {
 				// The cluster doesn't contain A, but connects to a cluster containing A
-				aInCluster = match.Cluster(client.Config().Cluster.Config()).GetMatches(apps.PodA)
+				aInCluster = match.Cluster(client.Config().Cluster.Config()).GetMatches(apps.NS1().A)
 			}
 			address := aInCluster[0].Config().ClusterLocalFQDN() + "?"
 			if tt.protocol != "" {
@@ -2604,7 +2605,7 @@ func DNSTestCases(apps *EchoDeployments, cniEnabled bool) []TrafficTestCase {
 	return tcases
 }
 
-func VMTestCases(vms echo.Instances, apps *EchoDeployments) []TrafficTestCase {
+func VMTestCases(vms echo.Instances, apps *deployment.Echos) []TrafficTestCase {
 	var testCases []vmCase
 
 	for _, vm := range vms {
@@ -2612,32 +2613,32 @@ func VMTestCases(vms echo.Instances, apps *EchoDeployments) []TrafficTestCase {
 			vmCase{
 				name: "dns: VM to k8s cluster IP service name.namespace host",
 				from: vm,
-				to:   apps.PodA,
-				host: PodASvc + "." + apps.Namespace.Name(),
+				to:   apps.NS1().A,
+				host: deployment.PodASvc + "." + apps.NS1().Namespace.Name(),
 			},
 			vmCase{
 				name: "dns: VM to k8s cluster IP service fqdn host",
 				from: vm,
-				to:   apps.PodA,
-				host: apps.PodA[0].Config().ClusterLocalFQDN(),
+				to:   apps.NS1().A,
+				host: apps.NS1().A[0].Config().ClusterLocalFQDN(),
 			},
 			vmCase{
 				name: "dns: VM to k8s cluster IP service short name host",
 				from: vm,
-				to:   apps.PodA,
-				host: PodASvc,
+				to:   apps.NS1().A,
+				host: deployment.PodASvc,
 			},
 			vmCase{
 				name: "dns: VM to k8s headless service",
 				from: vm,
-				to:   match.Cluster(vm.Config().Cluster.Config()).GetMatches(apps.Headless),
-				host: apps.Headless[0].Config().ClusterLocalFQDN(),
+				to:   match.Cluster(vm.Config().Cluster.Config()).GetMatches(apps.NS1().Headless),
+				host: apps.NS1().Headless.Config().ClusterLocalFQDN(),
 			},
 			vmCase{
 				name: "dns: VM to k8s statefulset service",
 				from: vm,
-				to:   match.Cluster(vm.Config().Cluster.Config()).GetMatches(apps.StatefulSet),
-				host: apps.StatefulSet[0].Config().ClusterLocalFQDN(),
+				to:   match.Cluster(vm.Config().Cluster.Config()).GetMatches(apps.NS1().StatefulSet),
+				host: apps.NS1().StatefulSet.Config().ClusterLocalFQDN(),
 			},
 			// TODO(https://github.com/istio/istio/issues/32552) re-enable
 			//vmCase{
@@ -2666,7 +2667,7 @@ func VMTestCases(vms echo.Instances, apps *EchoDeployments) []TrafficTestCase {
 			//},
 		)
 	}
-	for _, podA := range apps.PodA {
+	for _, podA := range apps.NS1().A {
 		testCases = append(testCases, vmCase{
 			name: "k8s to vm",
 			from: podA,
@@ -2776,10 +2777,10 @@ func globalPeerAuthentication(mode string) string {
 `, mode)
 }
 
-func serverFirstTestCases(apps *EchoDeployments) []TrafficTestCase {
+func serverFirstTestCases(apps *deployment.Echos) []TrafficTestCase {
 	cases := make([]TrafficTestCase, 0)
-	from := apps.PodA
-	to := apps.PodC
+	from := apps.NS1().A
+	to := apps.NS1().C
 	configs := []struct {
 		port    string
 		dest    string
@@ -2820,7 +2821,7 @@ func serverFirstTestCases(apps *EchoDeployments) []TrafficTestCase {
 			cases = append(cases, TrafficTestCase{
 				name: fmt.Sprintf("%v:%v/%v", c.port, c.dest, c.auth),
 				skip: skip{
-					skip:   apps.All.Clusters().IsMulticluster(),
+					skip:   apps.NS1().All.Instances().Clusters().IsMulticluster(),
 					reason: "https://github.com/istio/istio/issues/37305: stabilize tcp connection breaks",
 				},
 				config: destinationRule(to.Config().Service, c.dest) + peerAuthentication(to.Config().Service, c.auth),
@@ -2843,7 +2844,7 @@ func serverFirstTestCases(apps *EchoDeployments) []TrafficTestCase {
 	return cases
 }
 
-func jwtClaimRoute(apps *EchoDeployments) []TrafficTestCase {
+func jwtClaimRoute(apps *deployment.Echos) []TrafficTestCase {
 	configRoute := `
 apiVersion: networking.istio.io/v1alpha3
 kind: Gateway
@@ -2904,7 +2905,7 @@ func jwtClaimRoute(apps *EchoDeployments) []TrafficTestCase {
     jwksUri: "https://raw.githubusercontent.com/istio/istio/master/tests/common/jwt/jwks.json"
 ---
 `
-	podB := []match.Matcher{match.ServiceName(apps.PodB.NamespacedName())}
+	podB := []match.Matcher{match.ServiceName(apps.NS1().B.NamespacedName())}
 	headersWithToken := map[string][]string{
 		"Host":          {"foo.bar"},
 		"Authorization": {"Bearer " + jwt.TokenIssuer1WithNestedClaims1},
diff --git a/tests/integration/pilot/common/traffic.go b/tests/integration/pilot/common/traffic.go
index f599641d05..f9aaa8a377 100644
--- a/tests/integration/pilot/common/traffic.go
+++ b/tests/integration/pilot/common/traffic.go
@@ -25,6 +25,7 @@
 	"istio.io/istio/pkg/test/echo/check"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/echo"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/echo/echotest"
 	"istio.io/istio/pkg/test/framework/components/echo/match"
 	"istio.io/istio/pkg/test/framework/components/istio"
@@ -234,7 +235,7 @@ func (c TrafficTestCase) Run(t framework.TestContext, namespace string) {
 	}
 }
 
-func RunAllTrafficTests(t framework.TestContext, i istio.Instance, apps *EchoDeployments) {
+func RunAllTrafficTests(t framework.TestContext, i istio.Instance, apps *deployment.Echos) {
 	cases := map[string][]TrafficTestCase{}
 	if !t.Settings().Selector.Excludes(label.NewSet(label.IPv4)) { // https://github.com/istio/istio/issues/35835
 		cases["jwt-claim-route"] = jwtClaimRoute(apps)
@@ -263,16 +264,16 @@ func RunAllTrafficTests(t framework.TestContext, i istio.Instance, apps *EchoDep
 	cases["use-client-protocol"] = useClientProtocolCases(apps)
 	cases["destinationrule"] = destinationRuleCases(apps)
 	if !t.Settings().Skip(echo.VM) {
-		cases["vm"] = VMTestCases(apps.VM, apps)
+		cases["vm"] = VMTestCases(apps.NS1().VM, apps)
 	}
 	cases["dns"] = DNSTestCases(apps, i.Settings().EnableCNI)
 	for name, tts := range cases {
 		t.NewSubTest(name).Run(func(t framework.TestContext) {
 			for _, tt := range tts {
 				if tt.workloadAgnostic {
-					tt.RunForApps(t, apps.All, apps.Namespace.Name())
+					tt.RunForApps(t, apps.All.Instances(), apps.NS1().Namespace.Name())
 				} else {
-					tt.Run(t, apps.Namespace.Name())
+					tt.Run(t, apps.NS1().Namespace.Name())
 				}
 			}
 		})
diff --git a/tests/integration/pilot/cross_revision_test.go b/tests/integration/pilot/cross_revision_test.go
index 2c6263048d..f594849b1a 100644
--- a/tests/integration/pilot/cross_revision_test.go
+++ b/tests/integration/pilot/cross_revision_test.go
@@ -58,7 +58,7 @@ func TestRevisionTraffic(t *testing.T) {
 				})
 			}
 			// Allow all namespaces so we do not hit passthrough cluster
-			t.ConfigIstio().YAML(apps.Namespace.Name(), `apiVersion: networking.istio.io/v1alpha3
+			t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), `apiVersion: networking.istio.io/v1alpha3
 kind: Sidecar
 metadata:
   name: allow-cross-namespaces
@@ -82,7 +82,7 @@ func TestRevisionTraffic(t *testing.T) {
 			}
 			instances := builder.BuildOrFail(t)
 			// Add our existing revision to the instances list
-			instances = append(instances, apps.PodA...)
+			instances = append(instances, apps.NS1().A...)
 			testAllEchoCalls(t, instances)
 		})
 }
diff --git a/tests/integration/pilot/endpointslice/endpointslice_test.go b/tests/integration/pilot/endpointslice/endpointslice_test.go
index ce03096e58..fcba557eb2 100644
--- a/tests/integration/pilot/endpointslice/endpointslice_test.go
+++ b/tests/integration/pilot/endpointslice/endpointslice_test.go
@@ -23,6 +23,7 @@
 
 	kubelib "istio.io/istio/pkg/kube"
 	"istio.io/istio/pkg/test/framework"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/istio"
 	"istio.io/istio/pkg/test/framework/resource"
 	"istio.io/istio/tests/integration/pilot/common"
@@ -34,7 +35,7 @@
 	// Below are various preconfigured echo deployments. Whenever possible, tests should utilize these
 	// to avoid excessive creation/tear down of deployments. In general, a test should only deploy echo if
 	// its doing something unique to that specific test.
-	apps = &common.EchoDeployments{}
+	apps = deployment.Echos{}
 )
 
 func TestMain(m *testing.M) {
@@ -53,7 +54,7 @@ func TestMain(m *testing.M) {
 				kubelib.IsLessThanVersion(t.Clusters().Kube().Default(), 21))
 		})).
 		Setup(func(t resource.Context) error {
-			return common.SetupApps(t, i, apps)
+			return deployment.Setup(t, &apps, deployment.Config{})
 		}).
 		Run()
 }
@@ -63,6 +64,6 @@ func TestTraffic(t *testing.T) {
 		NewTest(t).
 		Features("traffic.routing", "traffic.reachability", "traffic.shifting").
 		Run(func(t framework.TestContext) {
-			common.RunAllTrafficTests(t, i, apps)
+			common.RunAllTrafficTests(t, i, &apps)
 		})
 }
diff --git a/tests/integration/pilot/gw_topology_test.go b/tests/integration/pilot/gw_topology_test.go
index 096c38f90a..0878d6da5c 100644
--- a/tests/integration/pilot/gw_topology_test.go
+++ b/tests/integration/pilot/gw_topology_test.go
@@ -96,8 +96,8 @@ func TestXFFGateway(t *testing.T) {
 				_, err := kubetest.CheckPodsAreReady(kubetest.NewPodFetch(cs, gatewayNs.Name(), "istio=ingressgateway"))
 				return err
 			}, retry.Timeout(time.Minute*2), retry.Delay(time.Second))
-			for _, tt := range common.XFFGatewayCase(apps, fmt.Sprintf("custom-gateway.%s.svc.cluster.local", gatewayNs.Name())) {
-				tt.Run(t, apps.Namespace.Name())
+			for _, tt := range common.XFFGatewayCase(&apps, fmt.Sprintf("custom-gateway.%s.svc.cluster.local", gatewayNs.Name())) {
+				tt.Run(t, apps.NS1().Namespace.Name())
 			}
 		})
 }
diff --git a/tests/integration/pilot/ingress_test.go b/tests/integration/pilot/ingress_test.go
index 3ae3a63a5a..574939f7e2 100644
--- a/tests/integration/pilot/ingress_test.go
+++ b/tests/integration/pilot/ingress_test.go
@@ -123,11 +123,11 @@ func TestGateway(t *testing.T) {
       certificateRefs:
       - kind: Secret
         name: test-gateway-cert-same
----`, apps.Namespace.Name())).Apply()
+---`, apps.NS1().Namespace.Name())).Apply()
 				return err
 			}, retry.Delay(time.Second*10), retry.Timeout(time.Second*90))
 			retry.UntilSuccessOrFail(t, func() error {
-				err := t.ConfigIstio().YAML(apps.Namespace.Name(), `
+				err := t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), `
 apiVersion: gateway.networking.k8s.io/v1alpha2
 kind: HTTPRoute
 metadata:
@@ -216,8 +216,8 @@ func TestGateway(t *testing.T) {
 						})
 					})
 					t.NewSubTest("mesh").Run(func(t framework.TestContext) {
-						_ = apps.PodA[0].CallOrFail(t, echo.CallOptions{
-							To: apps.PodB,
+						_ = apps.NS1().A[0].CallOrFail(t, echo.CallOptions{
+							To: apps.NS1().B,
 							Port: echo.Port{
 								Name: "http",
 							},
@@ -244,7 +244,7 @@ func TestGateway(t *testing.T) {
 				})
 			}
 			t.NewSubTest("managed").Run(func(t framework.TestContext) {
-				t.ConfigIstio().YAML(apps.Namespace.Name(), `apiVersion: gateway.networking.k8s.io/v1alpha2
+				t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), `apiVersion: gateway.networking.k8s.io/v1alpha2
 kind: Gateway
 metadata:
   name: gateway
@@ -268,13 +268,13 @@ func TestGateway(t *testing.T) {
     - name: b
       port: 80
 `).ApplyOrFail(t)
-				apps.PodB[0].CallOrFail(t, echo.CallOptions{
+				apps.NS1().B[0].CallOrFail(t, echo.CallOptions{
 					Port:   echo.Port{ServicePort: 80},
 					Scheme: scheme.HTTP,
 					HTTP: echo.HTTP{
 						Headers: headers.New().WithHost("bar.example.com").Build(),
 					},
-					Address: fmt.Sprintf("gateway.%s.svc.cluster.local", apps.Namespace.Name()),
+					Address: fmt.Sprintf("gateway.%s.svc.cluster.local", apps.NS1().Namespace.Name()),
 					Check:   check.OK(),
 					Retry: echo.Retry{
 						Options: []retry.Option{retry.Timeout(time.Minute)},
@@ -382,7 +382,7 @@ func TestIngress(t *testing.T) {
 `
 			}
 
-			successChecker := check.And(check.OK(), check.ReachedClusters(apps.PodB.Clusters()))
+			successChecker := check.And(check.OK(), check.ReachedClusters(apps.NS1().B.Clusters()))
 			failureChecker := check.Status(http.StatusNotFound)
 			count := 2 * t.Clusters().Len()
 
@@ -563,7 +563,7 @@ func TestIngress(t *testing.T) {
 					for _, c := range cases {
 						c := c
 						t.NewSubTest(c.name).Run(func(t framework.TestContext) {
-							if err := t.ConfigIstio().YAML(apps.Namespace.Name(), ingressClassConfig,
+							if err := t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), ingressClassConfig,
 								fmt.Sprintf(ingressConfigTemplate, "ingress", "istio-test", c.path, c.path, c.prefixPath)).
 								Apply(); err != nil {
 								t.Fatal(err)
@@ -582,7 +582,7 @@ func TestIngress(t *testing.T) {
 				if !t.Environment().(*kube.Environment).Settings().LoadBalancerSupported {
 					t.Skip("ingress status not supported without load balancer")
 				}
-				if err := t.ConfigIstio().YAML(apps.Namespace.Name(), ingressClassConfig,
+				if err := t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), ingressClassConfig,
 					fmt.Sprintf(ingressConfigTemplate, "ingress", "istio-test", "/test", "/test", "/test")).
 					Apply(); err != nil {
 					t.Fatal(err)
@@ -592,7 +592,7 @@ func TestIngress(t *testing.T) {
 				hostIsIP := net.ParseIP(host).String() != "<nil>"
 				retry.UntilSuccessOrFail(t, func() error {
 					if apiVersion == "v1beta1" {
-						ing, err := t.Clusters().Default().NetworkingV1beta1().Ingresses(apps.Namespace.Name()).Get(context.Background(), "ingress", metav1.GetOptions{})
+						ing, err := t.Clusters().Default().NetworkingV1beta1().Ingresses(apps.NS1().Namespace.Name()).Get(context.Background(), "ingress", metav1.GetOptions{})
 						if err != nil {
 							return err
 						}
@@ -608,7 +608,7 @@ func TestIngress(t *testing.T) {
 						}
 						return nil
 					}
-					ing, err := t.Clusters().Default().NetworkingV1().Ingresses(apps.Namespace.Name()).Get(context.Background(), "ingress", metav1.GetOptions{})
+					ing, err := t.Clusters().Default().NetworkingV1().Ingresses(apps.NS1().Namespace.Name()).Get(context.Background(), "ingress", metav1.GetOptions{})
 					if err != nil {
 						return err
 					}
@@ -628,7 +628,7 @@ func TestIngress(t *testing.T) {
 
 			// setup another ingress pointing to a different route; the ingress will have an ingress class that should be targeted at first
 			const updateIngressName = "update-test-ingress"
-			if err := t.ConfigIstio().YAML(apps.Namespace.Name(), ingressClassConfig,
+			if err := t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), ingressClassConfig,
 				fmt.Sprintf(ingressConfigTemplate, updateIngressName, "istio-test", "/update-test", "/update-test", "/update-test")).
 				Apply(); err != nil {
 				t.Fatal(err)
@@ -697,7 +697,7 @@ func TestIngress(t *testing.T) {
 			for _, c := range ingressUpdateCases {
 				c := c
 				updatedIngress := fmt.Sprintf(ingressConfigTemplate, updateIngressName, c.ingressClass, c.path, c.path, c.path)
-				t.ConfigIstio().YAML(apps.Namespace.Name(), updatedIngress).ApplyOrFail(t)
+				t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), updatedIngress).ApplyOrFail(t)
 				t.NewSubTest(c.name).Run(func(t framework.TestContext) {
 					c.call.Retry.Options = []retry.Option{retry.Timeout(time.Minute)}
 					apps.Ingress.CallOrFail(t, c.call)
@@ -720,7 +720,7 @@ func TestCustomGateway(t *testing.T) {
 			templateParams := map[string]string{
 				"imagePullSecret": t.Settings().Image.PullSecretNameOrFail(t),
 				"injectLabel":     injectLabel,
-				"host":            apps.PodA[0].Config().ClusterLocalFQDN(),
+				"host":            apps.NS1().A.Config().ClusterLocalFQDN(),
 				"imagePullPolicy": t.Settings().Image.PullPolicy,
 			}
 
@@ -801,7 +801,7 @@ func TestCustomGateway(t *testing.T) {
 					_, err := kubetest.CheckPodsAreReady(kubetest.NewPodFetch(cs, gatewayNs.Name(), "istio=custom"))
 					return err
 				}, retry.Timeout(time.Minute*2))
-				apps.PodB[0].CallOrFail(t, echo.CallOptions{
+				apps.NS1().B[0].CallOrFail(t, echo.CallOptions{
 					Port:    echo.Port{ServicePort: 80},
 					Scheme:  scheme.HTTP,
 					Address: fmt.Sprintf("custom-gateway.%s.svc.cluster.local", gatewayNs.Name()),
@@ -873,8 +873,8 @@ func TestCustomGateway(t *testing.T) {
         host: %s
         port:
           number: 80
-`, apps.PodA[0].Config().ClusterLocalFQDN())).Apply(resource.NoCleanup)
-				apps.PodB[0].CallOrFail(t, echo.CallOptions{
+`, apps.NS1().A.Config().ClusterLocalFQDN())).Apply(resource.NoCleanup)
+				apps.NS1().B[0].CallOrFail(t, echo.CallOptions{
 					Port:    echo.Port{ServicePort: 80},
 					Scheme:  scheme.HTTP,
 					Address: fmt.Sprintf("custom-gateway-helm.%s.svc.cluster.local", gatewayNs.Name()),
@@ -940,8 +940,8 @@ func TestCustomGateway(t *testing.T) {
         host: %s
         port:
           number: 80
-`, apps.PodA[0].Config().ClusterLocalFQDN())).Apply(resource.NoCleanup)
-				apps.PodB[0].CallOrFail(t, echo.CallOptions{
+`, apps.NS1().A.Config().ClusterLocalFQDN())).Apply(resource.NoCleanup)
+				apps.NS1().B[0].CallOrFail(t, echo.CallOptions{
 					Port:    echo.Port{ServicePort: 80},
 					Scheme:  scheme.HTTP,
 					Address: fmt.Sprintf("helm-simple.%s.svc.cluster.local", gatewayNs.Name()),
diff --git a/tests/integration/pilot/istioctl_test.go b/tests/integration/pilot/istioctl_test.go
index 480682fbc4..ae02293c5a 100644
--- a/tests/integration/pilot/istioctl_test.go
+++ b/tests/integration/pilot/istioctl_test.go
@@ -34,6 +34,7 @@
 	"istio.io/istio/pkg/test"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/echo"
+	commonDeployment "istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/echo/deployment"
 	"istio.io/istio/pkg/test/framework/components/istioctl"
 	"istio.io/istio/pkg/test/framework/components/namespace"
@@ -41,7 +42,6 @@
 	"istio.io/istio/pkg/test/util/retry"
 	"istio.io/istio/pkg/url"
 	"istio.io/istio/pkg/util/protomarshal"
-	"istio.io/istio/tests/integration/pilot/common"
 )
 
 var (
@@ -146,7 +146,7 @@ func TestDescribe(t *testing.T) {
 	framework.NewTest(t).Features("usability.observability.describe").
 		RequiresSingleCluster().
 		Run(func(t framework.TestContext) {
-			t.ConfigIstio().File(apps.Namespace.Name(), "testdata/a.yaml").ApplyOrFail(t)
+			t.ConfigIstio().File(apps.NS1().Namespace.Name(), "testdata/a.yaml").ApplyOrFail(t)
 
 			istioCtl := istioctl.NewOrFail(t, t, istioctl.Config{})
 
@@ -156,7 +156,7 @@ func TestDescribe(t *testing.T) {
 			retry.UntilSuccessOrFail(t, func() error {
 				args := []string{
 					"--namespace=dummy",
-					"x", "describe", "svc", fmt.Sprintf("%s.%s", common.PodASvc, apps.Namespace.Name()),
+					"x", "describe", "svc", fmt.Sprintf("%s.%s", commonDeployment.PodASvc, apps.NS1().Namespace.Name()),
 				}
 				output, _, err := istioCtl.Invoke(args)
 				if err != nil {
@@ -169,13 +169,13 @@ func TestDescribe(t *testing.T) {
 			}, retry.Timeout(time.Second*20))
 
 			retry.UntilSuccessOrFail(t, func() error {
-				podID, err := getPodID(apps.PodA[0])
+				podID, err := getPodID(apps.NS1().A[0])
 				if err != nil {
 					return fmt.Errorf("could not get Pod ID: %v", err)
 				}
 				args := []string{
 					"--namespace=dummy",
-					"x", "describe", "pod", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()),
+					"x", "describe", "pod", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()),
 				}
 				output, _, err := istioCtl.Invoke(args)
 				if err != nil {
@@ -263,7 +263,7 @@ func TestProxyConfig(t *testing.T) {
 		Run(func(t framework.TestContext) {
 			istioCtl := istioctl.NewOrFail(t, t, istioctl.Config{})
 
-			podID, err := getPodID(apps.PodA[0])
+			podID, err := getPodID(apps.NS1().A[0])
 			if err != nil {
 				t.Fatalf("Could not get Pod ID: %v", err)
 			}
@@ -274,7 +274,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "bootstrap", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()),
+				"pc", "bootstrap", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()),
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput := jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -282,7 +282,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "cluster", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "-o", "json",
+				"pc", "cluster", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "-o", "json",
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput = jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -290,7 +290,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "endpoint", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "-o", "json",
+				"pc", "endpoint", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "-o", "json",
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput = jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -298,7 +298,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "listener", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "-o", "json",
+				"pc", "listener", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "-o", "json",
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput = jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -306,7 +306,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "route", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "-o", "json",
+				"pc", "route", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "-o", "json",
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput = jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -314,7 +314,7 @@ func TestProxyConfig(t *testing.T) {
 
 			args = []string{
 				"--namespace=dummy",
-				"pc", "secret", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "-o", "json",
+				"pc", "secret", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "-o", "json",
 			}
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			jsonOutput = jsonUnmarshallOrFail(t, strings.Join(args, " "), output)
@@ -353,7 +353,7 @@ func TestProxyStatus(t *testing.T) {
 		Run(func(t framework.TestContext) {
 			istioCtl := istioctl.NewOrFail(t, t, istioctl.Config{})
 
-			podID, err := getPodID(apps.PodA[0])
+			podID, err := getPodID(apps.NS1().A[0])
 			if err != nil {
 				t.Fatalf("Could not get Pod ID: %v", err)
 			}
@@ -366,7 +366,7 @@ func TestProxyStatus(t *testing.T) {
 			output, _ = istioCtl.InvokeOrFail(t, args)
 			// Just verify pod A is known to Pilot; implicitly this verifies that
 			// the printing code printed it.
-			g.Expect(output).To(gomega.ContainSubstring(fmt.Sprintf("%s.%s", podID, apps.Namespace.Name())))
+			g.Expect(output).To(gomega.ContainSubstring(fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name())))
 
 			expectSubstrings := func(have string, wants ...string) error {
 				for _, want := range wants {
@@ -379,7 +379,7 @@ func TestProxyStatus(t *testing.T) {
 
 			retry.UntilSuccessOrFail(t, func() error {
 				args = []string{
-					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()),
+					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()),
 				}
 				output, _, err := istioCtl.Invoke(args)
 				if err != nil {
@@ -393,12 +393,12 @@ func TestProxyStatus(t *testing.T) {
 				d := t.TempDir()
 				filename := filepath.Join(d, "ps-configdump.json")
 				cs := t.Clusters().Default()
-				dump, err := cs.EnvoyDo(context.TODO(), podID, apps.Namespace.Name(), "GET", "config_dump")
+				dump, err := cs.EnvoyDo(context.TODO(), podID, apps.NS1().Namespace.Name(), "GET", "config_dump")
 				g.Expect(err).ShouldNot(gomega.HaveOccurred())
 				err = os.WriteFile(filename, dump, os.ModePerm)
 				g.Expect(err).ShouldNot(gomega.HaveOccurred())
 				args = []string{
-					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "--file", filename,
+					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "--file", filename,
 				}
 				output, _, err = istioCtl.Invoke(args)
 				if err != nil {
@@ -416,7 +416,7 @@ func TestXdsProxyStatus(t *testing.T) {
 		Run(func(t framework.TestContext) {
 			istioCtl := istioctl.NewOrFail(t, t, istioctl.Config{})
 
-			podID, err := getPodID(apps.PodA[0])
+			podID, err := getPodID(apps.NS1().A[0])
 			if err != nil {
 				t.Fatalf("Could not get Pod ID: %v", err)
 			}
@@ -427,7 +427,7 @@ func TestXdsProxyStatus(t *testing.T) {
 			output, _ := istioCtl.InvokeOrFail(t, args)
 			// Just verify pod A is known to Pilot; implicitly this verifies that
 			// the printing code printed it.
-			g.Expect(output).To(gomega.ContainSubstring(fmt.Sprintf("%s.%s", podID, apps.Namespace.Name())))
+			g.Expect(output).To(gomega.ContainSubstring(fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name())))
 
 			expectSubstrings := func(have string, wants ...string) error {
 				for _, want := range wants {
@@ -440,7 +440,7 @@ func TestXdsProxyStatus(t *testing.T) {
 
 			retry.UntilSuccessOrFail(t, func() error {
 				args = []string{
-					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()),
+					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()),
 				}
 				output, _, err = istioCtl.Invoke(args)
 				if err != nil {
@@ -454,12 +454,12 @@ func TestXdsProxyStatus(t *testing.T) {
 				d := t.TempDir()
 				filename := filepath.Join(d, "ps-configdump.json")
 				cs := t.Clusters().Default()
-				dump, err := cs.EnvoyDo(context.TODO(), podID, apps.Namespace.Name(), "GET", "config_dump")
+				dump, err := cs.EnvoyDo(context.TODO(), podID, apps.NS1().Namespace.Name(), "GET", "config_dump")
 				g.Expect(err).ShouldNot(gomega.HaveOccurred())
 				err = os.WriteFile(filename, dump, os.ModePerm)
 				g.Expect(err).ShouldNot(gomega.HaveOccurred())
 				args = []string{
-					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.Namespace.Name()), "--file", filename,
+					"proxy-status", fmt.Sprintf("%s.%s", podID, apps.NS1().Namespace.Name()), "--file", filename,
 				}
 				output, _, err = istioCtl.Invoke(args)
 				if err != nil {
@@ -474,14 +474,14 @@ func TestAuthZCheck(t *testing.T) {
 	framework.NewTest(t).Features("usability.observability.authz-check").
 		RequiresSingleCluster().
 		Run(func(t framework.TestContext) {
-			t.ConfigIstio().File(apps.Namespace.Name(), "testdata/authz-a.yaml").ApplyOrFail(t)
+			t.ConfigIstio().File(apps.NS1().Namespace.Name(), "testdata/authz-a.yaml").ApplyOrFail(t)
 			t.ConfigIstio().File(i.Settings().SystemNamespace, "testdata/authz-b.yaml").ApplyOrFail(t)
 
 			gwPod, err := i.IngressFor(t.Clusters().Default()).PodID(0)
 			if err != nil {
 				t.Fatalf("Could not get Pod ID: %v", err)
 			}
-			appPod, err := getPodID(apps.PodA[0])
+			appPod, err := getPodID(apps.NS1().A[0])
 			if err != nil {
 				t.Fatalf("Could not get Pod ID: %v", err)
 			}
@@ -501,11 +501,11 @@ func TestAuthZCheck(t *testing.T) {
 				},
 				{
 					name: "workload",
-					pod:  fmt.Sprintf("%s.%s", appPod, apps.Namespace.Name()),
+					pod:  fmt.Sprintf("%s.%s", appPod, apps.NS1().Namespace.Name()),
 					wants: []*regexp.Regexp{
-						regexp.MustCompile(fmt.Sprintf(`DENY\s+deny-policy\.%s\s+2`, apps.Namespace.Name())),
+						regexp.MustCompile(fmt.Sprintf(`DENY\s+deny-policy\.%s\s+2`, apps.NS1().Namespace.Name())),
 						regexp.MustCompile(`ALLOW\s+_anonymous_match_nothing_\s+1`),
-						regexp.MustCompile(fmt.Sprintf(`ALLOW\s+allow-policy\.%s\s+1`, apps.Namespace.Name())),
+						regexp.MustCompile(fmt.Sprintf(`ALLOW\s+allow-policy\.%s\s+1`, apps.NS1().Namespace.Name())),
 					},
 				},
 			}
diff --git a/tests/integration/pilot/locality_test.go b/tests/integration/pilot/locality_test.go
index dcad009290..4947724b7b 100644
--- a/tests/integration/pilot/locality_test.go
+++ b/tests/integration/pilot/locality_test.go
@@ -111,12 +111,12 @@ func TestLocality(t *testing.T) {
 		Features("traffic.locality").
 		RequiresSingleCluster().
 		Run(func(t framework.TestContext) {
-			destA := apps.PodB[0]
-			destB := apps.PodC[0]
-			destC := apps.Naked[0]
+			destA := apps.NS1().B[0]
+			destB := apps.NS1().C[0]
+			destC := apps.NS1().Naked[0]
 			if !t.Settings().Skip(echo.VM) {
 				// TODO do we even need this to be a VM
-				destC = apps.VM[0]
+				destC = apps.NS1().VM[0]
 			}
 
 			cases := []struct {
@@ -210,8 +210,8 @@ func TestLocality(t *testing.T) {
 				t.NewSubTest(tt.name).Run(func(t framework.TestContext) {
 					hostname := fmt.Sprintf("%s-fake-locality.example.com", strings.ToLower(strings.ReplaceAll(tt.name, "/", "-")))
 					tt.input.Host = hostname
-					t.ConfigIstio().YAML(apps.Namespace.Name(), runTemplate(t, localityTemplate, tt.input)).ApplyOrFail(t)
-					sendTrafficOrFail(t, apps.PodA[0], hostname, tt.expected)
+					t.ConfigIstio().YAML(apps.NS1().Namespace.Name(), runTemplate(t, localityTemplate, tt.input)).ApplyOrFail(t)
+					sendTrafficOrFail(t, apps.NS1().A[0], hostname, tt.expected)
 				})
 			}
 		})
diff --git a/tests/integration/pilot/main_test.go b/tests/integration/pilot/main_test.go
index 6239ee4de1..de7cba26da 100644
--- a/tests/integration/pilot/main_test.go
+++ b/tests/integration/pilot/main_test.go
@@ -23,10 +23,10 @@
 	"istio.io/istio/pkg/config/protocol"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/echo"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/framework/components/istio"
 	"istio.io/istio/pkg/test/framework/components/namespace"
 	"istio.io/istio/pkg/test/framework/resource"
-	"istio.io/istio/tests/integration/pilot/common"
 )
 
 var (
@@ -35,7 +35,7 @@
 	// Below are various preconfigured echo deployments. Whenever possible, tests should utilize these
 	// to avoid excessive creation/tear down of deployments. In general, a test should only deploy echo if
 	// its doing something unique to that specific test.
-	apps = &common.EchoDeployments{}
+	apps = deployment.Echos{}
 )
 
 func supportsCRDv1(t resource.Context) bool {
@@ -55,7 +55,7 @@ func TestMain(m *testing.M) {
 		NewSuite(m).
 		Setup(istio.Setup(&i, nil)).
 		Setup(func(t resource.Context) error {
-			return common.SetupApps(t, i, apps)
+			return deployment.Setup(t, &apps, deployment.Config{})
 		}).
 		Run()
 }
diff --git a/tests/integration/pilot/mirror_test.go b/tests/integration/pilot/mirror_test.go
index e471dacecd..281db99e78 100644
--- a/tests/integration/pilot/mirror_test.go
+++ b/tests/integration/pilot/mirror_test.go
@@ -29,8 +29,8 @@
 	"istio.io/istio/pkg/config/protocol"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/echo"
+	"istio.io/istio/pkg/test/framework/components/echo/common/deployment"
 	"istio.io/istio/pkg/test/util/retry"
-	"istio.io/istio/tests/integration/pilot/common"
 	"istio.io/pkg/log"
 )
 
@@ -102,8 +102,8 @@ func TestMirroring(t *testing.T) {
 // mesh because of the Sidecar), then we can inspect "external" logs to verify the requests were properly mirrored.
 func TestMirroringExternalService(t *testing.T) {
 	header := ""
-	if len(apps.External) > 0 {
-		header = apps.External[0].Config().HostHeader()
+	if len(apps.External.Echos) > 0 {
+		header = apps.External.Echos.Config().HostHeader()
 	}
 	runMirrorTest(t, mirrorTestOptions{
 		mirrorHost: header,
@@ -113,7 +113,7 @@ func TestMirroringExternalService(t *testing.T) {
 				absent:              true,
 				percentage:          100.0,
 				threshold:           0.0,
-				expectedDestination: apps.External,
+				expectedDestination: apps.External.Echos,
 			},
 		},
 	})
@@ -128,7 +128,7 @@ func runMirrorTest(t *testing.T, options mirrorTestOptions) {
 				t.NewSubTest(c.name).Run(func(t framework.TestContext) {
 					mirrorHost := options.mirrorHost
 					if len(mirrorHost) == 0 {
-						mirrorHost = common.PodCSvc
+						mirrorHost = deployment.PodCSvc
 					}
 					vsc := VirtualServiceMirrorConfig{
 						c.name,
@@ -138,24 +138,24 @@ func runMirrorTest(t *testing.T, options mirrorTestOptions) {
 					}
 
 					// we only apply to config clusters
-					t.ConfigIstio().EvalFile(apps.Namespace.Name(), vsc, "testdata/traffic-mirroring-template.yaml").ApplyOrFail(t)
+					t.ConfigIstio().EvalFile(apps.NS1().Namespace.Name(), vsc, "testdata/traffic-mirroring-template.yaml").ApplyOrFail(t)
 
-					for _, podA := range apps.PodA {
+					for _, podA := range apps.NS1().A {
 						podA := podA
 						t.NewSubTest(fmt.Sprintf("from %s", podA.Config().Cluster.StableName())).Run(func(t framework.TestContext) {
 							for _, proto := range mirrorProtocols {
 								t.NewSubTest(string(proto)).Run(func(t framework.TestContext) {
 									retry.UntilSuccessOrFail(t, func() error {
 										testID := rand.String(16)
-										if err := sendTrafficMirror(podA, apps.PodB, proto, testID); err != nil {
+										if err := sendTrafficMirror(podA, apps.NS1().B, proto, testID); err != nil {
 											return err
 										}
 										expected := c.expectedDestination
 										if expected == nil {
-											expected = apps.PodC
+											expected = apps.NS1().C
 										}
 
-										return verifyTrafficMirror(apps.PodB, expected, c, testID)
+										return verifyTrafficMirror(apps.NS1().B, expected, c, testID)
 									}, echo.DefaultCallRetryOptions()...)
 								})
 							}
diff --git a/tests/integration/pilot/multi_version_revision_test.go b/tests/integration/pilot/multi_version_revision_test.go
index 58c983bdf2..6407b36eb6 100644
--- a/tests/integration/pilot/multi_version_revision_test.go
+++ b/tests/integration/pilot/multi_version_revision_test.go
@@ -122,7 +122,7 @@ func TestMultiVersionRevision(t *testing.T) {
 			}
 			instances := builder.BuildOrFail(t)
 			// add an existing pod from apps to the rotation to avoid an extra deployment
-			instances = append(instances, apps.PodA[0])
+			instances = append(instances, apps.NS1().A[0])
 
 			testAllEchoCalls(t, instances)
 		})
diff --git a/tests/integration/pilot/multicluster_test.go b/tests/integration/pilot/multicluster_test.go
index ad839e9c00..65c389d165 100644
--- a/tests/integration/pilot/multicluster_test.go
+++ b/tests/integration/pilot/multicluster_test.go
@@ -54,8 +54,8 @@ func TestClusterLocal(t *testing.T) {
 		RequireIstioVersion("1.11").
 		Run(func(t framework.TestContext) {
 			// TODO use echotest to dynamically pick 2 simple pods from apps.All
-			sources := apps.PodA
-			to := apps.PodB
+			sources := apps.NS1().A
+			to := apps.NS1().B
 
 			tests := []struct {
 				name  string
@@ -70,7 +70,7 @@ func(t framework.TestContext) {
     clusterLocal: true
   hosts:
   - "%s"
-`, apps.PodB[0].Config().ClusterLocalFQDN()))
+`, apps.NS1().B.Config().ClusterLocalFQDN()))
 					},
 				},
 				{
diff --git a/tests/integration/pilot/original_src_addr_test.go b/tests/integration/pilot/original_src_addr_test.go
index 68d7c76c4d..c4c37c9079 100644
--- a/tests/integration/pilot/original_src_addr_test.go
+++ b/tests/integration/pilot/original_src_addr_test.go
@@ -35,7 +35,7 @@ func TestTproxy(t *testing.T) {
 			if t.Settings().Skip(echo.TProxy) {
 				t.Skip()
 			}
-			workloads, err := apps.PodA[0].Workloads()
+			workloads, err := apps.NS1().A[0].Workloads()
 			if err != nil {
 				t.Errorf("failed to get Subsets: %v", err)
 				return
@@ -45,7 +45,7 @@ func TestTproxy(t *testing.T) {
 			for _, w := range workloads {
 				srcIps = append(srcIps, w.Address())
 			}
-			checkOriginalSrcIP(t, apps.PodA[0], apps.PodTproxy[0], srcIps)
+			checkOriginalSrcIP(t, apps.NS1().A[0], apps.NS1().Tproxy[0], srcIps)
 		})
 }
 
diff --git a/tests/integration/pilot/piggyback_test.go b/tests/integration/pilot/piggyback_test.go
index c1226e0190..2818a7f968 100644
--- a/tests/integration/pilot/piggyback_test.go
+++ b/tests/integration/pilot/piggyback_test.go
@@ -34,8 +34,8 @@ func TestPiggyback(t *testing.T) {
 		RequireIstioVersion("1.10.0").
 		Run(func(t framework.TestContext) {
 			out, _, err := t.Clusters()[0].PodExec(
-				apps.PodA[0].WorkloadsOrFail(t)[0].PodName(),
-				apps.PodA[0].Config().Namespace.Name(),
+				apps.NS1().A[0].WorkloadsOrFail(t)[0].PodName(),
+				apps.NS1().A.Config().Namespace.Name(),
 				"istio-proxy",
 				"pilot-agent request --debug-port 15004 GET /debug/syncz")
 			if err != nil {
diff --git a/tests/integration/pilot/revisioned_upgrade_test.go b/tests/integration/pilot/revisioned_upgrade_test.go
index 4da4a1381c..261bed4ac7 100644
--- a/tests/integration/pilot/revisioned_upgrade_test.go
+++ b/tests/integration/pilot/revisioned_upgrade_test.go
@@ -101,9 +101,9 @@ func testUpgradeFromVersion(t framework.TestContext, fromVersion string) {
 
 	// Create a traffic generator between A and B.
 	g := traffic.NewGenerator(t, traffic.Config{
-		Source: apps.PodA[0],
+		Source: apps.NS1().A[0],
 		Options: echo.CallOptions{
-			To: apps.PodB,
+			To: apps.NS1().B,
 			Port: echo.Port{
 				Name: "http",
 			},
diff --git a/tests/integration/pilot/routing_test.go b/tests/integration/pilot/routing_test.go
index c47e7d4698..a53b12fbd7 100644
--- a/tests/integration/pilot/routing_test.go
+++ b/tests/integration/pilot/routing_test.go
@@ -29,6 +29,6 @@ func TestTraffic(t *testing.T) {
 		NewTest(t).
 		Features("traffic.routing", "traffic.reachability", "traffic.shifting").
 		Run(func(t framework.TestContext) {
-			common.RunAllTrafficTests(t, i, apps)
+			common.RunAllTrafficTests(t, i, &apps)
 		})
 }
diff --git a/tests/integration/pilot/vm_test.go b/tests/integration/pilot/vm_test.go
index 7bd00deb4e..3d75253a97 100644
--- a/tests/integration/pilot/vm_test.go
+++ b/tests/integration/pilot/vm_test.go
@@ -68,7 +68,7 @@ func TestVmOSPost(t *testing.T) {
 			for _, image := range images {
 				b = b.WithConfig(echo.Config{
 					Service:    "vm-" + strings.ReplaceAll(image, "_", "-"),
-					Namespace:  apps.Namespace,
+					Namespace:  apps.NS1().Namespace,
 					Ports:      ports.All(),
 					DeployAsVM: true,
 					VMDistro:   image,
@@ -80,8 +80,8 @@ func TestVmOSPost(t *testing.T) {
 			for i, image := range images {
 				i, image := i, image
 				t.NewSubTest(image).RunParallel(func(t framework.TestContext) {
-					for _, tt := range common.VMTestCases(echo.Instances{instances[i]}, apps) {
-						tt.Run(t, apps.Namespace.Name())
+					for _, tt := range common.VMTestCases(echo.Instances{instances[i]}, &apps) {
+						tt.Run(t, apps.NS1().Namespace.Name())
 					}
 				})
 			}
@@ -99,12 +99,12 @@ func TestVMRegistrationLifecycle(t *testing.T) {
 				t.Skip()
 			}
 			scaleDeploymentOrFail(t, "istiod", i.Settings().SystemNamespace, 2)
-			client := match.Cluster(t.Clusters().Default()).FirstOrFail(t, apps.PodA)
+			client := match.Cluster(t.Clusters().Default()).FirstOrFail(t, apps.NS1().A)
 			// TODO test multi-network (must be shared control plane but on different networks)
 			var autoVM echo.Instance
 			_ = deployment.New(t).
 				With(&autoVM, echo.Config{
-					Namespace:      apps.Namespace,
+					Namespace:      apps.NS1().Namespace,
 					Service:        "auto-vm",
 					Ports:          ports.All(),
 					DeployAsVM:     true,
-- 
2.35.3

