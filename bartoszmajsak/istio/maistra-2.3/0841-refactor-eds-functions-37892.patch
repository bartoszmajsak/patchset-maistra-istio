From c9085c959b0b5112c868c79dcc9d5e84288d934e Mon Sep 17 00:00:00 2001
From: Rama Chavali <rama.rao@salesforce.com>
Date: Fri, 18 Mar 2022 08:08:05 +0530
Subject: refactor eds functions (#37892)

* refactor eds functions

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>

* fix test

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>

* revert

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>

* fix

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>

* rename

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>

* rename

Signed-off-by: Rama Chavali <rama.rao@salesforce.com>
---
 .../serviceentry/servicediscovery.go          | 140 ++++++++++--------
 1 file changed, 82 insertions(+), 58 deletions(-)

diff --git a/pilot/pkg/serviceregistry/serviceentry/servicediscovery.go b/pilot/pkg/serviceregistry/serviceentry/servicediscovery.go
index dbd5048cca..d42fa23cc4 100644
--- a/pilot/pkg/serviceregistry/serviceentry/servicediscovery.go
+++ b/pilot/pkg/serviceregistry/serviceentry/servicediscovery.go
@@ -282,12 +282,12 @@ func (s *ServiceEntryStore) workloadEntryHandler(old, curr config.Config, event
 		if event == model.EventAdd {
 			s.XdsUpdater.ProxyUpdate(s.Cluster(), wle.Address)
 		}
-		s.edsUpdate(allInstances, true)
+		s.edsUpdate(allInstances)
 		return
 	}
 
 	// update eds cache only
-	s.edsUpdate(allInstances, false)
+	s.edsCacheUpdate(allInstances)
 
 	pushReq := &model.PushRequest{
 		Full:           true,
@@ -338,6 +338,7 @@ func (s *ServiceEntryStore) serviceEntryHandler(_, curr config.Config, event mod
 	}
 
 	shard := model.ShardKeyFromRegistry(s)
+
 	for _, svc := range addedSvcs {
 		s.XdsUpdater.SvcUpdate(shard, string(svc.Hostname), svc.Attributes.Namespace, model.EventAdd)
 		configsUpdated[makeConfigKey(svc)] = struct{}{}
@@ -384,7 +385,7 @@ func (s *ServiceEntryStore) serviceEntryHandler(_, curr config.Config, event mod
 	fullPush := len(configsUpdated) > 0
 	// if not full push needed, at least one service unchanged
 	if !fullPush {
-		s.edsUpdate(serviceInstances, true)
+		s.edsUpdate(serviceInstances)
 		return
 	}
 
@@ -406,8 +407,7 @@ func (s *ServiceEntryStore) serviceEntryHandler(_, curr config.Config, event mod
 		keys[instancesKey{hostname: svc.Hostname, namespace: curr.Namespace}] = struct{}{}
 	}
 
-	// trigger update eds endpoint shards
-	s.edsUpdateInSerial(keys, false)
+	s.queueEdsEvent(keys, s.doEdsCacheUpdate)
 
 	pushReq := &model.PushRequest{
 		Full:           true,
@@ -500,7 +500,7 @@ func (s *ServiceEntryStore) WorkloadInstanceHandler(wi *model.WorkloadInstance,
 	}
 	s.mutex.Unlock()
 
-	s.edsUpdate(instances, true)
+	s.edsUpdate(instances)
 }
 
 func (s *ServiceEntryStore) Provider() provider.ID {
@@ -590,28 +590,41 @@ func (s *ServiceEntryStore) ResyncEDS() {
 	s.mutex.RLock()
 	allInstances := s.serviceInstances.getAll()
 	s.mutex.RUnlock()
-	s.edsUpdate(allInstances, true)
+	s.edsUpdate(allInstances)
+}
+
+// edsUpdate triggers an EDS push serially such that we can prevent allinstances
+// got at t1 can accidentally override that got at t2 if multiple threads are
+// running this function. Queueing ensures latest updated wins.
+func (s *ServiceEntryStore) edsUpdate(instances []*model.ServiceInstance) {
+	// Find all keys we need to lookup
+	keys := map[instancesKey]struct{}{}
+	for _, i := range instances {
+		keys[makeInstanceKey(i)] = struct{}{}
+	}
+	s.queueEdsEvent(keys, s.doEdsUpdate)
 }
 
-// edsUpdate triggers an EDS cache update for the given instances.
-// And triggers a push if `push` is true.
-func (s *ServiceEntryStore) edsUpdate(instances []*model.ServiceInstance, push bool) {
+// edsCacheUpdate upates eds cache serially such that we can prevent allinstances
+// got at t1 can accidentally override that got at t2 if multiple threads are
+// running this function. Queueing ensures latest updated wins.
+func (s *ServiceEntryStore) edsCacheUpdate(instances []*model.ServiceInstance) {
 	// Find all keys we need to lookup
 	keys := map[instancesKey]struct{}{}
 	for _, i := range instances {
 		keys[makeInstanceKey(i)] = struct{}{}
 	}
-	s.edsUpdateInSerial(keys, push)
+	s.queueEdsEvent(keys, s.doEdsCacheUpdate)
 }
 
-// edsUpdateInSerial run s.edsUpdateByKeys in serial and wait for complete.
-func (s *ServiceEntryStore) edsUpdateInSerial(keys map[instancesKey]struct{}, push bool) {
+// queueEdsEvent processes eds events sequentially for the passed keys and invokes the passed function.
+func (s *ServiceEntryStore) queueEdsEvent(keys map[instancesKey]struct{}, edsFn func(keys map[instancesKey]struct{})) {
 	// wait for the cache update finished
 	waitCh := make(chan struct{})
 	// trigger update eds endpoint shards
 	s.edsQueue.Push(func() error {
 		defer close(waitCh)
-		s.edsUpdateByKeys(keys, push)
+		edsFn(keys)
 		return nil
 	})
 	select {
@@ -624,9 +637,41 @@ func (s *ServiceEntryStore) edsUpdateInSerial(keys map[instancesKey]struct{}, pu
 	}
 }
 
-// edsUpdateByKeys will be run in serial within one thread, such that we can
-// prevent allinstances got at t1 can override that got at t2 if multi threads running this function
-func (s *ServiceEntryStore) edsUpdateByKeys(keys map[instancesKey]struct{}, push bool) {
+// doEdsCacheUpdate invokes XdsUpdater's EDSCacheUpdate to update endpoint shards.
+func (s *ServiceEntryStore) doEdsCacheUpdate(keys map[instancesKey]struct{}) {
+	endpoints := s.buildEndpoints(keys)
+	shard := model.ShardKeyFromRegistry(s)
+	// This is delete.
+	if len(endpoints) == 0 {
+		for k := range keys {
+			s.XdsUpdater.EDSCacheUpdate(shard, string(k.hostname), k.namespace, nil)
+		}
+	} else {
+		for k, eps := range endpoints {
+			s.XdsUpdater.EDSCacheUpdate(shard, string(k.hostname), k.namespace, eps)
+		}
+	}
+}
+
+// doEdsUpdate invokes XdsUpdater's eds update to trigger eds push.
+func (s *ServiceEntryStore) doEdsUpdate(keys map[instancesKey]struct{}) {
+	endpoints := s.buildEndpoints(keys)
+	shard := model.ShardKeyFromRegistry(s)
+	// This is delete.
+	if len(endpoints) == 0 {
+		for k := range keys {
+			s.XdsUpdater.EDSUpdate(shard, string(k.hostname), k.namespace, nil)
+		}
+	} else {
+		for k, eps := range endpoints {
+			s.XdsUpdater.EDSUpdate(shard, string(k.hostname), k.namespace, eps)
+		}
+	}
+}
+
+// buildEndpoints builds endpoints for the instance keys.
+func (s *ServiceEntryStore) buildEndpoints(keys map[instancesKey]struct{}) map[instancesKey][]*model.IstioEndpoint {
+	var endpoints map[instancesKey][]*model.IstioEndpoint
 	allInstances := []*model.ServiceInstance{}
 	s.mutex.RLock()
 	for key := range keys {
@@ -635,50 +680,29 @@ func (s *ServiceEntryStore) edsUpdateByKeys(keys map[instancesKey]struct{}, push
 	}
 	s.mutex.RUnlock()
 
-	// This was a delete
-	shard := model.ShardKeyFromRegistry(s)
-	if len(allInstances) == 0 {
-		if push {
-			for k := range keys {
-				s.XdsUpdater.EDSUpdate(shard, string(k.hostname), k.namespace, nil)
-			}
-		} else {
-			for k := range keys {
-				s.XdsUpdater.EDSCacheUpdate(shard, string(k.hostname), k.namespace, nil)
-			}
+	if len(allInstances) > 0 {
+		endpoints = make(map[instancesKey][]*model.IstioEndpoint)
+		for _, instance := range allInstances {
+			port := instance.ServicePort
+			key := makeInstanceKey(instance)
+			endpoints[key] = append(endpoints[key],
+				&model.IstioEndpoint{
+					Address:         instance.Endpoint.Address,
+					EndpointPort:    instance.Endpoint.EndpointPort,
+					ServicePortName: port.Name,
+					Labels:          instance.Endpoint.Labels,
+					ServiceAccount:  instance.Endpoint.ServiceAccount,
+					Network:         instance.Endpoint.Network,
+					Locality:        instance.Endpoint.Locality,
+					LbWeight:        instance.Endpoint.LbWeight,
+					TLSMode:         instance.Endpoint.TLSMode,
+					WorkloadName:    instance.Endpoint.WorkloadName,
+					Namespace:       instance.Endpoint.Namespace,
+				})
 		}
-		return
-	}
 
-	endpoints := make(map[instancesKey][]*model.IstioEndpoint)
-	for _, instance := range allInstances {
-		port := instance.ServicePort
-		key := makeInstanceKey(instance)
-		endpoints[key] = append(endpoints[key],
-			&model.IstioEndpoint{
-				Address:         instance.Endpoint.Address,
-				EndpointPort:    instance.Endpoint.EndpointPort,
-				ServicePortName: port.Name,
-				Labels:          instance.Endpoint.Labels,
-				ServiceAccount:  instance.Endpoint.ServiceAccount,
-				Network:         instance.Endpoint.Network,
-				Locality:        instance.Endpoint.Locality,
-				LbWeight:        instance.Endpoint.LbWeight,
-				TLSMode:         instance.Endpoint.TLSMode,
-				WorkloadName:    instance.Endpoint.WorkloadName,
-				Namespace:       instance.Endpoint.Namespace,
-			})
-	}
-
-	if push {
-		for k, eps := range endpoints {
-			s.XdsUpdater.EDSUpdate(shard, string(k.hostname), k.namespace, eps)
-		}
-	} else {
-		for k, eps := range endpoints {
-			s.XdsUpdater.EDSCacheUpdate(shard, string(k.hostname), k.namespace, eps)
-		}
 	}
+	return endpoints
 }
 
 // returns true if an instance's port matches with any in the provided list
-- 
2.35.3

