From 26e13f9542634db505fb10813e8f9638d6a2353e Mon Sep 17 00:00:00 2001
From: Steven Landow <steven@stlcomputerservices.com>
Date: Thu, 16 Dec 2021 14:50:35 -0800
Subject: configgentest: avoid running kubecontroller 2x (#36332)

* configgentest: avoid running kubecontroller 2x

Change-Id: I8101701256e101a93aef14e0e60c36538a8b1f1b

* fix hanging tests that use fake kube directly

Change-Id: If052a24b9ade11e42f870651c1385fd1f61fb757

* fix test that use fake k8s directly

Change-Id: Ic773169a809662a1f14c2e59cb523c9785483411

* add before run in non-configgen test

Change-Id: I5ec4f820a6b0e56d5c6fb6755450cc08776bf2ef
---
 pilot/pkg/networking/core/v1alpha3/fake.go    |  7 +++-
 .../kube/controller/controller_test.go        |  1 -
 .../serviceregistry/kube/controller/fake.go   | 34 ++++++++++++-------
 pilot/pkg/xds/fake.go                         | 14 +++++---
 4 files changed, 36 insertions(+), 20 deletions(-)

diff --git a/pilot/pkg/networking/core/v1alpha3/fake.go b/pilot/pkg/networking/core/v1alpha3/fake.go
index e4051c4f1b..991fc5c60e 100644
--- a/pilot/pkg/networking/core/v1alpha3/fake.go
+++ b/pilot/pkg/networking/core/v1alpha3/fake.go
@@ -67,6 +67,8 @@ type TestOptions struct {
 	MeshConfig      *meshconfig.MeshConfig
 	NetworksWatcher mesh.NetworksWatcher
 
+	// Optionally provide a top-level aggregate registry with subregistries added. The ConfigGenTest will handle running it.
+	AggregateRegistry *aggregate.Controller
 	// Additional service registries to use. A ServiceEntry and memory registry will always be created.
 	ServiceRegistries []serviceregistry.Instance
 
@@ -120,7 +122,10 @@ func NewConfigGenTest(t test.Failer, opts TestOptions) *ConfigGenTest {
 		m = &def
 	}
 
-	serviceDiscovery := aggregate.NewController(aggregate.Options{})
+	serviceDiscovery := opts.AggregateRegistry
+	if serviceDiscovery == nil {
+		serviceDiscovery = aggregate.NewController(aggregate.Options{})
+	}
 	se := serviceentry.NewServiceDiscovery(
 		configController, model.MakeIstioStore(configStore),
 		&FakeXdsUpdater{}, serviceentry.WithClusterID(opts.ClusterID))
diff --git a/pilot/pkg/serviceregistry/kube/controller/controller_test.go b/pilot/pkg/serviceregistry/kube/controller/controller_test.go
index 419e84ab1d..8e1aac4688 100644
--- a/pilot/pkg/serviceregistry/kube/controller/controller_test.go
+++ b/pilot/pkg/serviceregistry/kube/controller/controller_test.go
@@ -284,7 +284,6 @@ func TestController_GetPodLocality(t *testing.T) {
 		// https://github.com/golang/go/wiki/CommonMistakes#using-goroutines-on-loop-iterator-variables
 		tc := tc
 		t.Run(tc.name, func(t *testing.T) {
-			t.Parallel()
 			// Setup kube caches
 			// Pod locality only matters for Endpoints
 			controller, fx := NewFakeControllerWithOptions(FakeControllerOptions{Mode: EndpointsOnly})
diff --git a/pilot/pkg/serviceregistry/kube/controller/fake.go b/pilot/pkg/serviceregistry/kube/controller/fake.go
index ec5c6b8667..564563eae3 100644
--- a/pilot/pkg/serviceregistry/kube/controller/fake.go
+++ b/pilot/pkg/serviceregistry/kube/controller/fake.go
@@ -150,9 +150,9 @@ type FakeControllerOptions struct {
 	XDSUpdater                model.XDSUpdater
 	DiscoveryNamespacesFilter filter.DiscoveryNamespacesFilter
 
-	// when calling from NewFakeDiscoveryServer, we wait for the aggregate cache to sync. Waiting here can cause deadlock.
-	SkipCacheSyncWait bool
-	Stop              chan struct{}
+	// when calling from NewFakeDiscoveryServer use the same aggregate controller we add other registries to
+	AggregateController *aggregate.Controller
+	Stop                chan struct{}
 }
 
 type FakeController struct {
@@ -169,14 +169,18 @@ func NewFakeControllerWithOptions(opts FakeControllerOptions) (*FakeController,
 	if opts.DomainSuffix != "" {
 		domainSuffix = opts.DomainSuffix
 	}
-	if opts.Client == nil {
-		opts.Client = kubelib.NewFakeClient()
+	client := opts.Client
+	if client == nil {
+		client = kubelib.NewFakeClient()
 	}
 	if opts.MeshWatcher == nil {
 		opts.MeshWatcher = mesh.NewFixedWatcher(&meshconfig.MeshConfig{})
 	}
 
-	meshServiceController := aggregate.NewController(aggregate.Options{MeshHolder: opts.MeshWatcher})
+	meshServiceController := opts.AggregateController
+	if meshServiceController == nil {
+		meshServiceController = aggregate.NewController(aggregate.Options{MeshHolder: opts.MeshWatcher})
+	}
 
 	options := Options{
 		DomainSuffix:              domainSuffix,
@@ -190,24 +194,28 @@ func NewFakeControllerWithOptions(opts FakeControllerOptions) (*FakeController,
 		DiscoveryNamespacesFilter: opts.DiscoveryNamespacesFilter,
 		MeshServiceController:     meshServiceController,
 	}
-	c := NewController(opts.Client, options)
-	meshServiceController.AddRegistry(c)
+	c := NewController(client, options)
 
 	if opts.ServiceHandler != nil {
 		c.AppendServiceHandler(opts.ServiceHandler)
 	}
+
+	// Run in initiation to prevent calling each test
+	// TODO: fix it, so we can remove `stop` channel
 	c.stop = opts.Stop
 	if c.stop == nil {
 		c.stop = make(chan struct{})
 	}
-	// Run in initiation to prevent calling each test
-	// TODO: fix it, so we can remove `stop` channel
-	go meshServiceController.Run(c.stop)
-	opts.Client.RunAndWait(c.stop)
-	if !opts.SkipCacheSyncWait {
+	client.RunAndWait(c.stop)
+
+	// we created the aggregate here, so we're responsible for starting it
+	if opts.AggregateController == nil {
+		meshServiceController.AddRegistry(c)
+		go meshServiceController.Run(c.stop)
 		// Wait for the caches to sync, otherwise we may hit race conditions where events are dropped
 		cache.WaitForCacheSync(c.stop, c.HasSynced)
 	}
+
 	var fx *FakeXdsUpdater
 	if x, ok := xdsUpdater.(*FakeXdsUpdater); ok {
 		fx = x
diff --git a/pilot/pkg/xds/fake.go b/pilot/pkg/xds/fake.go
index db895df0e2..b39b4b28d6 100644
--- a/pilot/pkg/xds/fake.go
+++ b/pilot/pkg/xds/fake.go
@@ -43,6 +43,7 @@
 	"istio.io/istio/pilot/pkg/networking/core/v1alpha3"
 	"istio.io/istio/pilot/pkg/networking/plugin"
 	"istio.io/istio/pilot/pkg/serviceregistry"
+	"istio.io/istio/pilot/pkg/serviceregistry/aggregate"
 	kube "istio.io/istio/pilot/pkg/serviceregistry/kube/controller"
 	v3 "istio.io/istio/pilot/pkg/xds/v3"
 	"istio.io/istio/pilot/test/xdstest"
@@ -172,6 +173,7 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 	}
 	creds := kubesecrets.NewMulticluster(opts.DefaultClusterName)
 	s.Generators[v3.SecretType] = NewSecretGen(creds, s.Cache, opts.DefaultClusterName)
+	aggregateRegistry := aggregate.NewController(aggregate.Options{})
 	for k8sCluster, objs := range k8sObjects {
 		client := kubelib.NewFakeClientWithVersion(opts.KubernetesVersion, objs...)
 		if opts.KubeClientModifier != nil {
@@ -186,8 +188,8 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 			NetworksWatcher: opts.NetworksWatcher,
 			Mode:            opts.KubernetesEndpointMode,
 			// we wait for the aggregate to sync
-			SkipCacheSyncWait: true,
-			Stop:              stop,
+			AggregateController: aggregateRegistry,
+			Stop:                stop,
 		})
 		// start default client informers after creating ingress/secret controllers
 		if defaultKubeClient == nil || k8sCluster == opts.DefaultClusterName {
@@ -197,6 +199,7 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 			client.RunAndWait(stop)
 		}
 		registries = append(registries, k8s)
+		aggregateRegistry.AddRegistry(k8s)
 		if err := creds.ClusterAdded(&multicluster.Cluster{ID: k8sCluster, Client: client}, nil); err != nil {
 			t.Fatal(err)
 		}
@@ -218,6 +221,7 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 		ConfigTemplateInput: opts.ConfigTemplateInput,
 		MeshConfig:          opts.MeshConfig,
 		NetworksWatcher:     opts.NetworksWatcher,
+		AggregateRegistry:   aggregateRegistry,
 		ServiceRegistries:   registries,
 		PushContextLock:     &s.updateMutex,
 		ConfigStoreCaches:   []model.ConfigStoreCache{ingr},
@@ -305,9 +309,6 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 	// Start the discovery server
 	s.Start(stop)
 	cg.ServiceEntryRegistry.XdsUpdater = s
-	cache.WaitForCacheSync(stop,
-		cg.Registry.HasSynced,
-		cg.Store().HasSynced)
 	cg.ServiceEntryRegistry.ResyncEDS()
 
 	// Send an update. This ensures that even if there are no configs provided, the push context is
@@ -316,6 +317,9 @@ func NewFakeDiscoveryServer(t test.Failer, opts FakeOptions) *FakeDiscoveryServe
 
 	// Now that handlers are added, get everything started
 	cg.Run()
+	cache.WaitForCacheSync(stop,
+		cg.Registry.HasSynced,
+		cg.Store().HasSynced)
 
 	// Wait until initial updates are committed
 	c := s.InboundUpdates.Load()
-- 
2.35.3

