From b440147dd108362c5c8c31e8f8c4e80ae99ff75f Mon Sep 17 00:00:00 2001
From: Frank Budinsky <frankb@ca.ibm.com>
Date: Mon, 18 Apr 2022 13:13:14 -0400
Subject: Prioritize local over remote leader (#38219)

* Prioritize local over remote leader

* Fix trim prefix

* check local only if prioritized

* more testing

* fix lint

* make test table driven

* John's test

* move LeaderElection type to test
---
 pilot/pkg/leaderelection/leaderelection.go    |  41 ++++--
 .../pkg/leaderelection/leaderelection_test.go | 118 ++++++++++++++++++
 .../kube/controller/multicluster.go           |   2 +-
 3 files changed, 153 insertions(+), 8 deletions(-)

diff --git a/pilot/pkg/leaderelection/leaderelection.go b/pilot/pkg/leaderelection/leaderelection.go
index ce95d5b227..16a6f7508f 100644
--- a/pilot/pkg/leaderelection/leaderelection.go
+++ b/pilot/pkg/leaderelection/leaderelection.go
@@ -18,6 +18,7 @@
 	"context"
 	"fmt"
 	"os"
+	"strings"
 	"sync"
 	"time"
 
@@ -51,6 +52,9 @@
 	AnalyzeController           = "istio-analyze-leader"
 )
 
+// Leader election key prefix for remote istiod managed clusters
+const remoteIstiodPrefix = "^"
+
 type LeaderElection struct {
 	namespace string
 	name      string
@@ -60,6 +64,7 @@ type LeaderElection struct {
 
 	// Criteria to determine leader priority.
 	revision       string
+	remote         bool
 	prioritized    bool
 	defaultWatcher revisions.DefaultWatcher
 
@@ -119,14 +124,20 @@ func (l *LeaderElection) create() (*k8sleaderelection.LeaderElector, error) {
 			log.Infof("leader election lock lost: %v", l.electionID)
 		},
 	}
+
+	key := l.revision
+	if l.remote {
+		key = remoteIstiodPrefix + key
+	}
 	lock := k8sresourcelock.ConfigMapLock{
 		ConfigMapMeta: metaV1.ObjectMeta{Namespace: l.namespace, Name: l.electionID},
 		Client:        l.client.CoreV1(),
 		LockConfig: k8sresourcelock.ResourceLockConfig{
 			Identity: l.name,
-			Key:      l.revision,
+			Key:      key,
 		},
 	}
+
 	config := k8sleaderelection.LeaderElectionConfig{
 		Lock:          &lock,
 		LeaseDuration: l.ttl,
@@ -140,18 +151,29 @@ func (l *LeaderElection) create() (*k8sleaderelection.LeaderElector, error) {
 	}
 
 	if l.prioritized {
-		// Function to use to decide whether this revision should steal the existing lock.
-		config.KeyComparison = func(currentLeaderRevision string) bool {
-			defaultRevision := l.defaultWatcher.GetDefault()
-			return l.revision != currentLeaderRevision &&
-				// empty default revision indicates that there is no default set
-				defaultRevision != "" && defaultRevision == l.revision
+		// Function to use to decide whether this leader should steal the existing lock.
+		config.KeyComparison = func(leaderKey string) bool {
+			return LocationPrioritizedComparison(leaderKey, l)
 		}
 	}
 
 	return k8sleaderelection.NewLeaderElector(config)
 }
 
+func LocationPrioritizedComparison(currentLeaderRevision string, l *LeaderElection) bool {
+	var currentLeaderRemote bool
+	if currentLeaderRemote = strings.HasPrefix(currentLeaderRevision, remoteIstiodPrefix); currentLeaderRemote {
+		currentLeaderRevision = strings.TrimPrefix(currentLeaderRevision, remoteIstiodPrefix)
+	}
+	defaultRevision := l.defaultWatcher.GetDefault()
+	if l.revision != currentLeaderRevision && defaultRevision != "" && defaultRevision == l.revision {
+		// Always steal the lock if the new one is the default revision and the current one is not
+		return true
+	}
+	// Otherwise steal the lock if the new one and the current one are the same revision, but new one is local and current is remote
+	return l.revision == currentLeaderRevision && !l.remote && currentLeaderRemote
+}
+
 // AddRunFunction registers a function to run when we are the leader. These will be run asynchronously.
 // To avoid running when not a leader, functions should respect the stop channel.
 func (l *LeaderElection) AddRunFunction(f func(stop <-chan struct{})) *LeaderElection {
@@ -160,6 +182,10 @@ func (l *LeaderElection) AddRunFunction(f func(stop <-chan struct{})) *LeaderEle
 }
 
 func NewLeaderElection(namespace, name, electionID, revision string, client kube.Client) *LeaderElection {
+	return NewLeaderElectionMulticluster(namespace, name, electionID, revision, false, client)
+}
+
+func NewLeaderElectionMulticluster(namespace, name, electionID, revision string, remote bool, client kube.Client) *LeaderElection {
 	var watcher revisions.DefaultWatcher
 	if features.PrioritizedLeaderElection {
 		watcher = revisions.NewDefaultWatcher(client, revision)
@@ -174,6 +200,7 @@ func NewLeaderElection(namespace, name, electionID, revision string, client kube
 		client:         client,
 		electionID:     electionID,
 		revision:       revision,
+		remote:         remote,
 		prioritized:    features.PrioritizedLeaderElection,
 		defaultWatcher: watcher,
 		// Default to a 30s ttl. Overridable for tests
diff --git a/pilot/pkg/leaderelection/leaderelection_test.go b/pilot/pkg/leaderelection/leaderelection_test.go
index cf372e370d..b142e56499 100644
--- a/pilot/pkg/leaderelection/leaderelection_test.go
+++ b/pilot/pkg/leaderelection/leaderelection_test.go
@@ -38,6 +38,15 @@ func createElection(t *testing.T,
 	watcher revisions.DefaultWatcher,
 	prioritized, expectLeader bool,
 	client kubernetes.Interface, fns ...func(stop <-chan struct{})) (*LeaderElection, chan struct{}) {
+	return createElectionMulticluster(t, name, revision, false, watcher, prioritized, expectLeader, client, fns...)
+}
+
+func createElectionMulticluster(t *testing.T,
+	name, revision string,
+	remote bool,
+	watcher revisions.DefaultWatcher,
+	prioritized, expectLeader bool,
+	client kubernetes.Interface, fns ...func(stop <-chan struct{})) (*LeaderElection, chan struct{}) {
 	t.Helper()
 	l := &LeaderElection{
 		namespace:      "ns",
@@ -45,6 +54,7 @@ func createElection(t *testing.T,
 		electionID:     testLock,
 		client:         client,
 		revision:       revision,
+		remote:         remote,
 		prioritized:    prioritized,
 		defaultWatcher: watcher,
 		ttl:            time.Second,
@@ -124,9 +134,117 @@ func TestPrioritizedLeaderElection(t *testing.T) {
 	// Test that "red" doesn't steal lock if "prioritized" is disabled
 	_, stop7 := createElection(t, "pod5", "red", watcher, false, false, client)
 	close(stop6)
+
 	close(stop7)
 }
 
+func TestMulticlusterLeaderElection(t *testing.T) {
+	client := fake.NewSimpleClientset()
+	watcher := &fakeDefaultWatcher{}
+	// First remote pod becomes the leader
+	_, stop := createElectionMulticluster(t, "pod1", "", true, watcher, false, true, client)
+	// A new local pod cannot become leader
+	_, stop2 := createElectionMulticluster(t, "pod2", "", false, watcher, false, false, client)
+	// A new remote pod cannot become leader
+	_, stop3 := createElectionMulticluster(t, "pod3", "", true, watcher, false, false, client)
+	close(stop3)
+	close(stop2)
+	close(stop)
+}
+
+func TestPrioritizedMulticlusterLeaderElection(t *testing.T) {
+	client := fake.NewSimpleClientset()
+	watcher := &fakeDefaultWatcher{defaultRevision: "red"}
+
+	// First pod, revision "green" becomes the remote leader
+	_, stop := createElectionMulticluster(t, "pod1", "green", true, watcher, true, true, client)
+	// Second pod, revision "red", steals the leader lock from "green" since it is the default revision
+	_, stop2 := createElectionMulticluster(t, "pod2", "red", true, watcher, true, true, client)
+	// Third pod with revision "red" comes in and can take the lock since it is a local revision "red"
+	_, stop3 := createElectionMulticluster(t, "pod3", "red", false, watcher, true, true, client)
+	// Fourth pod with revision "red" cannot take the lock since it is remote
+	_, stop4 := createElectionMulticluster(t, "pod4", "red", true, watcher, true, false, client)
+	close(stop4)
+	close(stop3)
+	close(stop2)
+	close(stop)
+}
+
+func SimpleRevisionComparison(currentLeaderRevision string, l *LeaderElection) bool {
+	// Old key comparison impl for interoperablilty testing
+	defaultRevision := l.defaultWatcher.GetDefault()
+	return l.revision != currentLeaderRevision &&
+		// empty default revision indicates that there is no default set
+		defaultRevision != "" && defaultRevision == l.revision
+}
+
+type LeaderComparison func(string, *LeaderElection) bool
+
+type instance struct {
+	revision string
+	remote   bool
+	comp     string
+}
+
+func (i instance) GetComp() LeaderComparison {
+	switch i.comp {
+	case "location":
+		return LocationPrioritizedComparison
+	case "simple":
+		return SimpleRevisionComparison
+	default:
+		panic("unknown comparison type")
+	}
+}
+
+// TestPrioritizationCycles
+func TestPrioritizationCycles(t *testing.T) {
+	cases := []instance{}
+	for _, rev := range []string{"", "default", "not-default"} {
+		for _, loc := range []bool{false, true} {
+			for _, comp := range []string{"location", "simple"} {
+				cases = append(cases, instance{
+					revision: rev,
+					remote:   loc,
+					comp:     comp,
+				})
+			}
+		}
+	}
+	for _, start := range cases {
+		t.Run(fmt.Sprint(start), func(t *testing.T) {
+			checkCycles(t, start, cases, nil)
+		})
+	}
+}
+
+func alreadyHit(cur instance, chain []instance) bool {
+	for _, cc := range chain {
+		if cur == cc {
+			return true
+		}
+	}
+	return false
+}
+
+func checkCycles(t *testing.T, start instance, cases []instance, chain []instance) {
+	if alreadyHit(start, chain) {
+		t.Fatalf("cycle on leader election: cur %v, chain %v", start, chain)
+	}
+	for _, nextHop := range cases {
+		next := LeaderElection{
+			remote:         nextHop.remote,
+			defaultWatcher: &fakeDefaultWatcher{defaultRevision: "default"},
+			revision:       nextHop.revision,
+		}
+		if nextHop.GetComp()(start.revision, &next) {
+			nc := append([]instance{}, chain...)
+			nc = append(nc, start)
+			checkCycles(t, nextHop, cases, nc)
+		}
+	}
+}
+
 func TestLeaderElectionConfigMapRemoved(t *testing.T) {
 	client := fake.NewSimpleClientset()
 	watcher := &fakeDefaultWatcher{}
diff --git a/pilot/pkg/serviceregistry/kube/controller/multicluster.go b/pilot/pkg/serviceregistry/kube/controller/multicluster.go
index 376487f833..87b67b2742 100644
--- a/pilot/pkg/serviceregistry/kube/controller/multicluster.go
+++ b/pilot/pkg/serviceregistry/kube/controller/multicluster.go
@@ -210,7 +210,7 @@ func (m *Multicluster) ClusterAdded(cluster *multicluster.Cluster, clusterStopCh
 			log.Infof("joining leader-election for %s in %s on cluster %s",
 				leaderelection.NamespaceController, options.SystemNamespace, options.ClusterID)
 			leaderelection.
-				NewLeaderElection(options.SystemNamespace, m.serverID, leaderelection.NamespaceController, m.revision, client).
+				NewLeaderElectionMulticluster(options.SystemNamespace, m.serverID, leaderelection.NamespaceController, m.revision, !localCluster, client).
 				AddRunFunction(func(leaderStop <-chan struct{}) {
 					log.Infof("starting namespace controller for cluster %s", cluster.ID)
 					nc := NewNamespaceController(client, m.caBundleWatcher)
-- 
2.35.3

