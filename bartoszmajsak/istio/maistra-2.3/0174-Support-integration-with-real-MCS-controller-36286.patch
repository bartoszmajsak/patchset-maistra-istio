From 3a6e3e58faa2520a1036aedf5394cce512a52c04 Mon Sep 17 00:00:00 2001
From: Nathan Mittler <nmittler@gmail.com>
Date: Tue, 30 Nov 2021 13:25:46 -0800
Subject: Support integration with real MCS controller (#36286)

---
 pilot/pkg/model/addressmap.go                 |   5 +-
 .../kube/controller/controller.go             |   6 +-
 .../kube/controller/serviceimportcache.go     | 106 +++++++------
 pkg/kube/mcs/register.go                      |  13 +-
 pkg/test/framework/components/echo/call.go    |  13 +-
 .../components/environment/kube/settings.go   |   8 +
 .../pilot/mcs/autoexport/autoexport_test.go   |   8 +-
 tests/integration/pilot/mcs/common/common.go  |  65 ++++++--
 .../discoverability/discoverability_test.go   | 150 ++++++++++++------
 9 files changed, 241 insertions(+), 133 deletions(-)

diff --git a/pilot/pkg/model/addressmap.go b/pilot/pkg/model/addressmap.go
index 4570a08d56..608a6b973c 100644
--- a/pilot/pkg/model/addressmap.go
+++ b/pilot/pkg/model/addressmap.go
@@ -22,8 +22,9 @@
 
 // AddressMap provides a thread-safe mapping of addresses for each Kubernetes cluster.
 type AddressMap struct {
-	// Addresses hold the underlying map. Visible only for testing, for the purposes of simplified construction.
-	// Production code should never access this directly.
+	// Addresses hold the underlying map. Most code should only access this through the available methods.
+	// Should only be used by tests and construction/initialization logic, where there is no concern
+	// for race conditions.
 	Addresses map[cluster.ID][]string
 
 	// NOTE: The copystructure library is not able to copy unexported fields, so the mutex will not be copied.
diff --git a/pilot/pkg/serviceregistry/kube/controller/controller.go b/pilot/pkg/serviceregistry/kube/controller/controller.go
index a88e45e4f1..da8773a8e0 100644
--- a/pilot/pkg/serviceregistry/kube/controller/controller.go
+++ b/pilot/pkg/serviceregistry/kube/controller/controller.go
@@ -544,7 +544,7 @@ func (c *Controller) onServiceEvent(curr interface{}, event model.Event) error {
 	case model.EventDelete:
 		c.deleteService(svcConv)
 	default:
-		c.addOrUpdateService(svc, svcConv, event)
+		c.addOrUpdateService(svc, svcConv, event, false)
 	}
 
 	return nil
@@ -571,7 +571,7 @@ func (c *Controller) deleteService(svc *model.Service) {
 	c.handlers.NotifyServiceHandlers(svc, event)
 }
 
-func (c *Controller) addOrUpdateService(svc *v1.Service, svcConv *model.Service, event model.Event) {
+func (c *Controller) addOrUpdateService(svc *v1.Service, svcConv *model.Service, event model.Event, updateEDSCache bool) {
 	needsFullPush := false
 	// First, process nodePort gateway service, whose externalIPs specified
 	// and loadbalancer gateway service
@@ -606,7 +606,7 @@ func (c *Controller) addOrUpdateService(svc *v1.Service, svcConv *model.Service,
 	// We also need to update when the Service changes. For Kubernetes, a service change will result in Endpoint updates,
 	// but workload entries will also need to be updated.
 	// TODO(nmittler): Build different sets of endpoints for cluster.local and clusterset.local.
-	endpoints := c.buildEndpointsForService(svcConv, false)
+	endpoints := c.buildEndpointsForService(svcConv, updateEDSCache)
 	ns := svcConv.Attributes.Namespace
 	if len(endpoints) > 0 {
 		c.opts.XDSUpdater.EDSCacheUpdate(shard, string(svcConv.Hostname), ns, endpoints)
diff --git a/pilot/pkg/serviceregistry/kube/controller/serviceimportcache.go b/pilot/pkg/serviceregistry/kube/controller/serviceimportcache.go
index 18b14db8c7..4a0b7b7ef4 100644
--- a/pilot/pkg/serviceregistry/kube/controller/serviceimportcache.go
+++ b/pilot/pkg/serviceregistry/kube/controller/serviceimportcache.go
@@ -16,6 +16,8 @@
 
 import (
 	"fmt"
+	"net"
+	"sort"
 	"strings"
 
 	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
@@ -25,6 +27,7 @@
 
 	"istio.io/istio/pilot/pkg/features"
 	"istio.io/istio/pilot/pkg/model"
+	"istio.io/istio/pilot/pkg/networking/util"
 	"istio.io/istio/pilot/pkg/serviceregistry/kube"
 	"istio.io/istio/pkg/cluster"
 	"istio.io/istio/pkg/config/constants"
@@ -57,7 +60,6 @@ type importedService struct {
 // The real k8s Service can live anywhere in the mesh and does not have to reside in the same
 // cluster as the ServiceImport.
 type serviceImportCache interface {
-	GetClusterSetIPs(name types.NamespacedName) []string
 	HasSynced() bool
 	ImportedServices() []importedService
 }
@@ -107,7 +109,7 @@ func (ic *serviceImportCacheImpl) onServiceEvent(svc *model.Service, event model
 
 	// Get the ClusterSet VIPs for this service in this cluster. Will only be populated if the
 	// service has a ServiceImport in this cluster.
-	vips := ic.GetClusterSetIPs(namespacedName)
+	vips := ic.getClusterSetIPs(namespacedName)
 
 	if event == model.EventDelete || len(vips) == 0 {
 		if prevMcsService != nil {
@@ -124,19 +126,7 @@ func (ic *serviceImportCacheImpl) onServiceEvent(svc *model.Service, event model
 	}
 
 	mcsService := ic.genMCSService(svc, mcsHost, vips)
-	ic.addOrUpdateService(nil, mcsService, event)
-}
-
-func getServiceImportIPs(si *unstructured.Unstructured) []string {
-	var ips []string
-	if spec, ok := si.Object["spec"].(map[string]interface{}); ok {
-		if rawIPs, ok := spec["ips"].([]interface{}); ok {
-			for _, rawIP := range rawIPs {
-				ips = append(ips, rawIP.(string))
-			}
-		}
-	}
-	return ips
+	ic.addOrUpdateService(nil, mcsService, event, false)
 }
 
 func (ic *serviceImportCacheImpl) onServiceImportEvent(obj interface{}, event model.Event) error {
@@ -159,7 +149,7 @@ func (ic *serviceImportCacheImpl) onServiceImportEvent(obj interface{}, event mo
 	mcsHost := serviceClusterSetLocalHostnameForKR(si)
 	mcsService := ic.GetService(mcsHost)
 
-	ips := getServiceImportIPs(si)
+	ips := GetServiceImportIPs(si)
 	if mcsService == nil {
 		if event == model.EventDelete || len(ips) == 0 {
 			// We never created the service. Nothing to delete.
@@ -189,48 +179,78 @@ func (ic *serviceImportCacheImpl) onServiceImportEvent(obj interface{}, event mo
 		// The service already existed. Treat it as an update.
 		event = model.EventUpdate
 
-		// Update the VIPs
-		mcsService.ClusterVIPs.SetAddressesFor(ic.Cluster(), ips)
-		needsFullPush = true
+		if ic.updateIPs(mcsService, ips) {
+			needsFullPush = true
+		}
 	}
 
-	ic.addOrUpdateService(nil, mcsService, event)
+	// Always force a rebuild of the endpoint cache in case this import caused
+	// a change to the discoverability policy.
+	ic.addOrUpdateService(nil, mcsService, event, true)
 
 	if needsFullPush {
-		pushReq := &model.PushRequest{
-			Full: true,
-			ConfigsUpdated: map[model.ConfigKey]struct{}{{
-				Kind:      gvk.ServiceEntry,
-				Name:      mcsHost.String(),
-				Namespace: si.GetNamespace(),
-			}: {}},
-			Reason: []model.TriggerReason{model.ServiceUpdate},
-		}
-		ic.opts.XDSUpdater.ConfigUpdate(pushReq)
+		ic.doFullPush(mcsHost, si.GetNamespace())
 	}
 
 	return nil
 }
 
+func (ic *serviceImportCacheImpl) updateIPs(mcsService *model.Service, ips []string) (updated bool) {
+	prevIPs := mcsService.ClusterVIPs.GetAddressesFor(ic.Cluster())
+	if !util.StringSliceEqual(prevIPs, ips) {
+		// Update the VIPs
+		mcsService.ClusterVIPs.SetAddressesFor(ic.Cluster(), ips)
+		updated = true
+	}
+	return
+}
+
+func (ic *serviceImportCacheImpl) doFullPush(mcsHost host.Name, ns string) {
+	pushReq := &model.PushRequest{
+		Full: true,
+		ConfigsUpdated: map[model.ConfigKey]struct{}{{
+			Kind:      gvk.ServiceEntry,
+			Name:      mcsHost.String(),
+			Namespace: ns,
+		}: {}},
+		Reason: []model.TriggerReason{model.ServiceUpdate},
+	}
+	ic.opts.XDSUpdater.ConfigUpdate(pushReq)
+}
+
+// GetServiceImportIPs returns the list of ClusterSet IPs for the ServiceImport.
+// Exported for testing only.
+func GetServiceImportIPs(si *unstructured.Unstructured) []string {
+	var ips []string
+	if spec, ok := si.Object["spec"].(map[string]interface{}); ok {
+		if rawIPs, ok := spec["ips"].([]interface{}); ok {
+			for _, rawIP := range rawIPs {
+				ip := rawIP.(string)
+				if net.ParseIP(ip) != nil {
+					ips = append(ips, ip)
+				}
+			}
+		}
+	}
+	sort.Strings(ips)
+	return ips
+}
+
+// genMCSService generates an MCS service based on the given real k8s service. The list of vips must be non-empty.
 func (ic *serviceImportCacheImpl) genMCSService(realService *model.Service, mcsHost host.Name, vips []string) *model.Service {
 	mcsService := realService.DeepCopy()
 	mcsService.Hostname = mcsHost
-
-	if len(vips) > 0 {
-		mcsService.DefaultAddress = vips[0]
-		mcsService.ClusterVIPs.SetAddresses(map[cluster.ID][]string{
-			ic.Cluster(): vips,
-		})
-	} else {
-		mcsService.DefaultAddress = ""
-		mcsService.ClusterVIPs.SetAddresses(nil)
+	mcsService.DefaultAddress = vips[0]
+	mcsService.ClusterVIPs.Addresses = map[cluster.ID][]string{
+		ic.Cluster(): vips,
 	}
+
 	return mcsService
 }
 
-func (ic *serviceImportCacheImpl) GetClusterSetIPs(name types.NamespacedName) []string {
+func (ic *serviceImportCacheImpl) getClusterSetIPs(name types.NamespacedName) []string {
 	if si, err := ic.lister.ByNamespace(name.Namespace).Get(name.Name); err == nil {
-		return getServiceImportIPs(si.(*unstructured.Unstructured))
+		return GetServiceImportIPs(si.(*unstructured.Unstructured))
 	}
 	return nil
 }
@@ -275,10 +295,6 @@ type disabledServiceImportCache struct{
 
 var _ serviceImportCache = disabledServiceImportCache{}
 
-func (c disabledServiceImportCache) GetClusterSetIPs(types.NamespacedName) []string {
-	return nil
-}
-
 func (c disabledServiceImportCache) HasSynced() bool {
 	return true
 }
diff --git a/pkg/kube/mcs/register.go b/pkg/kube/mcs/register.go
index ab843808e9..876927a03f 100644
--- a/pkg/kube/mcs/register.go
+++ b/pkg/kube/mcs/register.go
@@ -32,17 +32,8 @@
 	// MCSSchemeGroupVersion is group version used to register Kubernetes Multi-Cluster Services (MCS) objects
 	MCSSchemeGroupVersion = schema.GroupVersion{Group: features.MCSAPIGroup, Version: features.MCSAPIVersion}
 
-	ServiceExportGVR = schema.GroupVersionResource{
-		Group:    features.MCSAPIGroup,
-		Version:  features.MCSAPIVersion,
-		Resource: "serviceexports",
-	}
-
-	ServiceImportGVR = schema.GroupVersionResource{
-		Group:    features.MCSAPIGroup,
-		Version:  features.MCSAPIVersion,
-		Resource: "serviceimports",
-	}
+	ServiceExportGVR = MCSSchemeGroupVersion.WithResource("serviceexports")
+	ServiceImportGVR = MCSSchemeGroupVersion.WithResource("serviceimports")
 )
 
 func init() {
diff --git a/pkg/test/framework/components/echo/call.go b/pkg/test/framework/components/echo/call.go
index 5611f570e9..9493fb13d8 100644
--- a/pkg/test/framework/components/echo/call.go
+++ b/pkg/test/framework/components/echo/call.go
@@ -149,7 +149,7 @@ type Validator interface {
 func (all validators) Validate(inResp client.ParsedResponses, err error) error {
 	if len(all) == 0 {
 		// By default, just assume no error.
-		return expectNoError.Validate(inResp, err)
+		return ExpectNoError().Validate(inResp, err)
 	}
 
 	for _, v := range all {
@@ -187,16 +187,21 @@ func (all validators) And(v Validator) Validator {
 	})
 )
 
-// ExpectError returns a Validator that is completed when an error occurs.
+// ExpectNoError returns a Validator that fails if the call returned an error.
+func ExpectNoError() Validator {
+	return expectNoError
+}
+
+// ExpectError returns a Validator that fails if the call did not return an error.
 func ExpectError() Validator {
 	return expectError
 }
 
 // ExpectOK returns a Validator that calls CheckOK on the given responses.
 func ExpectOK() Validator {
-	return ValidatorFunc(func(resp client.ParsedResponses, err error) error {
+	return And(ExpectNoError(), ValidatorFunc(func(resp client.ParsedResponses, err error) error {
 		return resp.CheckOK()
-	})
+	}))
 }
 
 // ExpectReachedClusters returns a Validator that checks that all provided clusters are reached.
diff --git a/pkg/test/framework/components/environment/kube/settings.go b/pkg/test/framework/components/environment/kube/settings.go
index 0c66e5f997..0f420c626f 100644
--- a/pkg/test/framework/components/environment/kube/settings.go
+++ b/pkg/test/framework/components/environment/kube/settings.go
@@ -224,6 +224,14 @@ func (s *Settings) MCSAPIGroupVersion() schema.GroupVersion {
 	}
 }
 
+func (s *Settings) ServiceExportGVR() schema.GroupVersionResource {
+	return s.MCSAPIGroupVersion().WithResource("serviceexports")
+}
+
+func (s *Settings) ServiceImportGVR() schema.GroupVersionResource {
+	return s.MCSAPIGroupVersion().WithResource("serviceimports")
+}
+
 // String implements fmt.Stringer
 func (s *Settings) String() string {
 	result := ""
diff --git a/tests/integration/pilot/mcs/autoexport/autoexport_test.go b/tests/integration/pilot/mcs/autoexport/autoexport_test.go
index 4aaed23352..6fd5eb2ef0 100644
--- a/tests/integration/pilot/mcs/autoexport/autoexport_test.go
+++ b/tests/integration/pilot/mcs/autoexport/autoexport_test.go
@@ -27,7 +27,6 @@
 	k8sErrors "k8s.io/apimachinery/pkg/api/errors"
 	v1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 
-	"istio.io/istio/pkg/kube/mcs"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/echo"
 	"istio.io/istio/pkg/test/framework/components/istio"
@@ -58,6 +57,7 @@ func TestAutoExport(t *testing.T) {
 	framework.NewTest(t).
 		Features("traffic.mcs.autoexport").
 		Run(func(ctx framework.TestContext) {
+			serviceExportGVR := common.KubeSettings(ctx).ServiceExportGVR()
 			// Verify that ServiceExport is created automatically for services.
 			ctx.NewSubTest("exported").RunParallel(
 				func(ctx framework.TestContext) {
@@ -67,7 +67,7 @@ func(ctx framework.TestContext) {
 							// Verify that the ServiceExport was created.
 							ctx.NewSubTest("create").Run(func(ctx framework.TestContext) {
 								retry.UntilSuccessOrFail(ctx, func() error {
-									serviceExport, err := cluster.Dynamic().Resource(mcs.ServiceExportGVR).Namespace(echos.Namespace).Get(
+									serviceExport, err := cluster.Dynamic().Resource(serviceExportGVR).Namespace(echos.Namespace).Get(
 										context.TODO(), common.ServiceB, v1.GetOptions{})
 									if err != nil {
 										return err
@@ -91,7 +91,7 @@ func(ctx framework.TestContext) {
 										echos.Namespace, common.ServiceB, cluster.Name(), err)
 								}
 								retry.UntilSuccessOrFail(t, func() error {
-									_, err := cluster.Dynamic().Resource(mcs.ServiceExportGVR).Namespace(echos.Namespace).Get(
+									_, err := cluster.Dynamic().Resource(serviceExportGVR).Namespace(echos.Namespace).Get(
 										context.TODO(), common.ServiceB, v1.GetOptions{})
 
 									if err != nil && k8sErrors.IsNotFound(err) {
@@ -118,7 +118,7 @@ func(ctx framework.TestContext) {
 				for i, cluster := range ctx.Clusters() {
 					cluster := cluster
 					ctx.NewSubTest(strconv.Itoa(i)).RunParallel(func(ctx framework.TestContext) {
-						services, err := cluster.Dynamic().Resource(mcs.ServiceExportGVR).Namespace(ns).List(
+						services, err := cluster.Dynamic().Resource(serviceExportGVR).Namespace(ns).List(
 							context.TODO(), v1.ListOptions{})
 						if err != nil {
 							ctx.Fatal(err)
diff --git a/tests/integration/pilot/mcs/common/common.go b/tests/integration/pilot/mcs/common/common.go
index b97f26cb49..bb88bab8f0 100644
--- a/tests/integration/pilot/mcs/common/common.go
+++ b/tests/integration/pilot/mcs/common/common.go
@@ -18,8 +18,13 @@
 package common
 
 import (
+	"context"
+	"fmt"
 	"os"
 
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+
+	"istio.io/istio/pkg/test/framework/components/cluster"
 	"istio.io/istio/pkg/test/framework/components/echo"
 	"istio.io/istio/pkg/test/framework/components/echo/common"
 	"istio.io/istio/pkg/test/framework/components/echo/echoboot"
@@ -43,29 +48,41 @@ func KubeSettings(t resource.Context) *kube.Settings {
 }
 
 func InstallMCSCRDs(t resource.Context) error {
-	if !IsMCSControllerEnabled(t) {
-		params := struct {
-			Group   string
-			Version string
-		}{
-			Group:   KubeSettings(t).MCSAPIGroup,
-			Version: KubeSettings(t).MCSAPIVersion,
+	params := struct {
+		Group   string
+		Version string
+	}{
+		Group:   KubeSettings(t).MCSAPIGroup,
+		Version: KubeSettings(t).MCSAPIVersion,
+	}
+
+	for _, kind := range []string{"serviceexport", "serviceimport"} {
+		// Generate the CRD YAML
+		fileName := fmt.Sprintf("mcs-%s-crd.yaml", kind)
+		crdTemplate, err := os.ReadFile("../../testdata/" + fileName)
+		if err != nil {
+			return err
 		}
-		for _, f := range []string{"mcs-serviceexport-crd.yaml", "mcs-serviceimport-crd.yaml"} {
-			crdTemplate, err := os.ReadFile("../../testdata/" + f)
-			if err != nil {
-				return err
-			}
-			crd, err := tmpl.Evaluate(string(crdTemplate), params)
-			if err != nil {
-				return err
+		crdYAML, err := tmpl.Evaluate(string(crdTemplate), params)
+		if err != nil {
+			return err
+		}
+
+		// Make sure the CRD exists in each cluster.
+		for _, c := range t.Clusters() {
+			crdName := fmt.Sprintf("%ss.%s", kind, params.Group)
+			if isCRDInstalled(c, crdName, params.Version) {
+				// It's already installed on this cluster - nothing to do.
+				continue
 			}
+
+			// Add/Update the CRD in this cluster...
 			if t.Settings().NoCleanup {
-				if err := t.ConfigKube().ApplyYAMLNoCleanup("", crd); err != nil {
+				if err := t.ConfigKube(c).ApplyYAMLNoCleanup("", crdYAML); err != nil {
 					return err
 				}
 			} else {
-				if err := t.ConfigKube().ApplyYAML("", crd); err != nil {
+				if err := t.ConfigKube(c).ApplyYAML("", crdYAML); err != nil {
 					return err
 				}
 			}
@@ -74,6 +91,20 @@ func InstallMCSCRDs(t resource.Context) error {
 	return nil
 }
 
+func isCRDInstalled(c cluster.Cluster, crdName string, version string) bool {
+	crd, err := c.Ext().ApiextensionsV1().CustomResourceDefinitions().Get(context.TODO(), crdName, metav1.GetOptions{})
+	if err == nil {
+		// Found the CRD, now check against the version.
+		for _, v := range crd.Spec.Versions {
+			if v.Name == version {
+				// The CRD is already installed on this cluster.
+				return true
+			}
+		}
+	}
+	return false
+}
+
 type EchoDeployment struct {
 	Namespace string
 	echo.Instances
diff --git a/tests/integration/pilot/mcs/discoverability/discoverability_test.go b/tests/integration/pilot/mcs/discoverability/discoverability_test.go
index b1f6f16936..89df418381 100644
--- a/tests/integration/pilot/mcs/discoverability/discoverability_test.go
+++ b/tests/integration/pilot/mcs/discoverability/discoverability_test.go
@@ -21,6 +21,7 @@
 	"context"
 	"fmt"
 	"sort"
+	"strings"
 	"sync"
 	"testing"
 	"time"
@@ -32,11 +33,14 @@
 	kubeMeta "k8s.io/apimachinery/pkg/apis/meta/v1"
 	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
 	"k8s.io/apimachinery/pkg/runtime"
+	"k8s.io/apimachinery/pkg/runtime/schema"
 	mcsapi "sigs.k8s.io/mcs-api/pkg/apis/v1alpha1"
 	"sigs.k8s.io/yaml"
 
 	"istio.io/api/annotation"
+	kube "istio.io/istio/pilot/pkg/serviceregistry/kube/controller"
 	"istio.io/istio/pkg/kube/mcs"
+	echoClient "istio.io/istio/pkg/test/echo/client"
 	"istio.io/istio/pkg/test/framework"
 	"istio.io/istio/pkg/test/framework/components/cluster"
 	"istio.io/istio/pkg/test/framework/components/echo"
@@ -78,7 +82,6 @@ func TestMain(m *testing.M) {
 		Setup(common.InstallMCSCRDs).
 		Setup(istio.Setup(&i, enableMCSServiceDiscovery)).
 		Setup(common.DeployEchosFunc("mcs", &echos)).
-		Setup(importServiceInAllClusters).
 		Run()
 }
 
@@ -92,9 +95,17 @@ func TestClusterLocal(t *testing.T) {
 			for _, ht := range hostTypes {
 				t.NewSubTest(ht.String()).Run(func(t framework.TestContext) {
 					runForAllClusterCombinations(t, func(t framework.TestContext, src echo.Instance, dst echo.Instances) {
-						// Ensure that all requests stay in the same cluster
-						expectedClusters := cluster.Clusters{src.Config().Cluster}
-						checkClustersReached(t, ht, src, dst[0], expectedClusters)
+						var validator echo.Validator
+						if ht == hostTypeClusterLocal {
+							// For calls to cluster.local, ensure that all requests stay in the same cluster
+							expectedClusters := cluster.Clusters{src.Config().Cluster}
+							validator = validateClustersReached(expectedClusters)
+						} else {
+							// For calls to clusterset.local, we should fail DNS lookup. The clusterset.local host
+							// is only available for a service when it is exported in at least one cluster.
+							validator = validateDNSLookupFailed()
+						}
+						callAndValidate(t, ht, src, dst[0], validator)
 					})
 				})
 			}
@@ -119,7 +130,7 @@ func TestMeshWide(t *testing.T) {
 							// Ensure that requests to clusterset.local reach all destination clusters.
 							expectedClusters = dst.Clusters()
 						}
-						checkClustersReached(t, ht, src, dst[0], expectedClusters)
+						callAndValidate(t, ht, src, dst[0], validateClustersReached(expectedClusters))
 					})
 				})
 			}
@@ -160,7 +171,7 @@ func TestServiceExportedInOneCluster(t *testing.T) {
 											expectedClusters = append(expectedClusters, src.Config().Cluster)
 										}
 									}
-									checkClustersReached(t, ht, src, dst[0], expectedClusters)
+									callAndValidate(t, ht, src, dst[0], validateClustersReached(expectedClusters))
 								})
 							})
 						}
@@ -184,31 +195,6 @@ func enableMCSServiceDiscovery(t resource.Context, cfg *istio.Config) {
 		common.KubeSettings(t).MCSAPIVersion)
 }
 
-func importServiceInAllClusters(t resource.Context) error {
-	if common.IsMCSControllerEnabled(t) {
-		// There is a real MCS controller running. No need to manually import the service.
-		return nil
-	}
-
-	clusters := echos.Match(echo.Service(common.ServiceB)).Clusters()
-	grp := errgroup.Group{}
-	for _, c := range clusters {
-		c := c
-		grp.Go(func() error {
-			// Generate a dummy service in the cluster to reserve the ClusterSet VIP.
-			clusterSetIPSvc, err := genClusterSetIPService(c)
-			if err != nil {
-				return err
-			}
-
-			// Create a ServiceImport in the cluster with the ClusterSet VIP.
-			return createServiceImport(t, c, clusterSetIPSvc.Spec.ClusterIP)
-		})
-	}
-
-	return grp.Wait()
-}
-
 func runForAllClusterCombinations(
 	t framework.TestContext,
 	fn func(t framework.TestContext, src echo.Instance, dst echo.Instances)) {
@@ -220,11 +206,11 @@ func runForAllClusterCombinations(
 		Run(fn)
 }
 
-func newServiceExport(t resource.Context, service string) *mcsapi.ServiceExport {
+func newServiceExport(service string, serviceExportGVR schema.GroupVersionResource) *mcsapi.ServiceExport {
 	return &mcsapi.ServiceExport{
 		TypeMeta: kubeMeta.TypeMeta{
 			Kind:       "ServiceExport",
-			APIVersion: common.KubeSettings(t).MCSAPIGroupVersion().String(),
+			APIVersion: serviceExportGVR.GroupVersion().String(),
 		},
 		ObjectMeta: kubeMeta.ObjectMeta{
 			Name:      service,
@@ -233,7 +219,20 @@ func newServiceExport(t resource.Context, service string) *mcsapi.ServiceExport
 	}
 }
 
-func checkClustersReached(t framework.TestContext, ht hostType, src, dest echo.Instance, clusters cluster.Clusters) {
+func validateClustersReached(clusters cluster.Clusters) echo.Validator {
+	return echo.And(echo.ExpectOK(), echo.ExpectReachedClusters(clusters))
+}
+
+func validateDNSLookupFailed() echo.Validator {
+	return echo.And(echo.ExpectError(), echo.ValidatorFunc(func(_ echoClient.ParsedResponses, err error) error {
+		if strings.Contains(err.Error(), "no such host") {
+			return nil
+		}
+		return err
+	}))
+}
+
+func callAndValidate(t framework.TestContext, ht hostType, src, dest echo.Instance, validator echo.Validator) {
 	t.Helper()
 
 	var address string
@@ -249,7 +248,7 @@ func checkClustersReached(t framework.TestContext, ht hostType, src, dest echo.I
 		Target:    dest,
 		Count:     20,
 		PortName:  "http",
-		Validator: echo.And(echo.ExpectOK(), echo.ExpectReachedClusters(clusters)),
+		Validator: validator,
 	}, retry.Delay(time.Millisecond*500), retryTimeout)
 	if err != nil {
 		t.Fatalf("failed calling host %s: %v\nCluster Details:\n%s", address, err,
@@ -275,7 +274,7 @@ type Details struct {
 		From     string     `json:"from"`
 		To       string     `json:"to"`
 		Outbound []Outbound `json:"outbound"`
-		IPs      []IPs      `json:"clusters"`
+		IPs      []IPs      `json:"ips"`
 	}
 	details := Details{
 		From: src.Config().Cluster.Name(),
@@ -342,9 +341,16 @@ type Details struct {
 	return string(detailsYAML)
 }
 
-func createAndCleanupServiceExport(t framework.TestContext, service string, clusters cluster.Clusters) {
+func createAndCleanupServiceExport(t framework.TestContext, service string, exportClusters cluster.Clusters) {
 	t.Helper()
-	serviceExport := newServiceExport(t, service)
+
+	start := time.Now()
+	scopes.Framework.Infof("=== BEGIN: Create ServiceExport%v ===", exportClusters.Names())
+
+	serviceExportGVR := common.KubeSettings(t).ServiceExportGVR()
+	serviceImportGVR := common.KubeSettings(t).ServiceImportGVR()
+
+	serviceExport := newServiceExport(service, serviceExportGVR)
 
 	u, err := runtime.DefaultUnstructuredConverter.ToUnstructured(serviceExport)
 	if err != nil {
@@ -353,28 +359,78 @@ func createAndCleanupServiceExport(t framework.TestContext, service string, clus
 
 	// Create the ServiceExports in each cluster concurrently.
 	g := errgroup.Group{}
-	for _, c := range clusters {
+	for _, c := range exportClusters {
 		c := c
 		g.Go(func() error {
-			_, err := c.Dynamic().Resource(mcs.ServiceExportGVR).Namespace(echos.Namespace).Create(context.TODO(),
+			_, err := c.Dynamic().Resource(serviceExportGVR).Namespace(echos.Namespace).Create(context.TODO(),
 				&unstructured.Unstructured{Object: u}, kubeMeta.CreateOptions{})
 			if err != nil {
-				return fmt.Errorf("failed creating ServiceExport %s/%s in cluster %s: %v",
-					echos.Namespace, common.ServiceB, c.Name(), err)
+				return fmt.Errorf("failed creating %s with name %s/%s in cluster %s: %v",
+					serviceExportGVR.String(), echos.Namespace, common.ServiceB, c.Name(), err)
 			}
 
 			return nil
 		})
 	}
 
-	if err := g.Wait(); err != nil {
+	// Now wait for ServiceImport to be created
+	importClusters := echos.Match(echo.Service(common.ServiceA)).Clusters()
+	if common.IsMCSControllerEnabled(t) {
+		scopes.Framework.Infof("Waiting for the MCS Controller to create ServiceImport in each cluster")
+		for _, c := range importClusters {
+			c := c
+			serviceImports := c.Dynamic().Resource(serviceImportGVR).Namespace(echos.Namespace)
+
+			g.Go(func() error {
+				return retry.UntilSuccess(func() error {
+					si, err := serviceImports.Get(context.TODO(), common.ServiceB, kubeMeta.GetOptions{})
+					if err != nil {
+						return fmt.Errorf("failed waiting for ServiceImport %s/%s in cluster %s: %v",
+							echos.Namespace, common.ServiceB, c.Name(), err)
+					}
+
+					ips := kube.GetServiceImportIPs(si)
+					if len(ips) == 0 {
+						return fmt.Errorf("no ClusterSet IP for ServiceImport %s/%s in cluster %s",
+							echos.Namespace, common.ServiceB, c.Name())
+					}
+					return nil
+				}, retry.Timeout(5*time.Minute)) // GKE has a significant delay in creating ServiceImport.
+			})
+		}
+	} else {
+		scopes.Framework.Infof("No MCS Controller running. Manually creating ServiceImport in each cluster")
+		for _, c := range importClusters {
+			c := c
+			g.Go(func() error {
+				// Generate a dummy service in the cluster to reserve the ClusterSet VIP.
+				clusterSetIPSvc, err := genClusterSetIPService(c)
+				if err != nil {
+					return err
+				}
+
+				// Create a ServiceImport in the cluster with the ClusterSet VIP.
+				return createServiceImport(c, clusterSetIPSvc.Spec.ClusterIP, serviceImportGVR)
+			})
+		}
+	}
+
+	err = g.Wait()
+	status := "success"
+	if err != nil {
+		status = "failed"
+	}
+
+	end := time.Now()
+	scopes.Framework.Infof("=== DONE (%s): Create ServiceExport%v (%v) ===", status, exportClusters.Names(), end.Sub(start))
+	if err != nil {
 		t.Fatal(err)
 	}
 
 	// Add a cleanup that will delete the ServiceExports in each cluster concurrently.
 	t.Cleanup(func() {
 		wg := sync.WaitGroup{}
-		for _, c := range clusters {
+		for _, c := range exportClusters {
 			c := c
 			wg.Add(1)
 			go func() {
@@ -441,7 +497,7 @@ func genClusterSetIPService(c cluster.Cluster) (*kubeCore.Service, error) {
 	return dummySvc, err
 }
 
-func createServiceImport(t resource.Context, c cluster.Cluster, vip string) error {
+func createServiceImport(c cluster.Cluster, vip string, serviceImportGVR schema.GroupVersionResource) error {
 	// Get the definition for service B, so we can get the ports.
 	svc, err := c.CoreV1().Services(echos.Namespace).Get(context.TODO(), common.ServiceB, kubeMeta.GetOptions{})
 	if err != nil {
@@ -462,7 +518,7 @@ func createServiceImport(t resource.Context, c cluster.Cluster, vip string) erro
 	serviceImport := &mcsapi.ServiceImport{
 		TypeMeta: kubeMeta.TypeMeta{
 			Kind:       "ServiceImport",
-			APIVersion: common.KubeSettings(t).MCSAPIGroupVersion().String(),
+			APIVersion: serviceImportGVR.GroupVersion().String(),
 		},
 		ObjectMeta: kubeMeta.ObjectMeta{
 			Namespace: echos.Namespace,
@@ -481,7 +537,7 @@ func createServiceImport(t resource.Context, c cluster.Cluster, vip string) erro
 	}
 
 	// Create the ServiceImport.
-	_, err = c.Dynamic().Resource(mcs.ServiceImportGVR).Namespace(echos.Namespace).Create(
+	_, err = c.Dynamic().Resource(serviceImportGVR).Namespace(echos.Namespace).Create(
 		context.TODO(), &unstructured.Unstructured{Object: u}, kubeMeta.CreateOptions{})
 	if err != nil && !kerrors.IsAlreadyExists(err) {
 		return err
-- 
2.35.3

