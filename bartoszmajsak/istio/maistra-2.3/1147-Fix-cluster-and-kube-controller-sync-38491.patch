From fa4d3a7dc779cf56868c5d6f1349a5a46e009461 Mon Sep 17 00:00:00 2001
From: Zhonghu Xu <xuzhonghu@huawei.com>
Date: Fri, 29 Apr 2022 01:29:33 +0800
Subject: Fix cluster and kube controller sync (#38491)

* Split out cluster and clusterstore from secretcontroller

* Respect remote cluster timeout when running each cluster and kubecontroller

* Fix lint

* Fix case when provided a error secret, the callback failed, so the cluster has no chance to be run

* reduce max elapsed time

* Fix close twice

* Fix lint

* Remove SyncTimeout for local cluster

* Set timeout in kube multi cluster controller for non local clusters
---
 pilot/pkg/config/kube/crdclient/client.go     |   2 +-
 .../kube/controller/controller.go             |  14 +-
 .../kube/controller/multicluster.go           |  10 +-
 pkg/kube/multicluster/cluster.go              |  93 +++++++++
 pkg/kube/multicluster/clusterstore.go         | 124 ++++++++++++
 pkg/kube/multicluster/secretcontroller.go     | 185 ++----------------
 6 files changed, 249 insertions(+), 179 deletions(-)
 create mode 100644 pkg/kube/multicluster/cluster.go
 create mode 100644 pkg/kube/multicluster/clusterstore.go

diff --git a/pilot/pkg/config/kube/crdclient/client.go b/pilot/pkg/config/kube/crdclient/client.go
index d558e31e3f..462a7fbf82 100644
--- a/pilot/pkg/config/kube/crdclient/client.go
+++ b/pilot/pkg/config/kube/crdclient/client.go
@@ -426,7 +426,7 @@ func knownCRDs(crdClient apiextensionsclient.Interface) (map[string]struct{}, er
 	var res *crd.CustomResourceDefinitionList
 	b := backoff.NewExponentialBackOff()
 	b.InitialInterval = time.Second
-	b.MaxElapsedTime = time.Minute
+	b.MaxElapsedTime = 20 * time.Second
 	err := backoff.Retry(func() error {
 		ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
 		defer cancel()
diff --git a/pilot/pkg/serviceregistry/kube/controller/controller.go b/pilot/pkg/serviceregistry/kube/controller/controller.go
index c3194c47b5..b77d6819b5 100644
--- a/pilot/pkg/serviceregistry/kube/controller/controller.go
+++ b/pilot/pkg/serviceregistry/kube/controller/controller.go
@@ -139,8 +139,8 @@ type Options struct {
 	// Maximum burst for throttle when communicating with the kubernetes API
 	KubernetesAPIBurst int
 
-	// SyncTimeout, if set, causes HasSynced to be returned when marked true.
-	SyncTimeout *atomic.Bool
+	// SyncTimeout, if set, causes HasSynced to be returned when timeout.
+	SyncTimeout time.Duration
 
 	// If meshConfig.DiscoverySelectors are specified, the DiscoveryNamespacesFilter tracks the namespaces this controller watches.
 	DiscoveryNamespacesFilter filter.DiscoveryNamespacesFilter
@@ -719,7 +719,7 @@ func tryGetLatestObject(informer filter.FilteredSharedIndexInformer, obj interfa
 
 // HasSynced returns true after the initial state synchronization
 func (c *Controller) HasSynced() bool {
-	return (c.opts.SyncTimeout != nil && c.opts.SyncTimeout.Load()) || c.initialSync.Load()
+	return c.initialSync.Load()
 }
 
 func (c *Controller) informersSynced() bool {
@@ -818,6 +818,14 @@ func (c *Controller) syncEndpoints() error {
 
 // Run all controllers until a signal is received
 func (c *Controller) Run(stop <-chan struct{}) {
+	if c.opts.SyncTimeout != 0 {
+		time.AfterFunc(c.opts.SyncTimeout, func() {
+			if !c.informerInit.Load() {
+				log.Warnf("kube controller for %s initial sync timed out", c.opts.ClusterID)
+				c.informerInit.Store(true)
+			}
+		})
+	}
 	st := time.Now()
 	if c.opts.NetworksWatcher != nil {
 		c.opts.NetworksWatcher.AddNetworksHandler(c.reloadNetworkLookup)
diff --git a/pilot/pkg/serviceregistry/kube/controller/multicluster.go b/pilot/pkg/serviceregistry/kube/controller/multicluster.go
index a8230f5562..6ef6aeeabf 100644
--- a/pilot/pkg/serviceregistry/kube/controller/multicluster.go
+++ b/pilot/pkg/serviceregistry/kube/controller/multicluster.go
@@ -151,22 +151,22 @@ func (m *Multicluster) ClusterAdded(cluster *multicluster.Cluster, clusterStopCh
 	}
 
 	client := cluster.Client
+	// localCluster may also be the "config" cluster, in an external-istiod setup.
+	localCluster := m.opts.ClusterID == cluster.ID
 
 	// clusterStopCh is a channel that will be closed when this cluster removed.
 	options := m.opts
 	options.ClusterID = cluster.ID
-	// the aggregate registry's HasSynced will use the k8s controller's HasSynced, so we reference the same timeout
-	options.SyncTimeout = cluster.SyncTimeout
 	// different clusters may have different k8s version, re-apply conditional default
 	options.EndpointMode = DetectEndpointMode(client)
-
+	if !localCluster {
+		options.SyncTimeout = features.RemoteClusterTimeout
+	}
 	log.Infof("Initializing Kubernetes service registry %q", options.ClusterID)
 	kubeRegistry := NewController(client, options)
 	m.remoteKubeControllers[cluster.ID] = &kubeController{
 		Controller: kubeRegistry,
 	}
-	// localCluster may also be the "config" cluster, in an external-istiod setup.
-	localCluster := m.opts.ClusterID == cluster.ID
 
 	m.m.Unlock()
 
diff --git a/pkg/kube/multicluster/cluster.go b/pkg/kube/multicluster/cluster.go
new file mode 100644
index 0000000000..95d929a5a8
--- /dev/null
+++ b/pkg/kube/multicluster/cluster.go
@@ -0,0 +1,93 @@
+// Copyright Istio Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package multicluster
+
+import (
+	"crypto/sha256"
+	"time"
+
+	"go.uber.org/atomic"
+
+	"istio.io/istio/pilot/pkg/features"
+	"istio.io/istio/pkg/cluster"
+	"istio.io/istio/pkg/kube"
+	"istio.io/pkg/log"
+)
+
+// Cluster defines cluster struct
+type Cluster struct {
+	// ID of the cluster.
+	ID cluster.ID
+	// Client for accessing the cluster.
+	Client kube.Client
+
+	kubeConfigSha [sha256.Size]byte
+
+	stop chan struct{}
+	// initialSync is marked when RunAndWait completes
+	initialSync *atomic.Bool
+	// initialSyncTimeout is set when RunAndWait timed out
+	initialSyncTimeout *atomic.Bool
+}
+
+// Run starts the cluster's informers and waits for caches to sync. Once caches are synced, we mark the cluster synced.
+// This should be called after each of the handlers have registered informers, and should be run in a goroutine.
+func (r *Cluster) Run() {
+	if features.RemoteClusterTimeout > 0 {
+		time.AfterFunc(features.RemoteClusterTimeout, func() {
+			if !r.initialSync.Load() {
+				log.Errorf("remote cluster %s failed to sync after %v", r.ID, features.RemoteClusterTimeout)
+				timeouts.Increment()
+			}
+			r.initialSyncTimeout.Store(true)
+		})
+	}
+
+	r.Client.RunAndWait(r.stop)
+	r.initialSync.Store(true)
+}
+
+// Stop closes the stop channel, if is safe to be called multi times.
+func (r *Cluster) Stop() {
+	select {
+	case <-r.stop:
+		return
+	default:
+		close(r.stop)
+	}
+}
+
+func (r *Cluster) HasSynced() bool {
+	// It could happen when a wrong crendential provide, this cluster has no chance to run.
+	// In this case, the `initialSyncTimeout` will never be set
+	// In order not block istiod start up, check close as well.
+	if r.Closed() {
+		return true
+	}
+	return r.initialSync.Load() || r.initialSyncTimeout.Load()
+}
+
+func (r *Cluster) Closed() bool {
+	select {
+	case <-r.stop:
+		return true
+	default:
+		return false
+	}
+}
+
+func (r *Cluster) SyncDidTimeout() bool {
+	return !r.initialSync.Load() && r.initialSyncTimeout.Load()
+}
diff --git a/pkg/kube/multicluster/clusterstore.go b/pkg/kube/multicluster/clusterstore.go
new file mode 100644
index 0000000000..a885d6a020
--- /dev/null
+++ b/pkg/kube/multicluster/clusterstore.go
@@ -0,0 +1,124 @@
+// Copyright Istio Authors
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package multicluster
+
+import (
+	"sync"
+
+	"istio.io/istio/pkg/cluster"
+	"istio.io/istio/pkg/util/sets"
+)
+
+// ClusterStore is a collection of clusters
+type ClusterStore struct {
+	sync.RWMutex
+	// keyed by secret key(ns/name)->clusterID
+	remoteClusters map[string]map[cluster.ID]*Cluster
+	clusters       sets.Set
+}
+
+// newClustersStore initializes data struct to store clusters information
+func newClustersStore() *ClusterStore {
+	return &ClusterStore{
+		remoteClusters: make(map[string]map[cluster.ID]*Cluster),
+		clusters:       sets.New(),
+	}
+}
+
+func (c *ClusterStore) Store(secretKey string, clusterID cluster.ID, value *Cluster) {
+	c.Lock()
+	defer c.Unlock()
+	if _, ok := c.remoteClusters[secretKey]; !ok {
+		c.remoteClusters[secretKey] = make(map[cluster.ID]*Cluster)
+	}
+	c.remoteClusters[secretKey][clusterID] = value
+	c.clusters.Insert(string(clusterID))
+}
+
+func (c *ClusterStore) Delete(secretKey string, clusterID cluster.ID) {
+	c.Lock()
+	defer c.Unlock()
+	delete(c.remoteClusters[secretKey], clusterID)
+	c.clusters.Delete(string(clusterID))
+	if len(c.remoteClusters[secretKey]) == 0 {
+		delete(c.remoteClusters, secretKey)
+	}
+}
+
+func (c *ClusterStore) Get(secretKey string, clusterID cluster.ID) *Cluster {
+	c.RLock()
+	defer c.RUnlock()
+	if _, ok := c.remoteClusters[secretKey]; !ok {
+		return nil
+	}
+	return c.remoteClusters[secretKey][clusterID]
+}
+
+func (c *ClusterStore) Contains(clusterID cluster.ID) bool {
+	c.RLock()
+	defer c.RUnlock()
+	return c.clusters.Contains(string(clusterID))
+}
+
+func (c *ClusterStore) GetByID(clusterID cluster.ID) *Cluster {
+	c.RLock()
+	defer c.RUnlock()
+	for _, clusters := range c.remoteClusters {
+		c, ok := clusters[clusterID]
+		if ok {
+			return c
+		}
+	}
+	return nil
+}
+
+// All returns a copy of the current remote clusters.
+func (c *ClusterStore) All() map[string]map[cluster.ID]*Cluster {
+	if c == nil {
+		return nil
+	}
+	c.RLock()
+	defer c.RUnlock()
+	out := make(map[string]map[cluster.ID]*Cluster, len(c.remoteClusters))
+	for secret, clusters := range c.remoteClusters {
+		out[secret] = make(map[cluster.ID]*Cluster, len(clusters))
+		for cid, c := range clusters {
+			outCluster := *c
+			out[secret][cid] = &outCluster
+		}
+	}
+	return out
+}
+
+// GetExistingClustersFor return existing clusters registered for the given secret
+func (c *ClusterStore) GetExistingClustersFor(secretKey string) []*Cluster {
+	c.RLock()
+	defer c.RUnlock()
+	out := make([]*Cluster, 0, len(c.remoteClusters[secretKey]))
+	for _, cluster := range c.remoteClusters[secretKey] {
+		out = append(out, cluster)
+	}
+	return out
+}
+
+func (c *ClusterStore) Len() int {
+	c.Lock()
+	defer c.Unlock()
+	out := 0
+	for _, clusterMap := range c.remoteClusters {
+		out += len(clusterMap)
+	}
+	return out
+}
diff --git a/pkg/kube/multicluster/secretcontroller.go b/pkg/kube/multicluster/secretcontroller.go
index 1d8ebd7343..c38d11b2cf 100644
--- a/pkg/kube/multicluster/secretcontroller.go
+++ b/pkg/kube/multicluster/secretcontroller.go
@@ -20,7 +20,6 @@
 	"crypto/sha256"
 	"errors"
 	"fmt"
-	"sync"
 	"time"
 
 	"github.com/hashicorp/go-multierror"
@@ -88,153 +87,6 @@ type Controller struct {
 	cs *ClusterStore
 
 	handlers []ClusterHandler
-
-	once              sync.Once
-	remoteSyncTimeout atomic.Bool
-}
-
-// Cluster defines cluster struct
-type Cluster struct {
-	// ID of the cluster.
-	ID cluster.ID
-	// SyncTimeout is marked after features.RemoteClusterTimeout.
-	SyncTimeout *atomic.Bool
-	// Client for accessing the cluster.
-	Client kube.Client
-
-	kubeConfigSha [sha256.Size]byte
-
-	stop chan struct{}
-	// initialSync is marked when RunAndWait completes
-	initialSync *atomic.Bool
-}
-
-// Stop channel which is closed when the cluster is removed or the Controller that created the client is stopped.
-// Client.RunAndWait is called using this channel.
-func (r *Cluster) Stop() <-chan struct{} {
-	return r.stop
-}
-
-func (c *Controller) AddHandler(h ClusterHandler) {
-	log.Infof("handling remote clusters in %T", h)
-	c.handlers = append(c.handlers, h)
-}
-
-// Run starts the cluster's informers and waits for caches to sync. Once caches are synced, we mark the cluster synced.
-// This should be called after each of the handlers have registered informers, and should be run in a goroutine.
-func (r *Cluster) Run() {
-	r.Client.RunAndWait(r.Stop())
-	r.initialSync.Store(true)
-}
-
-func (r *Cluster) HasSynced() bool {
-	return r.initialSync.Load() || r.SyncTimeout.Load()
-}
-
-func (r *Cluster) SyncDidTimeout() bool {
-	return r.SyncTimeout.Load() && !r.HasSynced()
-}
-
-// ClusterStore is a collection of clusters
-type ClusterStore struct {
-	sync.RWMutex
-	// keyed by secret key(ns/name)->clusterID
-	remoteClusters map[string]map[cluster.ID]*Cluster
-	clusters       sets.Set
-}
-
-// newClustersStore initializes data struct to store clusters information
-func newClustersStore() *ClusterStore {
-	return &ClusterStore{
-		remoteClusters: make(map[string]map[cluster.ID]*Cluster),
-		clusters:       sets.New(),
-	}
-}
-
-func (c *ClusterStore) Store(secretKey string, clusterID cluster.ID, value *Cluster) {
-	c.Lock()
-	defer c.Unlock()
-	if _, ok := c.remoteClusters[secretKey]; !ok {
-		c.remoteClusters[secretKey] = make(map[cluster.ID]*Cluster)
-	}
-	c.remoteClusters[secretKey][clusterID] = value
-	c.clusters.Insert(string(clusterID))
-}
-
-func (c *ClusterStore) Delete(secretKey string, clusterID cluster.ID) {
-	c.Lock()
-	defer c.Unlock()
-	delete(c.remoteClusters[secretKey], clusterID)
-	c.clusters.Delete(string(clusterID))
-	if len(c.remoteClusters[secretKey]) == 0 {
-		delete(c.remoteClusters, secretKey)
-	}
-}
-
-func (c *ClusterStore) Get(secretKey string, clusterID cluster.ID) *Cluster {
-	c.RLock()
-	defer c.RUnlock()
-	if _, ok := c.remoteClusters[secretKey]; !ok {
-		return nil
-	}
-	return c.remoteClusters[secretKey][clusterID]
-}
-
-func (c *ClusterStore) Contains(clusterID cluster.ID) bool {
-	c.RLock()
-	defer c.RUnlock()
-	return c.clusters.Contains(string(clusterID))
-}
-
-func (c *ClusterStore) GetByID(clusterID cluster.ID) *Cluster {
-	c.RLock()
-	defer c.RUnlock()
-	for _, clusters := range c.remoteClusters {
-		c, ok := clusters[clusterID]
-		if ok {
-			return c
-		}
-	}
-	return nil
-}
-
-// All returns a copy of the current remote clusters.
-func (c *ClusterStore) All() map[string]map[cluster.ID]*Cluster {
-	if c == nil {
-		return nil
-	}
-	c.RLock()
-	defer c.RUnlock()
-	out := make(map[string]map[cluster.ID]*Cluster, len(c.remoteClusters))
-	for secret, clusters := range c.remoteClusters {
-		out[secret] = make(map[cluster.ID]*Cluster, len(clusters))
-		for cid, c := range clusters {
-			outCluster := *c
-			out[secret][cid] = &outCluster
-		}
-	}
-	return out
-}
-
-// GetExistingClustersFor return existing clusters registered for the given secret
-func (c *ClusterStore) GetExistingClustersFor(secretKey string) []*Cluster {
-	c.RLock()
-	defer c.RUnlock()
-	out := make([]*Cluster, 0, len(c.remoteClusters[secretKey]))
-	for _, cluster := range c.remoteClusters[secretKey] {
-		out = append(out, cluster)
-	}
-	return out
-}
-
-func (c *ClusterStore) Len() int {
-	c.Lock()
-	defer c.Unlock()
-	out := 0
-	for _, clusterMap := range c.remoteClusters {
-		out += len(clusterMap)
-	}
-	return out
 }
 
 // NewController returns a new secret controller
@@ -270,6 +122,10 @@ func NewController(kubeclientset kube.Client, namespace string, localClusterID c
 	return controller
 }
 
+func (c *Controller) AddHandler(h ClusterHandler) {
+	c.handlers = append(c.handlers, h)
+}
+
 // Run starts the controller until it receives a message over stopCh
 func (c *Controller) Run(stopCh <-chan struct{}) error {
 	// run handlers for the local cluster; do not store this *Cluster in the ClusterStore or give it a SyncTimeout
@@ -289,11 +145,6 @@ func (c *Controller) Run(stopCh <-chan struct{}) error {
 			return
 		}
 		log.Infof("multicluster remote secrets controller cache synced in %v", time.Since(t0))
-		if features.RemoteClusterTimeout != 0 {
-			time.AfterFunc(features.RemoteClusterTimeout, func() {
-				c.remoteSyncTimeout.Store(true)
-			})
-		}
 		c.queue.Run(stopCh)
 	}()
 	return nil
@@ -304,7 +155,7 @@ func (c *Controller) close() {
 	defer c.cs.Unlock()
 	for _, clusterMap := range c.cs.remoteClusters {
 		for _, cluster := range clusterMap {
-			close(cluster.stop)
+			cluster.Stop()
 		}
 	}
 }
@@ -334,14 +185,6 @@ func (c *Controller) HasSynced() bool {
 	if synced {
 		return true
 	}
-	if c.remoteSyncTimeout.Load() {
-		c.once.Do(func() {
-			log.Errorf("remote clusters failed to sync after %v", features.RemoteClusterTimeout)
-			timeouts.Increment()
-		})
-		return true
-	}
-
 	return synced
 }
 
@@ -460,9 +303,9 @@ func (c *Controller) createRemoteCluster(kubeConfig []byte, clusterID string) (*
 		Client: clients,
 		stop:   make(chan struct{}),
 		// for use inside the package, to close on cleanup
-		initialSync:   atomic.NewBool(false),
-		SyncTimeout:   &c.remoteSyncTimeout,
-		kubeConfigSha: sha256.Sum256(kubeConfig),
+		initialSync:        atomic.NewBool(false),
+		initialSyncTimeout: atomic.NewBool(false),
+		kubeConfigSha:      sha256.Sum256(kubeConfig),
 	}, nil
 }
 
@@ -505,6 +348,7 @@ func (c *Controller) addSecret(name types.NamespacedName, s *corev1.Secret) {
 		}
 		c.cs.Store(secretKey, remoteCluster.ID, remoteCluster)
 		if err := callback(remoteCluster, remoteCluster.stop); err != nil {
+			remoteCluster.Stop()
 			log.Errorf("%s cluster_id from secret=%v: %s %v", action, clusterID, secretKey, err)
 			continue
 		}
@@ -522,7 +366,7 @@ func (c *Controller) deleteSecret(secretKey string) {
 			continue
 		}
 		log.Infof("Deleting cluster_id=%v configured by secret=%v", cluster.ID, secretKey)
-		close(cluster.stop)
+		cluster.Stop()
 		err := c.handleDelete(cluster.ID)
 		if err != nil {
 			log.Errorf("Error removing cluster_id=%v configured by secret=%v: %v",
@@ -541,7 +385,7 @@ func (c *Controller) deleteCluster(secretKey string, clusterID cluster.ID) {
 		log.Infof("Number of remote clusters: %d", c.cs.Len())
 	}()
 	log.Infof("Deleting cluster_id=%v configured by secret=%v", clusterID, secretKey)
-	close(c.cs.remoteClusters[secretKey][clusterID].stop)
+	c.cs.remoteClusters[secretKey][clusterID].Stop()
 	err := c.handleDelete(clusterID)
 	if err != nil {
 		log.Errorf("Error removing cluster_id=%v configured by secret=%v: %v",
@@ -580,12 +424,13 @@ func (c *Controller) ListRemoteClusters() []cluster.DebugInfo {
 	for secretName, clusters := range c.cs.All() {
 		for clusterID, c := range clusters {
 			syncStatus := "syncing"
-			if c.HasSynced() {
-				syncStatus = "synced"
+			if c.Closed() {
+				syncStatus = "closed"
 			} else if c.SyncDidTimeout() {
 				syncStatus = "timeout"
+			} else if c.HasSynced() {
+				syncStatus = "synced"
 			}
-
 			out = append(out, cluster.DebugInfo{
 				ID:         clusterID,
 				SecretName: secretName,
-- 
2.35.3

