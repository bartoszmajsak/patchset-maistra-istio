From 1716048a7fa5182cb3d5ba258eac78c3aa09f7f7 Mon Sep 17 00:00:00 2001
From: John Howard <howardjohn@google.com>
Date: Mon, 21 Mar 2022 19:42:23 -0700
Subject: Remove PILOT_ENABLE_FLOW_CONTROL flag (#37916)

* xds: refactor Generator signature

Curently we take a `push` and a `PushRequest`. PushRequest already has
push, so we can just use that everywhere. This avoids mistakes wher we
may accidentally set one but not the other, etc.

There are no (known) bugs this fixes; this is intended to be a
refactoring only.

* lint

* Remove PILOT_ENABLE_FLOW_CONTROL flag

This was originally added in
https://github.com/istio/istio/commit/d63c8162dd54132da683307a88549895aa0cec79.
While this may have a future in Istio, it currently has been dead,
untested code for 2 years. Because of this, and due to the fact it adds
complexity to our critical code paths, I think its best to drop it until
we have the time and desire to bring it to stable.
---
 pilot/pkg/features/pilot.go |   8 ---
 pilot/pkg/xds/ads.go        |  96 ++++++++--------------------------
 pilot/pkg/xds/ads_test.go   |  73 --------------------------
 pilot/pkg/xds/delta.go      | 101 ++++++++++--------------------------
 4 files changed, 51 insertions(+), 227 deletions(-)

diff --git a/pilot/pkg/features/pilot.go b/pilot/pkg/features/pilot.go
index 925920748c..bec070fcfd 100644
--- a/pilot/pkg/features/pilot.go
+++ b/pilot/pkg/features/pilot.go
@@ -492,14 +492,6 @@
 	WorkloadEntryCrossCluster = env.RegisterBoolVar("PILOT_ENABLE_CROSS_CLUSTER_WORKLOAD_ENTRY", true,
 		"If enabled, pilot will read WorkloadEntry from other clusters, selectable by Services in that cluster.").Get()
 
-	EnableFlowControl = env.RegisterBoolVar(
-		"PILOT_ENABLE_FLOW_CONTROL",
-		false,
-		"If enabled, pilot will wait for the completion of a receive operation before"+
-			"executing a push operation. This is a form of flow control and is useful in"+
-			"environments with high rates of push requests to each gateway. By default,"+
-			"this is false.").Get()
-
 	FlowControlTimeout = env.RegisterDurationVar(
 		"PILOT_FLOW_CONTROL_TIMEOUT",
 		15*time.Second,
diff --git a/pilot/pkg/xds/ads.go b/pilot/pkg/xds/ads.go
index 0b12ee6065..da1b3dacc9 100644
--- a/pilot/pkg/xds/ads.go
+++ b/pilot/pkg/xds/ads.go
@@ -106,11 +106,6 @@ type Connection struct {
 
 	// errorChan is used to process error during discovery request processing.
 	errorChan chan error
-
-	// blockedPushes is a map of TypeUrl to push request. This is set when we attempt to push to a busy Envoy
-	// (last push not ACKed). When we get an ACK from Envoy, if the type is populated here, we will trigger
-	// the push.
-	blockedPushes map[string]*model.PushRequest
 }
 
 // Event represents a config or registry event that results in a push.
@@ -124,15 +119,14 @@ type Event struct {
 
 func newConnection(peerAddr string, stream DiscoveryStream) *Connection {
 	return &Connection{
-		pushChannel:   make(chan *Event),
-		initialized:   make(chan struct{}),
-		stop:          make(chan struct{}),
-		reqChan:       make(chan *discovery.DiscoveryRequest, 1),
-		errorChan:     make(chan error, 1),
-		PeerAddr:      peerAddr,
-		Connect:       time.Now(),
-		stream:        stream,
-		blockedPushes: map[string]*model.PushRequest{},
+		pushChannel: make(chan *Event),
+		initialized: make(chan struct{}),
+		stop:        make(chan struct{}),
+		reqChan:     make(chan *discovery.DiscoveryRequest, 1),
+		errorChan:   make(chan error, 1),
+		PeerAddr:    peerAddr,
+		Connect:     time.Now(),
+		stream:      stream,
 	}
 }
 
@@ -208,40 +202,25 @@ func (s *DiscoveryServer) processRequest(req *discovery.DiscoveryRequest, con *C
 		s.StatusReporter.RegisterEvent(con.ConID, req.TypeUrl, req.ResponseNonce)
 	}
 	shouldRespond := s.shouldRespond(con, req)
+	if !shouldRespond {
+		return nil
+	}
 
-	var request *model.PushRequest
-	push := con.proxy.LastPushContext
-	if shouldRespond {
-		// This is a request, trigger a full push for this type. Override the blocked push (if it exists),
-		// as this full push is guaranteed to be a superset of what we would have pushed from the blocked push.
-		request = &model.PushRequest{Full: true, Push: push}
-	} else {
-		// Check if we have a blocked push. If this was an ACK, we will send it.
-		// Either way we remove the blocked push as we will send a push.
-		haveBlockedPush := false
-		con.proxy.Lock()
-		request, haveBlockedPush = con.blockedPushes[req.TypeUrl]
-		delete(con.blockedPushes, req.TypeUrl)
-		con.proxy.Unlock()
-		if haveBlockedPush {
-			// we have a blocked push which we will use
-			log.Debugf("%s: DEQUEUE for node:%s", v3.GetShortType(req.TypeUrl), con.proxy.ID)
-		} else {
-			// This is an ACK, no delayed push
-			// Return immediately, no action needed
-			return nil
-		}
+	request := &model.PushRequest{
+		Full:   true,
+		Push:   con.proxy.LastPushContext,
+		Reason: []model.TriggerReason{model.ProxyRequest},
+
+		// The usage of LastPushTime (rather than time.Now()), is critical here for correctness; This time
+		// is used by the XDS cache to determine if a entry is stale. If we use Now() with an old push context,
+		// we may end up overriding active cache entries with stale ones.
+		Start: con.proxy.LastPushTime,
 	}
 
-	request.Reason = append(request.Reason, model.ProxyRequest)
-	// The usage of LastPushTime (rather than time.Now()), is critical here for correctness; This time
-	// is used by the XDS cache to determine if a entry is stale. If we use Now() with an old push context,
-	// we may end up overriding active cache entries with stale ones.
-	request.Start = con.proxy.LastPushTime
 	// SidecarScope for the proxy may not have been updated based on this pushContext.
 	// It can happen when `processRequest` comes after push context has been updated(s.initPushContext),
 	// but before proxy's SidecarScope has been updated(s.updateProxy).
-	if con.proxy.SidecarScope != nil && con.proxy.SidecarScope.Version != push.PushVersion {
+	if con.proxy.SidecarScope != nil && con.proxy.SidecarScope.Version != request.Push.PushVersion {
 		s.computeProxyState(con.proxy, request)
 	}
 	return s.pushXds(con, con.Watched(req.TypeUrl), request)
@@ -711,37 +690,8 @@ func (s *DiscoveryServer) pushConnection(con *Connection, pushEv *Event) error {
 	// Each Generator is responsible for determining if the push event requires a push
 	wrl, ignoreEvents := con.pushDetails()
 	for _, w := range wrl {
-		if !features.EnableFlowControl {
-			// Always send the push if flow control disabled
-			if err := s.pushXds(con, w, pushRequest); err != nil {
-				return err
-			}
-			continue
-		}
-		// If flow control is enabled, we will only push if we got an ACK for the previous response
-		synced, timeout := con.Synced(w.TypeUrl)
-		if !synced && timeout {
-			// We are not synced, but we have been stuck for too long. We will trigger the push anyways to
-			// avoid any scenario where this may deadlock.
-			// This can possibly be removed in the future if we find this never causes issues
-			totalDelayedPushes.With(typeTag.Value(v3.GetMetricType(w.TypeUrl))).Increment()
-			log.Warnf("%s: QUEUE TIMEOUT for node:%s", v3.GetShortType(w.TypeUrl), con.proxy.ID)
-		}
-		if synced || timeout {
-			// Send the push now
-			if err := s.pushXds(con, w, pushRequest); err != nil {
-				return err
-			}
-		} else {
-			// The type is not yet synced. Instead of pushing now, which may overload Envoy,
-			// we will wait until the last push is ACKed and trigger the push. See
-			// https://github.com/istio/istio/issues/25685 for details on the performance
-			// impact of sending pushes before Envoy ACKs.
-			totalDelayedPushes.With(typeTag.Value(v3.GetMetricType(w.TypeUrl))).Increment()
-			log.Debugf("%s: QUEUE for node:%s", v3.GetShortType(w.TypeUrl), con.proxy.ID)
-			con.proxy.Lock()
-			con.blockedPushes[w.TypeUrl] = con.blockedPushes[w.TypeUrl].CopyMerge(pushEv.pushRequest)
-			con.proxy.Unlock()
+		if err := s.pushXds(con, w, pushRequest); err != nil {
+			return err
 		}
 	}
 	if pushRequest.Full {
diff --git a/pilot/pkg/xds/ads_test.go b/pilot/pkg/xds/ads_test.go
index a64a61bd9d..2193fcc06e 100644
--- a/pilot/pkg/xds/ads_test.go
+++ b/pilot/pkg/xds/ads_test.go
@@ -21,10 +21,8 @@
 
 	core "github.com/envoyproxy/go-control-plane/envoy/config/core/v3"
 	discovery "github.com/envoyproxy/go-control-plane/envoy/service/discovery/v3"
-	"google.golang.org/genproto/googleapis/rpc/status"
 
 	networking "istio.io/api/networking/v1alpha3"
-	"istio.io/istio/pilot/pkg/features"
 	"istio.io/istio/pilot/pkg/model"
 	"istio.io/istio/pilot/pkg/util/sets"
 	"istio.io/istio/pilot/pkg/xds"
@@ -815,77 +813,6 @@ func TestEnvoyRDSProtocolError(t *testing.T) {
 	})
 }
 
-func TestBlockedPush(t *testing.T) {
-	original := features.EnableFlowControl
-	t.Cleanup(func() {
-		features.EnableFlowControl = original
-	})
-	t.Run("flow control enabled", func(t *testing.T) {
-		features.EnableFlowControl = true
-		s := xds.NewFakeDiscoveryServer(t, xds.FakeOptions{})
-		ads := s.ConnectADS().WithType(v3.ClusterType)
-		ads.RequestResponseAck(t, nil)
-		// Send push, get a response but do not ACK it
-		xds.AdsPushAll(s.Discovery)
-		res := ads.ExpectResponse(t)
-
-		// Another push results in no response as we are blocked
-		xds.AdsPushAll(s.Discovery)
-		ads.ExpectNoResponse(t)
-
-		// ACK, unblocking the previous push
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce})
-		res = ads.ExpectResponse(t)
-
-		// ACK again, ensure we do not response
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce})
-		ads.ExpectNoResponse(t)
-
-		// request new resources, expect response
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce, ResourceNames: []string{"foo"}})
-		res = ads.ExpectResponse(t)
-		// request new resources, expect response, even without explicit ACK
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce, ResourceNames: []string{"foo", "bar"}})
-		ads.ExpectResponse(t)
-	})
-	t.Run("flow control enabled NACK", func(t *testing.T) {
-		features.EnableFlowControl = true
-		s := xds.NewFakeDiscoveryServer(t, xds.FakeOptions{})
-		ads := s.ConnectADS().WithType(v3.ClusterType)
-		ads.RequestResponseAck(t, nil)
-
-		// Send push, get a response and NACK it
-		xds.AdsPushAll(s.Discovery)
-		res := ads.ExpectResponse(t)
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce, ErrorDetail: &status.Status{Message: "Test request NACK"}})
-
-		// Another push results in a response as we are not blocked (NACK unblocks)
-		xds.AdsPushAll(s.Discovery)
-		ads.ExpectResponse(t)
-
-		// ACK should not get push
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce})
-		ads.ExpectNoResponse(t)
-	})
-	t.Run("flow control disabled", func(t *testing.T) {
-		features.EnableFlowControl = false
-		s := xds.NewFakeDiscoveryServer(t, xds.FakeOptions{})
-		ads := s.ConnectADS().WithType(v3.ClusterType)
-		ads.RequestResponseAck(t, nil)
-		// Send push, get a response but do not ACK it
-		xds.AdsPushAll(s.Discovery)
-		res := ads.ExpectResponse(t)
-
-		// Another push results in response as we do not care that we are blocked
-		xds.AdsPushAll(s.Discovery)
-		ads.ExpectResponse(t)
-
-		// ACK gets no response as we don't have flow control enabled
-		ads.Request(t, &discovery.DiscoveryRequest{ResponseNonce: res.Nonce})
-		ads.ExpectNoResponse(t)
-	})
-}
-
 func TestEnvoyRDSUpdatedRouteRequest(t *testing.T) {
 	expectRoutes := func(resp *discovery.DiscoveryResponse, expected ...string) {
 		t.Helper()
diff --git a/pilot/pkg/xds/delta.go b/pilot/pkg/xds/delta.go
index f0915cfc54..169df38b8a 100644
--- a/pilot/pkg/xds/delta.go
+++ b/pilot/pkg/xds/delta.go
@@ -150,37 +150,8 @@ func (s *DiscoveryServer) pushConnectionDelta(con *Connection, pushEv *Event) er
 	// Each Generator is responsible for determining if the push event requires a push
 	wrl, ignoreEvents := con.pushDetails()
 	for _, w := range wrl {
-		if !features.EnableFlowControl {
-			// Always send the push if flow control disabled
-			if err := s.pushDeltaXds(con, pushRequest.Push, w, nil, pushRequest); err != nil {
-				return err
-			}
-			continue
-		}
-		// If flow control is enabled, we will only push if we got an ACK for the previous response
-		synced, timeout := con.Synced(w.TypeUrl)
-		if !synced && timeout {
-			// We are not synced, but we have been stuck for too long. We will trigger the push anyways to
-			// avoid any scenario where this may deadlock.
-			// This can possibly be removed in the future if we find this never causes issues
-			totalDelayedPushes.With(typeTag.Value(v3.GetMetricType(w.TypeUrl))).Increment()
-			deltaLog.Warnf("%s: QUEUE TIMEOUT for node:%s", v3.GetShortType(w.TypeUrl), con.proxy.ID)
-		}
-		if synced || timeout {
-			// Send the push now
-			if err := s.pushDeltaXds(con, pushRequest.Push, w, nil, pushRequest); err != nil {
-				return err
-			}
-		} else {
-			// The type is not yet synced. Instead of pushing now, which may overload Envoy,
-			// we will wait until the last push is ACKed and trigger the push. See
-			// https://github.com/istio/istio/issues/25685 for details on the performance
-			// impact of sending pushes before Envoy ACKs.
-			totalDelayedPushes.With(typeTag.Value(v3.GetMetricType(w.TypeUrl))).Increment()
-			deltaLog.Debugf("%s: QUEUE for node:%s", v3.GetShortType(w.TypeUrl), con.proxy.ID)
-			con.proxy.Lock()
-			con.blockedPushes[w.TypeUrl] = con.blockedPushes[w.TypeUrl].CopyMerge(pushEv.pushRequest)
-			con.proxy.Unlock()
+		if err := s.pushDeltaXds(con, w, nil, pushRequest); err != nil {
+			return err
 		}
 	}
 	if pushRequest.Full {
@@ -288,42 +259,27 @@ func (s *DiscoveryServer) processDeltaRequest(req *discovery.DeltaDiscoveryReque
 		s.StatusReporter.RegisterEvent(con.ConID, req.TypeUrl, req.ResponseNonce)
 	}
 	shouldRespond := s.shouldRespondDelta(con, req)
-	var request *model.PushRequest
-	push := con.proxy.LastPushContext
-	if shouldRespond {
-		// This is a request, trigger a full push for this type. Override the blocked push (if it exists),
-		// as this full push is guaranteed to be a superset of what we would have pushed from the blocked push.
-		request = &model.PushRequest{Full: true, Push: push}
-	} else {
-		// Check if we have a blocked push. If this was an ACK, we will send it.
-		// Either way we remove the blocked push as we will send a push.
-		haveBlockedPush := false
-		con.proxy.Lock()
-		request, haveBlockedPush = con.blockedPushes[req.TypeUrl]
-		delete(con.blockedPushes, req.TypeUrl)
-		con.proxy.Unlock()
-		if haveBlockedPush {
-			// we have a blocked push which we will use
-			deltaLog.Debugf("%s: DEQUEUE for node:%s", v3.GetShortType(req.TypeUrl), con.proxy.ID)
-		} else {
-			// This is an ACK, no delayed push
-			// Return immediately, no action needed
-			return nil
-		}
+	if !shouldRespond {
+		return nil
 	}
 
-	request.Reason = append(request.Reason, model.ProxyRequest)
-	// The usage of LastPushTime (rather than time.Now()), is critical here for correctness; This time
-	// is used by the XDS cache to determine if a entry is stale. If we use Now() with an old push context,
-	// we may end up overriding active cache entries with stale ones.
-	request.Start = con.proxy.LastPushTime
+	request := &model.PushRequest{
+		Full:   true,
+		Push:   con.proxy.LastPushContext,
+		Reason: []model.TriggerReason{model.ProxyRequest},
+
+		// The usage of LastPushTime (rather than time.Now()), is critical here for correctness; This time
+		// is used by the XDS cache to determine if a entry is stale. If we use Now() with an old push context,
+		// we may end up overriding active cache entries with stale ones.
+		Start: con.proxy.LastPushTime,
+	}
 	// SidecarScope for the proxy may has not been updated based on this pushContext.
 	// It can happen when `processRequest` comes after push context has been updated(s.initPushContext),
 	// but before proxy's SidecarScope has been updated(s.updateProxy).
-	if con.proxy.SidecarScope != nil && con.proxy.SidecarScope.Version != push.PushVersion {
+	if con.proxy.SidecarScope != nil && con.proxy.SidecarScope.Version != request.Push.PushVersion {
 		s.computeProxyState(con.proxy, request)
 	}
-	return s.pushDeltaXds(con, push, con.Watched(req.TypeUrl), req.ResourceNamesSubscribe, request)
+	return s.pushDeltaXds(con, con.Watched(req.TypeUrl), req.ResourceNamesSubscribe, request)
 }
 
 // shouldRespondDelta determines whether this request needs to be responded back. It applies the ack/nack rules as per xds protocol
@@ -421,7 +377,7 @@ func (s *DiscoveryServer) shouldRespondDelta(con *Connection, request *discovery
 // Push an XDS resource for the given connection. Configuration will be generated
 // based on the passed in generator. Based on the updates field, generators may
 // choose to send partial or even no response if there are no changes.
-func (s *DiscoveryServer) pushDeltaXds(con *Connection, push *model.PushContext,
+func (s *DiscoveryServer) pushDeltaXds(con *Connection,
 	w *model.WatchedResource, subscribe []string, req *model.PushRequest) error {
 	if w == nil {
 		return nil
@@ -460,7 +416,7 @@ func (s *DiscoveryServer) pushDeltaXds(con *Connection, push *model.PushContext,
 	if err != nil || (res == nil && deletedRes == nil) {
 		// If we have nothing to send, report that we got an ACK for this version.
 		if s.StatusReporter != nil {
-			s.StatusReporter.RegisterEvent(con.ConID, w.TypeUrl, push.LedgerVersion)
+			s.StatusReporter.RegisterEvent(con.ConID, w.TypeUrl, req.Push.LedgerVersion)
 		}
 		return err
 	}
@@ -469,8 +425,8 @@ func (s *DiscoveryServer) pushDeltaXds(con *Connection, push *model.PushContext,
 		ControlPlane: ControlPlane(),
 		TypeUrl:      w.TypeUrl,
 		// TODO: send different version for incremental eds
-		SystemVersionInfo: push.PushVersion,
-		Nonce:             nonce(push.LedgerVersion),
+		SystemVersionInfo: req.Push.PushVersion,
+		Nonce:             nonce(req.Push.LedgerVersion),
 		Resources:         res,
 	}
 	currentResources := extractNames(res)
@@ -533,15 +489,14 @@ func (s *DiscoveryServer) pushDeltaXds(con *Connection, push *model.PushContext,
 
 func newDeltaConnection(peerAddr string, stream DeltaDiscoveryStream) *Connection {
 	return &Connection{
-		pushChannel:   make(chan *Event),
-		initialized:   make(chan struct{}),
-		stop:          make(chan struct{}),
-		PeerAddr:      peerAddr,
-		Connect:       time.Now(),
-		deltaStream:   stream,
-		deltaReqChan:  make(chan *discovery.DeltaDiscoveryRequest, 1),
-		errorChan:     make(chan error, 1),
-		blockedPushes: map[string]*model.PushRequest{},
+		pushChannel:  make(chan *Event),
+		initialized:  make(chan struct{}),
+		stop:         make(chan struct{}),
+		PeerAddr:     peerAddr,
+		Connect:      time.Now(),
+		deltaStream:  stream,
+		deltaReqChan: make(chan *discovery.DeltaDiscoveryRequest, 1),
+		errorChan:    make(chan error, 1),
 	}
 }
 
-- 
2.35.3

